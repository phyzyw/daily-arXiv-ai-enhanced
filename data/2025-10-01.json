{"id": "2509.25486", "title": "Scalable Boltzmann Generators for equilibrium sampling of large-scale materials", "authors": ["Maximilian Schebek", "Jutta Rogal"], "summary": "The use of generative models to sample equilibrium distributions of many-body systems, as first demonstrated by Boltzmann Generators, has attracted substantial interest due to their ability to produce unbiased and uncorrelated samples in `one shot'. Despite their promise and impressive results across the natural sciences, scaling these models to large systems remains a major challenge. In this work, we introduce a Boltzmann Generator architecture that addresses this scalability bottleneck with a focus on applications in materials science. We leverage augmented coupling flows in combination with graph neural networks to base the generation process on local environmental information, while allowing for energy-based training and fast inference. Compared to previous architectures, our model trains significantly faster, requires far less computational resources, and achieves superior sampling efficiencies. Crucially, the architecture is transferable to larger system sizes, which allows for the efficient sampling of materials with simulation cells of unprecedented size. We demonstrate the potential of our approach by applying it to several materials systems, including Lennard-Jones crystals, ice phases of mW water, and the phase diagram of silicon, for system sizes well above one thousand atoms. The trained Boltzmann Generators produce highly accurate equilibrium ensembles for various crystal structures, as well as Helmholtz and Gibbs free energies across a range of system sizes, able to reach scales where finite-size effects become negligible.", "published": "2025-09-29", "categories": ["cond-mat.stat-mech", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2509.25486v1", "primary_category": "cond-mat.stat-mech"}
{"id": "2509.26397", "title": "Are neural scaling laws leading quantum chemistry astray?", "authors": ["Siwoo Lee", "Adji Bousso Dieng"], "summary": "Neural scaling laws are driving the machine learning community toward training ever-larger foundation models across domains, assuring high accuracy and transferable representations for extrapolative tasks. We test this promise in quantum chemistry by scaling model capacity and training data from quantum chemical calculations. As a generalization task, we evaluate the resulting models' predictions of the bond dissociation energy of neutral H$_2$, the simplest possible molecule. We find that, regardless of dataset size or model capacity, models trained only on stable structures fail dramatically to even qualitatively reproduce the H$_2$ energy curve. Only when compressed and stretched geometries are explicitly included in training do the predictions roughly resemble the correct shape. Nonetheless, the largest foundation models trained on the largest and most diverse datasets containing dissociating diatomics exhibit serious failures on simple diatomic molecules. Most strikingly, they cannot reproduce the trivial repulsive energy curve of two bare protons, revealing their failure to learn the basic Coulomb's law involved in electronic structure theory. These results suggest that scaling alone is insufficient for building reliable quantum chemical models.", "published": "2025-09-30", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2509.26397v1", "primary_category": "physics.chem-ph"}
{"id": "2509.26139", "title": "Leveraging AI modelling for FDS with Simvue: monitor and optimise for more sustainable simulations", "authors": ["James Panayis", "Matt Field", "Vignesh Gopakumar", "Andrew Lahiff", "Kristian Zarebski", "Aby Abraham", "Jonathan L. Hodges"], "summary": "There is high demand on fire simulations, in both scale and quantity. We present a multi-pronged approach to improving the time and energy required to meet these demands. We show the ability of a custom machine learning surrogate model to predict the dynamics of heat propagation orders of magnitude faster than state-of-the-art CFD software for this application. We also demonstrate how a guided optimisation procedure can decrease the number of simulations required to meet an objective; using lightweight models to decide which simulations to run, we see a tenfold reduction when locating the most dangerous location for a fire to occur within a building based on the impact of smoke on visibility. Finally we present a framework and product, Simvue, through which we access these tools along with a host of automatic organisational and tracking features which enables future reuse of data and more savings through better management of simulations and combating redundancy.", "published": "2025-09-30", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2509.26139v1", "primary_category": "cs.LG"}
{"id": "2509.25730", "title": "A Physics-Guided Probabilistic Surrogate Modeling Framework for Digital Twins of Underwater Radiated Noise", "authors": ["Indu Kant Deo", "Akash Venkateshwaran", "Rajeev K. Jaiman"], "summary": "Ship traffic is an increasing source of underwater radiated noise in coastal waters, motivating real-time digital twins of ocean acoustics for operational noise mitigation. We present a physics-guided probabilistic framework to predict three-dimensional transmission loss in realistic ocean environments. As a case study, we consider the Salish Sea along shipping routes from the Pacific Ocean to the Port of Vancouver. A dataset of over 30 million source-receiver pairs was generated with a Gaussian beam solver across seasonal sound speed profiles and one-third-octave frequency bands spanning 12.5 Hz to 8 kHz. We first assess sparse variational Gaussian processes (SVGP) and then incorporate physics-based mean functions combining spherical spreading with frequency-dependent absorption. To capture nonlinear effects, we examine deep sigma-point processes and stochastic variational deep kernel learning. The final framework integrates four components: (i) a learnable physics-informed mean that represents dominant propagation trends, (ii) a convolutional encoder for bathymetry along the source-receiver track, (iii) a neural encoder for source, receiver, and frequency coordinates, and (iv) a residual SVGP layer that provides calibrated predictive uncertainty. This probabilistic digital twin facilitates the construction of sound-exposure bounds and worst-case scenarios for received levels. We further demonstrate the application of the framework to ship speed optimization, where predicted transmission loss combined with near-field source models provides sound exposure level estimates for minimizing acoustic impacts on marine mammals. The proposed framework advances uncertainty-aware digital twins for ocean acoustics and illustrates how physics-guided machine learning can support sustainable maritime operations.", "published": "2025-09-30", "categories": ["cs.LG", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2509.25730v1", "primary_category": "cs.LG"}
{"id": "2509.25311", "title": "Aspects of holographic entanglement using physics-informed-neural-networks", "authors": ["Anirudh Deb", "Yaman Sanghavi"], "summary": "We implement physics-informed-neural-networks (PINNs) to compute holographic entanglement entropy and entanglement wedge cross section. This technique allows us to compute these quantities for arbitrary shapes of the subregions in any asymptotically AdS metric. We test our computations against some known results and further demonstrate the utility of PINNs in examples, where it is not straightforward to perform such computations.", "published": "2025-09-29", "categories": ["hep-th", "cs.LG", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2509.25311v1", "primary_category": "hep-th"}
{"id": "2509.25450", "title": "Multi-patch isogeometric neural solver for partial differential equations on computer-aided design domains", "authors": ["Moritz von Tresckow", "Ion Gabriel Ion", "Dimitrios Loukrezis"], "summary": "This work develops a computational framework that combines physics-informed neural networks with multi-patch isogeometric analysis to solve partial differential equations on complex computer-aided design geometries. The method utilizes patch-local neural networks that operate on the reference domain of isogeometric analysis. A custom output layer enables the strong imposition of Dirichlet boundary conditions. Solution conformity across interfaces between non-uniform rational B-spline patches is enforced using dedicated interface neural networks. Training is performed using the variational framework by minimizing the energy functional derived after the weak form of the partial differential equation. The effectiveness of the suggested method is demonstrated on two highly non-trivial and practically relevant use-cases, namely, a 2D magnetostatics model of a quadrupole magnet and a 3D nonlinear solid and contact mechanics model of a mechanical holder. The results show excellent agreement to reference solutions obtained with high-fidelity finite element solvers, thus highlighting the potential of the suggested neural solver to tackle complex engineering problems given the corresponding computer-aided design models.", "published": "2025-09-29", "categories": ["cs.CE", "cs.AI", "cs.NA", "math.NA", "physics.comp-ph", "68T07 (Primary), 78A30 (Secondary)", "J.2; J.6; I.2.m"], "pdf_url": "http://arxiv.org/pdf/2509.25450v1", "primary_category": "cs.CE"}
{"id": "2509.25955", "title": "AIM: Adaptive Intervention for Deep Multi-task Learning of Molecular Properties", "authors": ["Mason Minot", "Gisbert Schneider"], "summary": "Simultaneously optimizing multiple, frequently conflicting, molecular properties is a key bottleneck in the development of novel therapeutics. Although a promising approach, the efficacy of multi-task learning is often compromised by destructive gradient interference, especially in the data-scarce regimes common to drug discovery. To address this, we propose AIM, an optimization framework that learns a dynamic policy to mediate gradient conflicts. The policy is trained jointly with the main network using a novel augmented objective composed of dense, differentiable regularizers. This objective guides the policy to produce updates that are geometrically stable and dynamically efficient, prioritizing progress on the most challenging tasks. We demonstrate that AIM achieves statistically significant improvements over multi-task baselines on subsets of the QM9 and targeted protein degraders benchmarks, with its advantage being most pronounced in data-scarce regimes. Beyond performance, AIM's key contribution is its interpretability; the learned policy matrix serves as a diagnostic tool for analyzing inter-task relationships. This combination of data-efficient performance and diagnostic insight highlights the potential of adaptive optimizers to accelerate scientific discovery by creating more robust and insightful models for multi-property molecular design.", "published": "2025-09-30", "categories": ["cs.LG", "cs.AI", "physics.chem-ph"], "pdf_url": "http://arxiv.org/pdf/2509.25955v1", "primary_category": "cs.LG"}
{"id": "2509.25724", "title": "Towards A Universally Transferable Acceleration Method for Density Functional Theory", "authors": ["Zhe Liu", "Yuyan Ni", "Zhichen Pu", "Qiming Sun", "Siyuan Liu", "Wen Yan"], "summary": "Recently, sophisticated deep learning-based approaches have been developed for generating efficient initial guesses to accelerate the convergence of density functional theory (DFT) calculations. While the actual initial guesses are often density matrices (DM), quantities that can convert into density matrices also qualify as alternative forms of initial guesses. Hence, existing works mostly rely on the prediction of the Hamiltonian matrix for obtaining high-quality initial guesses. However, the Hamiltonian matrix is both numerically difficult to predict and intrinsically non-transferable, hindering the application of such models in real scenarios. In light of this, we propose a method that constructs DFT initial guesses by predicting the electron density in a compact auxiliary basis representation using E(3)-equivariant neural networks. Trained on small molecules with up to 20 atoms, our model is able to achieve an average 33.3% self-consistent field (SCF) step reduction on systems up to 60 atoms, substantially outperforming Hamiltonian-centric and DM-centric models. Critically, this acceleration remains nearly constant with increasing system sizes and exhibits strong transferring behaviors across orbital basis sets and exchange-correlation (XC) functionals. To the best of our knowledge, this work represents the first and robust candidate for a universally transferable DFT acceleration method. We are also releasing the SCFbench dataset and its accompanying code to facilitate future research in this promising direction.", "published": "2025-09-30", "categories": ["physics.chem-ph", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2509.25724v1", "primary_category": "physics.chem-ph"}
{"id": "2509.25171", "title": "TR2-D2: Tree Search Guided Trajectory-Aware Fine-Tuning for Discrete Diffusion", "authors": ["Sophia Tang", "Yuchen Zhu", "Molei Tao", "Pranam Chatterjee"], "summary": "Reinforcement learning with stochastic optimal control offers a promising framework for diffusion fine-tuning, where a pre-trained diffusion model is optimized to generate paths that lead to a reward-tilted distribution. While these approaches enable optimization without access to explicit samples from the optimal distribution, they require training on rollouts under the current fine-tuned model, making them susceptible to reinforcing sub-optimal trajectories that yield poor rewards. To overcome this challenge, we introduce TRee Search Guided TRajectory-Aware Fine-Tuning for Discrete Diffusion (TR2-D2), a novel framework that optimizes reward-guided discrete diffusion trajectories with tree search to construct replay buffers for trajectory-aware fine-tuning. These buffers are generated using Monte Carlo Tree Search (MCTS) and subsequently used to fine-tune a pre-trained discrete diffusion model under a stochastic optimal control objective. We validate our framework on single- and multi-objective fine-tuning of biological sequence diffusion models, highlighting the overall effectiveness of TR2-D2 for reliable reward-guided fine-tuning in discrete sequence generation.", "published": "2025-09-29", "categories": ["cs.LG", "q-bio.BM"], "pdf_url": "http://arxiv.org/pdf/2509.25171v1", "primary_category": "cs.LG"}
{"id": "2509.25479", "title": "Discontinuous Epitope Fragments as Sufficient Target Templates for Efficient Binder Design", "authors": ["Zhenfeng Deng", "Ruijie Hou", "Ningrui Xie", "Mike Tyers", "Michał Koziarski"], "summary": "Recent advances in structure-based protein design have accelerated de novo binder generation, yet interfaces on large domains or spanning multiple domains remain challenging due to high computational cost and declining success with increasing target size. We hypothesized that protein folding neural networks (PFNNs) operate in a ``local-first'' manner, prioritizing local interactions while displaying limited sensitivity to global foldability.Guided by this hypothesis, we propose an epitope-only strategy that retains only the discontinuous surface residues surrounding the binding site. Compared to intact-domain workflows, this approach improves in silico success rates by up to 80% and reduces the average time per successful design by up to forty-fold, enabling binder design against previously intractable targets such as ClpP and ALS3. Building on this foundation, we further developed a tailored pipeline that incorporates a Monte Carlo-based evolution step to overcome local minima and a position-specific biased inverse folding step to refine sequence patterns. Together, these advances not only establish a generalizable framework for efficient binder design against structurally large and otherwise inaccessible targets, but also support the broader ``local-first'' hypothesis as a guiding principle for PFNN-based design.", "published": "2025-09-29", "categories": ["q-bio.BM", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2509.25479v1", "primary_category": "q-bio.BM"}
