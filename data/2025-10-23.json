{"id": "2510.19544", "title": "Demonstrating Real Advantage of Machine-Learning-Enhanced Monte Carlo for Combinatorial Optimization", "authors": ["Luca Maria Del Bono", "Federico Ricci-Tersenghi", "Francesco Zamponi"], "summary": "Combinatorial optimization problems are central to both practical applications and the development of optimization methods. While classical and quantum algorithms have been refined over decades, machine learning-assisted approaches are comparatively recent and have not yet consistently outperformed simple, state-of-the-art classical methods. Here, we focus on a class of Quadratic Unconstrained Binary Optimization (QUBO) problems, specifically the challenge of finding minimum energy configurations in three-dimensional Ising spin glasses. We use a Global Annealing Monte Carlo algorithm that integrates standard local moves with global moves proposed via machine learning. We show that local moves play a crucial role in achieving optimal performance. Benchmarking against Simulated Annealing and Population Annealing, we demonstrate that Global Annealing not only surpasses the performance of Simulated Annealing but also exhibits greater robustness than Population Annealing, maintaining effectiveness across problem hardness and system size without hyperparameter tuning. These results provide, to our knowledge, the first clear and robust evidence that a machine learning-assisted optimization method can exceed the capabilities of classical state-of-the-art techniques in a combinatorial optimization setting.", "published": "2025-10-22", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.LG", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2510.19544v1", "primary_category": "cond-mat.dis-nn"}
{"id": "2510.18900", "title": "Foundation Models for Discovery and Exploration in Chemical Space", "authors": ["Alexius Wadell", "Anoushka Bhutani", "Victor Azumah", "Austin R. Ellis-Mohr", "Celia Kelly", "Hancheng Zhao", "Anuj K. Nayak", "Kareem Hegazy", "Alexander Brace", "Hongyi Lin", "Murali Emani", "Venkatram Vishwanath", "Kevin Gering", "Melisa Alkan", "Tom Gibbs", "Jack Wells", "Lav R. Varshney", "Bharath Ramsundar", "Karthik Duraisamy", "Michael W. Mahoney", "Arvind Ramanathan", "Venkatasubramanian Viswanathan"], "summary": "Accurate prediction of atomistic, thermodynamic, and kinetic properties from molecular structures underpins materials innovation. Existing computational and experimental approaches lack the scalability required to efficiently navigate chemical space. Scientific foundation models trained on large unlabeled datasets offer a path toward exploring chemical space across diverse application domains. Here we develop MIST, a family of molecular foundation models with up to an order of magnitude more parameters and data than prior works. Trained using a novel tokenization scheme that comprehensively captures nuclear, electronic, and geometric information, MIST learns from a diverse range of molecules. MIST models have been fine-tuned to predict more than 400 structure -- property relationships and match or exceed state-of-the-art performance across benchmarks spanning physiology, electrochemistry, and quantum chemistry. We demonstrate the ability of these models to solve real-world problems across chemical space, including multiobjective electrolyte solvent screening, olfactory perception mapping, isotope half-life prediction, stereochemical reasoning for chiral organometallic compounds, and binary and multi-component mixture property prediction. Probing MIST models using mechanistic interpretability methods reveals identifiable patterns and trends not explicitly present in the training data, suggesting that the models learn generalizable scientific concepts. We formulate hyperparameter-penalized Bayesian neural scaling laws and use them to reduce the computational cost of model development by an order of magnitude. The methods and findings presented here represent a significant step toward accelerating materials discovery, design, and optimization using foundation models and provide valuable guidance for training compute-optimal scientific foundation models.", "published": "2025-10-20", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2510.18900v1", "primary_category": "physics.chem-ph"}
{"id": "2510.18911", "title": "Prospects for Using Artificial Intelligence to Understand Intrinsic Kinetics of Heterogeneous Catalytic Reactions", "authors": ["Andrew J. Medford", "Todd N. Whittaker", "Bjarne Kreitz", "David W. Flaherty", "John R. Kitchin"], "summary": "Artificial intelligence (AI) is influencing heterogeneous catalysis research by accelerating simulations and materials discovery. A key frontier is integrating AI with multiscale models and multimodal experiments to address the \"many-to-one\" challenge of linking intrinsic kinetics to observables. Advances in machine-learned force fields, microkinetics, and reactor modeling enable rapid exploration of chemical spaces, while operando and transient data provide unprecedented insight. Yet, inconsistent data quality and model complexity limit mechanistic discovery. Generative and agentic AI can automate model generation, quantify uncertainty, and couple theory with experiment, realizing \"self-driving models\" that produce interpretable, reproducible, and transferable understanding of catalytic systems.", "published": "2025-10-21", "categories": ["physics.chem-ph", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2510.18911v1", "primary_category": "physics.chem-ph"}
{"id": "2510.19090", "title": "Learning noisy tissue dynamics across time scales", "authors": ["Ming Han", "John Devany", "Michel Fruchart", "Margaret L. Gardel", "Vincenzo Vitelli"], "summary": "Tissue dynamics play a crucial role in biological processes ranging from wound healing to morphogenesis. However, these noisy multicellular dynamics are notoriously hard to predict. Here, we introduce a biomimetic machine learning framework capable of inferring noisy multicellular dynamics directly from experimental movies. This generative model combines graph neural networks, normalizing flows and WaveNet algorithms to represent tissues as neural stochastic differential equations where cells are edges of an evolving graph. This machine learning architecture reflects the architecture of the underlying biological tissues, substantially reducing the amount of data needed to train it compared to convolutional or fully-connected neural networks. Taking epithelial tissue experiments as a case study, we show that our model not only captures stochastic cell motion but also predicts the evolution of cell states in their division cycle. Finally, we demonstrate that our method can accurately generate the experimental dynamics of developmental systems, such as the fly wing, and cell signaling processes mediated by stochastic ERK waves, paving the way for its use as a digital twin in bioengineering and clinical contexts.", "published": "2025-10-21", "categories": ["cond-mat.soft", "cs.LG", "physics.bio-ph", "q-bio.QM"], "pdf_url": "http://arxiv.org/pdf/2510.19090v1", "primary_category": "cond-mat.soft"}
{"id": "2510.19484", "title": "KnowMol: Advancing Molecular Large Language Models with Multi-Level Chemical Knowledge", "authors": ["Zaifei Yang", "Hong Chang", "Ruibing Hou", "Shiguang Shan", "Xilin Chen"], "summary": "The molecular large language models have garnered widespread attention due to their promising potential on molecular applications. However, current molecular large language models face significant limitations in understanding molecules due to inadequate textual descriptions and suboptimal molecular representation strategies during pretraining. To address these challenges, we introduce KnowMol-100K, a large-scale dataset with 100K fine-grained molecular annotations across multiple levels, bridging the gap between molecules and textual descriptions. Additionally, we propose chemically-informative molecular representation, effectively addressing limitations in existing molecular representation strategies. Building upon these innovations, we develop KnowMol, a state-of-the-art multi-modal molecular large language model. Extensive experiments demonstrate that KnowMol achieves superior performance across molecular understanding and generation tasks.   GitHub: https://github.com/yzf-code/KnowMol   Huggingface: https://hf.co/datasets/yzf1102/KnowMol-100K", "published": "2025-10-22", "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2510.19484v1", "primary_category": "q-bio.BM"}
