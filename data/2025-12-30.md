<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [cs.LG](#cs.LG) [Total: 4]
- [math.DS](#math.DS) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Lessons from Neuroscience for AI: How integrating Actions, Compositional Structure and Episodic Memory could enable Safe, Interpretable and Human-Like AI](https://arxiv.org/abs/2512.22568)
*Rajesh P. N. Rao, Vishwas Sathish, Linxing Preston Jiang, Matthew Bryan, Prashant Rangarajan*

Main category: cs.AI

TL;DR: 本文认为，为了构建安全、可解释、类人的AI，应将动作、层次化结构和情景记忆融入到大型语言模型（LLMs）中，借鉴神经科学的预测编码模型。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs虽然在预测编码方面取得了进展，但忽略了神经科学中重要的三个组成部分：动作与生成模型的紧密结合、层次化结构和情景记忆，导致模型存在幻觉、缺乏责任感、缺乏可解释性和能源效率低下等问题。

Method: 本文结合神经科学的证据，提出了将动作（多层抽象）、层次化生成架构和情景记忆整合到LLMs中的方案，并将其与当前趋势（如链式思维推理和检索增强生成）进行比较，探讨了如何通过借鉴大脑机制来增强模型。

Result: 研究表明，整合这些缺失的组件可以解决LLMs当前的一些缺陷，例如减少幻觉、提升对概念的理解、赋予模型责任感、提高可解释性和能源效率。

Conclusion: 本文强调了脑科学与AI之间思想交流的重要性，认为重新点燃这种交流将有助于构建安全、可解释、以人为本的AI。

Abstract: The phenomenal advances in large language models (LLMs) and other foundation models over the past few years have been based on optimizing large-scale transformer models on the surprisingly simple objective of minimizing next-token prediction loss, a form of predictive coding that is also the backbone of an increasingly popular model of brain function in neuroscience and cognitive science. However, current foundation models ignore three other important components of state-of-the-art predictive coding models: tight integration of actions with generative models, hierarchical compositional structure, and episodic memory. We propose that to achieve safe, interpretable, energy-efficient, and human-like AI, foundation models should integrate actions, at multiple scales of abstraction, with a compositional generative architecture and episodic memory. We present recent evidence from neuroscience and cognitive science on the importance of each of these components. We describe how the addition of these missing components to foundation models could help address some of their current deficiencies: hallucinations and superficial understanding of concepts due to lack of grounding, a missing sense of agency/responsibility due to lack of control, threats to safety and trustworthiness due to lack of interpretability, and energy inefficiency. We compare our proposal to current trends, such as adding chain-of-thought (CoT) reasoning and retrieval-augmented generation (RAG) to foundation models, and discuss new ways of augmenting these models with brain-inspired components. We conclude by arguing that a rekindling of the historically fruitful exchange of ideas between brain science and AI will help pave the way towards safe and interpretable human-centered AI.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [2] [Integrating Wide and Deep Neural Networks with Squeeze-and-Excitation Blocks for Multi-Target Property Prediction in Additively Manufactured Fiber Reinforced Composites](https://arxiv.org/abs/2512.22397)
*Behzad Parvaresh, Rahmat K. Adesunkanmi, Adel Alaeddini*

Main category: physics.comp-ph

TL;DR: 本文提出了一种结合拉丁超立方抽样（LHS）和挤压-激发（SE）的宽深神经网络（WDNN）模型，用于高效预测增材制造连续纤维增强复合材料（CFRC-AM）的多个机械和制造性能，并实现了优于传统机器学习模型的预测精度。


<details>
  <summary>Details</summary>
Motivation: CFRC-AM的性能受制造参数影响显著，全面实验测试不可行。传统模型和规则难以准确捕捉微观结构、工艺条件与性能之间的耦合关系，因此需要一种高效且可解释的多目标预测方法。

Method: 研究人员采用LHS指导实验设计，收集了155个样品的实验数据，并利用SE-WDNN模型进行多目标回归预测。将该模型与前馈神经网络、Kolmogorov-Arnold网络、XGBoost、CatBoost和随机森林等常用机器学习模型进行比较。

Result: 提出的SE-WDNN模型在测试误差（MAPE=12.33%）方面优于其他模型，在多个目标变量上显著优于基准WDNN模型。SHAP分析表明，增强策略是影响机械性能的主要因素。

Conclusion: 该研究表明，LHS与SE-WDNN的结合能够实现高效、可解释的多目标预测，为CFRC-AM的参数选择提供指导，在机械性能和制造指标之间取得平衡。

Abstract: Continuous fiber-reinforced composite manufactured by additive manufacturing (CFRC-AM) offers opportunities for printing lightweight materials with high specific strength. However, their performance is sensitive to the interaction of process and material parameters, making exhaustive experimental testing impractical. In this study, we introduce a data-efficient, multi-input, multi-target learning approach that integrates Latin Hypercube Sampling (LHS)-guided experimentation with a squeeze-and-excitation wide and deep neural network (SE-WDNN) to jointly predict multiple mechanical and manufacturing properties of CFRC-AMs based on different manufacturing parameters. We printed and tested 155 specimens selected from a design space of 4,320 combinations using a Markforged Mark Two 3D printer. The processed data formed the input-output set for our proposed model. We compared the results with those from commonly used machine learning models, including feedforward neural networks, Kolmogorov-Arnold networks, XGBoost, CatBoost, and random forests. Our model achieved the lowest overall test error (MAPE = 12.33%) and showed statistically significant improvements over the baseline wide and deep neural network for several target variables (paired t-tests, p <= 0.05). SHapley Additive exPlanations (SHAP) analysis revealed that reinforcement strategy was the major influence on mechanical performance. Overall, this study demonstrates that the integration of LHS and SE-WDNN enables interpretable and sample-efficient multi-target predictions, guiding parameter selection in CFRC-AM with a balance between mechanical behavior and manufacturing metrics.

</details>


### [3] [PINNs for Electromagnetic Wave Propagation](https://arxiv.org/abs/2512.23396)
*Nilufer K. Bulut*

Main category: physics.comp-ph

TL;DR: 本文提出了一种混合训练策略，旨在提高基于物理信息神经网络 (PINNs) 在电磁波传播中的准确性和能量一致性，使其能够与有限差分时域 (FDTD) 方法竞争。


<details>
  <summary>Details</summary>
Motivation: 虽然 PINNs 具有无网特性和解决反问题能力，但在电磁学领域，与成熟的 FDTD 和 FEM 方法相比，其在准确性和能量指标方面存在不足，需要改进。

Method: 该研究提出了一种混合方法，通过时间步进和因果感知的加权解决了 PINNs 时间依赖性训练中的因果关系崩溃问题；应用了双阶段界面连续性损失以减轻时间步进引入的间断性；并开发了一种基于 Poynting 场的局部正则化器，以抑制损失积累和电磁波中的能量漂移。

Result: 实验结果表明，该 PINN 模型实现了平均 0.09% 的 NRMSE 和 1.01% 的 L2 误差，能量不匹配仅为 0.024%，且无需标记场数据，仅使用基于物理的残差损失进行训练。

Conclusion: 研究表明，PINNs 可以在规范的电磁学示例中实现与 FDTD 相当的结果，是一种可行的替代方案，为电磁波传播的数值模拟提供了一种新的思路。

Abstract: Physics-Informed Neural Networks (PINNs) are a methodology that aims to solve physical systems by directly embedding PDE constraints into the neural network training process. In electromagnetism, where well-established methodologies such as FDTD and FEM already exist, new methodologies are expected to provide clear advantages to be accepted. Despite their mesh-free nature and applicability to inverse problems, PINNs can exhibit deficiencies in terms of accuracy and energy metrics when compared to FDTD solutions. This study demonstrates hybrid training strategies can bring PINNs closer to FDTD-level accuracy and energy consistency.   This study presents a hybrid methodology addressing common challenges in wave propagation scenarios. The causality collapse problem in time-dependent PINN training is addressed via time marching and causality-aware weighting. In order to mitigate the discontinuities that are introduced by time marching, a two-stage interface continuity loss is applied. In order to suppress loss accumulation, which is manifested as cumulative energy drift in electromagnetic waves, a local Poynting-based regularizer has been developed.   In the developed PINN model, high field accuracy is achieved with an average 0.09\% $NRMSE$ and 1.01\% $L^2$ error over time. Energy conservation is achieved on the PINN side with only a 0.024\% relative energy mismatch in the 2D PEC cavity scenario. Training is performed without labeled field data, using only physics-based residual losses; FDTD is used solely for post-training evaluation. The results demonstrate that PINNs can achieve competitive results with FDTD in canonical electromagnetic examples and are a viable alternative.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Spectral Analysis of Hard-Constraint PINNs: The Spatial Modulation Mechanism of Boundary Functions](https://arxiv.org/abs/2512.23295)
*Yuchen Xie, Honghang Chi, Haopeng Quan, Yahui Wang, Wei Wang, Yu Ma*

Main category: cs.LG

TL;DR: 本文研究了硬约束 PINNs (HC-PINNs) 的训练动态，揭示了边界函数通过空间调制改变学习景观的机制，并提出了基于谱分析的边界函数设计框架。


<details>
  <summary>Details</summary>
Motivation: 现有理论主要关注软约束 PINNs，缺乏对硬约束 PINNs 训练动态的深入理解。硬约束 PINNs 通过试函数 ansatz 严格施加边界条件，其训练机制尚不明确。

Method: 本文建立了一个严格的 HC-PINNs 神经网络切线核 (NTK) 框架，推导了显式的核组成定律，并通过谱分析研究了 HC-PINNs 的训练动态，识别了残余核的有效秩。

Result: 研究发现，边界函数 B 充当谱滤波器，重塑神经网络的固有核的特征谱。有效残余核的秩可以作为训练收敛的确定性预测指标，优于传统的条件数。某些边界函数可能导致谱坍缩，从而导致优化停滞。

Conclusion: 本文将边界函数设计从启发式选择转变为一种基于谱优化的原则性问题，为科学机器学习中的几何硬约束提供了坚实的理论基础，并为 HC-PINNs 的设计提供了指导。

Abstract: Physics-Informed Neural Networks with hard constraints (HC-PINNs) are increasingly favored for their ability to strictly enforce boundary conditions via a trial function ansatz $\tilde{u} = A + B \cdot N$, yet the theoretical mechanisms governing their training dynamics have remained unexplored.   Unlike soft-constrained formulations where boundary terms act as additive penalties, this work reveals that the boundary function $B$ introduces a multiplicative spatial modulation that fundamentally alters the learning landscape.   A rigorous Neural Tangent Kernel (NTK) framework for HC-PINNs is established, deriving the explicit kernel composition law.   This relationship demonstrates that the boundary function $B(\vec{x})$ functions as a spectral filter, reshaping the eigenspectrum of the neural network's native kernel.   Through spectral analysis, the effective rank of the residual kernel is identified as a deterministic predictor of training convergence, superior to classical condition numbers.   It is shown that widely used boundary functions can inadvertently induce spectral collapse, leading to optimization stagnation despite exact boundary satisfaction.   Validated across multi-dimensional benchmarks, this framework transforms the design of boundary functions from a heuristic choice into a principled spectral optimization problem, providing a solid theoretical foundation for geometric hard constraints in scientific machine learning.

</details>


### [5] [PI-MFM: Physics-informed multimodal foundation model for solving partial differential equations](https://arxiv.org/abs/2512.23056)
*Min Zhu, Jingmin Sun, Zecheng Zhang, Hayden Schaeffer, Lu Lu*

Main category: cs.LG

TL;DR: 本文提出了一种名为PI-MFM的物理信息多模态基础模型框架，该框架通过直接在预训练和适应过程中强制执行控制方程，实现了高效且可迁移的偏微分方程求解。


<details>
  <summary>Details</summary>
Motivation: 现有多算子学习方法数据需求量大，且训练过程中忽略了物理信息。为了解决这些问题，并实现对不同方程族的统一物理信息目标训练，需要一种更有效的方法。

Method: PI-MFM框架接收PDE的符号表示作为输入，通过向量化导数计算自动组装PDE残差损失。该模型利用物理损失来提高鲁棒性，并采用自动微分或有限差分计算导数。此外，还实现了零样本物理信息微调，仅使用PDE残差和初始/边界条件进行适应。

Result: 在13个参数化的一维时依赖性PDE族上，PI-MFM始终优于纯数据驱动的对应物，尤其是在稀疏标记时空点、部分观测时间域或少量标记函数对的情况下。零样本微调能够快速将测试误差降低到1%左右。

Conclusion: PI-MFM提供了一条实用且可扩展的途径，实现了数据高效、可迁移的PDE求解器，为解决变化频繁的问题提供了新的可能性。

Abstract: Partial differential equations (PDEs) govern a wide range of physical systems, and recent multimodal foundation models have shown promise for learning PDE solution operators across diverse equation families. However, existing multi-operator learning approaches are data-hungry and neglect physics during training. Here, we propose a physics-informed multimodal foundation model (PI-MFM) framework that directly enforces governing equations during pretraining and adaptation. PI-MFM takes symbolic representations of PDEs as the input, and automatically assembles PDE residual losses from the input expression via a vectorized derivative computation. These designs enable any PDE-encoding multimodal foundation model to be trained or adapted with unified physics-informed objectives across equation families. On a benchmark of 13 parametric one-dimensional time-dependent PDE families, PI-MFM consistently outperforms purely data-driven counterparts, especially with sparse labeled spatiotemporal points, partially observed time domains, or few labeled function pairs. Physics losses further improve robustness against noise, and simple strategies such as resampling collocation points substantially improve accuracy. We also analyze the accuracy, precision, and computational cost of automatic differentiation and finite differences for derivative computation within PI-MFM. Finally, we demonstrate zero-shot physics-informed fine-tuning to unseen PDE families: starting from a physics-informed pretrained model, adapting using only PDE residuals and initial/boundary conditions, without any labeled solution data, rapidly reduces test errors to around 1% and clearly outperforms physics-only training from scratch. These results show that PI-MFM provides a practical and scalable path toward data-efficient, transferable PDE solvers.

</details>


### [6] [Energy-Guided Flow Matching Enables Few-Step Conformer Generation and Ground-State Identification](https://arxiv.org/abs/2512.22597)
*Guikun Xu, Xiaohan Yi, Peilin Zhao, Yatao Bian*

Main category: cs.LG

TL;DR: 本文提出了一种名为EnFlow的统一框架，它将流匹配（FM）与显式学习的能量模型相结合，通过能量引导的采样方案实现高效的低能量构象生成和精确的基态识别。


<details>
  <summary>Details</summary>
Motivation: 传统的基于物理的计算方法计算成本高昂，而现有的学习方法在生成多样性构象和可靠的能量校准、以及预测单一结构和捕捉构象变异性方面存在不足，因此需要一种能够同时解决这些问题的框架。

Method: EnFlow框架通过能量梯度引导在非高斯FM路径上进行采样，将流匹配（FM）与显式学习的能量模型耦合。学习到的能量函数进一步用于对生成的构象集合进行能量排序，从而实现准确的基态识别。

Result: 在GEOM-QM9和GEOM-Drugs数据集上的实验表明，EnFlow在仅使用1-2个ODE步骤的情况下，同时提高了生成指标并减少了基态预测误差，优于现有最先进方法。

Conclusion: EnFlow框架为分子构象生成和基态识别提供了一种高效且准确的解决方案，有望加速计算化学和药物发现领域的研究。

Abstract: Generating low-energy conformer ensembles and identifying ground-state conformations from molecular graphs remain computationally demanding with physics-based pipelines. Current learning-based approaches often suffer from a fragmented paradigm: generative models capture diversity but lack reliable energy calibration, whereas deterministic predictors target a single structure and fail to represent ensemble variability. Here we present EnFlow, a unified framework that couples flow matching (FM) with an explicitly learned energy model through an energy-guided sampling scheme defined along a non-Gaussian FM path. By incorporating energy-gradient guidance during sampling, our method steers trajectories toward lower-energy regions, substantially improving conformational fidelity, particularly in the few-step regime. The learned energy function further enables efficient energy-based ranking of generated ensembles for accurate ground-state identification. Extensive experiments on GEOM-QM9 and GEOM-Drugs demonstrate that EnFlow simultaneously improves generation metrics with 1--2 ODE-steps and reduces ground-state prediction errors compared with state-of-the-art methods.

</details>


### [7] [HELM-BERT: A Transformer for Medium-sized Peptide Property Prediction](https://arxiv.org/abs/2512.23175)
*Seungeon Lee, Takuto Koyama, Itsuki Maeda, Shigeyuki Matsumoto, Yasushi Okuno*

Main category: cs.LG

TL;DR: 本文提出了HELM-BERT，一种基于HELM表示法的肽语言模型，它在肽性质预测任务中显著优于基于SMILES的现有模型，尤其是在环肽膜渗透性和肽-蛋白质相互作用预测方面。


<details>
  <summary>Details</summary>
Motivation: 现有分子语言模型在处理复杂肽结构和化学修饰方面存在局限性，难以准确预测肽的理化性质，从而阻碍了肽药物的开发。需要一种能够有效捕捉肽单体组成和连接方式的表示方法。

Method: 研究人员基于DeBERTa构建了HELM-BERT，该模型使用分层编辑语言（HELM）表示法进行训练，并在包含39,079个化学多样性肽的语料库上进行预训练，以捕捉HELM序列中的分层依赖关系。

Result: HELM-BERT在环肽膜渗透性和肽-蛋白质相互作用预测等下游任务中，显著优于基于SMILES的现有语言模型，证明了HELM表示法在肽建模方面的优势。

Conclusion: HELM-BERT的成功表明，HELM的单体和拓扑结构感知表示法为建模治疗肽提供了显著的数据效率优势，弥补了小分子和蛋白质语言模型之间的长期差距，有望加速肽药物的开发。

Abstract: Therapeutic peptides have emerged as a pivotal modality in modern drug discovery, occupying a chemically and topologically rich space. While accurate prediction of their physicochemical properties is essential for accelerating peptide development, existing molecular language models rely on representations that fail to capture this complexity. Atom-level SMILES notation generates long token sequences and obscures cyclic topology, whereas amino-acid-level representations cannot encode the diverse chemical modifications central to modern peptide design. To bridge this representational gap, the Hierarchical Editing Language for Macromolecules (HELM) offers a unified framework enabling precise description of both monomer composition and connectivity, making it a promising foundation for peptide language modeling. Here, we propose HELM-BERT, the first encoder-based peptide language model trained on HELM notation. Based on DeBERTa, HELM-BERT is specifically designed to capture hierarchical dependencies within HELM sequences. The model is pre-trained on a curated corpus of 39,079 chemically diverse peptides spanning linear and cyclic structures. HELM-BERT significantly outperforms state-of-the-art SMILES-based language models in downstream tasks, including cyclic peptide membrane permeability prediction and peptide-protein interaction prediction. These results demonstrate that HELM's explicit monomer- and topology-aware representations offer substantial data-efficiency advantages for modeling therapeutic peptides, bridging a long-standing gap between small-molecule and protein language models.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [8] [From geometry to dynamics: Learning overdamped Langevin dynamics from sparse observations with geometric constraints](https://arxiv.org/abs/2512.23566)
*Dimitra Maoutsa*

Main category: math.DS

TL;DR: 本文提出了一种新的框架，通过几何约束引导路径增强，从稀疏观测中学习过阻尼 Langevin 动力学，即使在数据严重欠采样的情况下也能准确恢复随机动力学。


<details>
  <summary>Details</summary>
Motivation: 现有学习随机系统动力学的方法要么需要高频率的时间分辨率观测，要么依赖于仅适用于保守系统的几何论证，限制了它们能够恢复的动力学范围。如何从稀疏的时间采样数据中学习随机系统的底层动力学是一个挑战。

Method: 本文将推断问题重新表述为随机控制问题，利用几何驱动的路径增强，由系统的不变密度中的几何结构引导，重建可能的轨迹并推断底层动力学，无需假设特定的参数模型。具体地，首先近似不变密度诱导的度量，构造连接连续观测的测地线，并采样几何约束的扩散。

Result: 实验结果表明，该方法能够准确地从极度欠采样的样本中恢复过阻尼 Langevin 系统中的随机动力学，在合成基准测试中优于现有方法。

Conclusion: 该工作证明了将几何归纳偏差纳入随机系统识别方法中的有效性，为从稀疏观测中学习复杂随机系统的动力学提供了一种新途径。

Abstract: How can we learn the laws underlying the dynamics of stochastic systems when their trajectories are sampled sparsely in time? Existing methods either require temporally resolved high-frequency observations, or rely on geometric arguments that apply only to conservative systems, limiting the range of dynamics they can recover. Here, we present a new framework that reconciles these two perspectives by reformulating inference as a stochastic control problem. Our method uses geometry-driven path augmentation, guided by the geometry in the system's invariant density to reconstruct likely trajectories and infer the underlying dynamics without assuming specific parametric models. Applied to overdamped Langevin systems, our approach accurately recovers stochastic dynamics even from extremely undersampled data, outperforming existing methods in synthetic benchmarks. This work demonstrates the effectiveness of incorporating geometric inductive biases into stochastic system identification methods.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [9] [QSAR-Guided Generative Framework for the Discovery of Synthetically Viable Odorants](https://arxiv.org/abs/2512.23080)
*Tim C. Pearce, Ahmed Ibrahim*

Main category: physics.chem-ph

TL;DR: 本文提出了一种结合变分自编码器 (VAE) 和定量构效关系 (QSAR) 模型的框架，用于从有限的训练数据集中生成具有合成可行性的新型香料分子。


<details>
  <summary>Details</summary>
Motivation: 香料和调味品行业需要不断发现新的香气分子，但有效探索庞大的化学空间以识别具有所需嗅觉特性的结构仍然是一个重大挑战。现有的生成式人工智能方法通常需要大型数据集进行学习。

Method: 该框架利用 VAE 的自监督学习能力从 ChemBL 数据库学习 SMILES 语法，并通过 QSAR 模型导向的损失项来结构化潜在表示，从而根据气味概率生成新型香料分子。此外，还进行了逆合成分析以评估合成可行性。

Result: 模型生成了 100% 的语法有效结构和 94.8% 的唯一结构。生成的分子在潜在空间中表现出良好的气味可能性结构（FCD ≈ 6.96），并具有与真实香料一致的物理化学性质（平均分子量 ~158 Da，LogP ~1.67），以及可行的合成路线（平均 2.89 步）。

Conclusion: 该集成方法提供了一种新颖且系统的应用生成式人工智能探索化学空间，以发现新的候选香料分子的方法，具有实际合成可行性，为香料和调味品行业提供了新的设计思路。

Abstract: The discovery of novel odorant molecules is key for the fragrance and flavor industries, yet efficiently navigating the vast chemical space to identify structures with desirable olfactory properties remains a significant challenge. Generative artificial intelligence offers a promising approach for \textit{de novo} molecular design but typically requires large sets of molecules to learn from. To address this problem, we present a framework combining a variational autoencoder (VAE) with a quantitative structure-activity relationship (QSAR) model to generate novel odorants from limited training sets of odor molecules. The self-supervised learning capabilities of the VAE allow it to learn SMILES grammar from ChemBL database, while its training objective is augmented with a loss term derived from an external QSAR model to structure the latent representation according to odor probability. While the VAE demonstrated high internal consistency in learning the QSAR supervision signal, validation against an external, unseen ground truth dataset (Unique Good Scents) confirms the model generates syntactically valid structures (100\% validity achieved via rejection sampling) and 94.8\% unique structures. The latent space is effectively structured by odor likelihood, evidenced by a Fréchet ChemNet Distance (FCD) of $\approx$ 6.96 between generated molecules and known odorants, compared to $\approx$ 21.6 for the ChemBL baseline. Structural analysis via Bemis-Murcko scaffolds reveals that 74.4\% of candidates possess novel core frameworks distinct from the training data, indicating the model performs extensive chemical space exploration beyond simple derivatization of known odorants. Generated candidates display physicochemical properties ....

</details>
