{"id": "2511.01976", "title": "Stability of mixed-state phases under weak decoherence", "authors": ["Yifan F. Zhang", "Sarang Gopalakrishnan"], "summary": "We prove that the Gibbs states of classical, and commuting-Pauli, Hamiltonians are stable under weak local decoherence: i.e., we show that the effect of the decoherence can be locally reversed. In particular, our conclusions apply to finite-temperature equilibrium critical points and ordered low-temperature phases. In these systems the unconditional spatio-temporal correlations are long-range, and local (e.g., Metropolis) dynamics exhibits critical slowing down. Nevertheless, our results imply the existence of local \"decoders\" that undo the decoherence, when the decoherence strength is below a critical value. An implication of these results is that thermally stable quantum memories have a threshold against decoherence that remains nonzero as one approaches the critical temperature. Analogously, in diffusion models, stability of data distributions implies the existence of computationally-efficent local denoisers in the late-time generation dynamics.", "abs": "", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.LG", "math-ph", "math.MP"], "AI": {"tldr": "本文证明了在弱局部退相干下，经典和交换泡利算符的吉布斯态是稳定的，即退相干效应可以局部逆转。这表明了在临界温度下，量子记忆具有非零的退相干阈值。", "motivation": "现有量子器件实验需要更通用的相的概念，超越传统的平衡统计力学。本文旨在推广纯量子态的FDLU-等价性概念到更一般的混合态和涉及噪声、测量和反馈的演化，并将其应用于机器学习中常见的经典概率分布。", "method": "研究基于吉布斯态和弱局部退相干，证明了退相干效应可以局部逆转。通过分析空间-时间相关性和局部动力学（如 Metropolis 动力学），并引入“解码器”的概念。", "result": "证明了在退相干强度低于某个临界值时，存在局部“解码器”可以逆转退相干。在临界温度下， thermally stable 的量子记忆具有非零的退相干阈值。", "conclusion": "本文结果为理解混合态相变提供了新的视角，并对量子信息处理和机器学习中的相关问题具有重要意义，例如热稳定量子记忆和扩散模型中的数据分布。"}}
{"id": "2511.02584", "title": "Redundancy Maximization as a Principle of Associative Memory Learning", "authors": ["Mark Blümel", "Andreas C. Schneider", "Valentin Neuhaus", "David A. Ehrlich", "Marcel Graetz", "Michael Wibral", "Abdullah Makkeh", "Viola Priesemann"], "summary": "Associative memory, traditionally modeled by Hopfield networks, enables the retrieval of previously stored patterns from partial or noisy cues. Yet, the local computational principles which are required to enable this function remain incompletely understood. To formally characterize the local information processing in such systems, we employ a recent extension of information theory - Partial Information Decomposition (PID). PID decomposes the contribution of different inputs to an output into unique information from each input, redundant information across inputs, and synergistic information that emerges from combining different inputs. Applying this framework to individual neurons in classical Hopfield networks we find that below the memory capacity, the information in a neuron's activity is characterized by high redundancy between the external pattern input and the internal recurrent input, while synergy and unique information are close to zero until the memory capacity is surpassed and performance drops steeply. Inspired by this observation, we use redundancy as an information-theoretic learning goal, which is directly optimized for each neuron, dramatically increasing the network's memory capacity to 1.59, a more than tenfold improvement over the 0.14 capacity of classical Hopfield networks and even outperforming recent state-of-the-art implementations of Hopfield networks. Ultimately, this work establishes redundancy maximization as a new design principle for associative memories and opens pathways for new associative memory models based on information-theoretic goals.", "abs": "", "categories": ["cs.IT", "cs.LG", "cs.NE", "math.IT", "physics.comp-ph"], "AI": {"tldr": "本文利用信息论中的冗余度最大化原则，优化了Hopfield网络，显著提高了其存储容量，并提出了新的联想记忆模型设计思路。", "motivation": "尽管Hopfield网络在联想记忆领域取得了进展，但其底层信息处理原理仍不完全清楚。本文旨在探索控制联想记忆形成的潜在原则，并利用其来提升网络性能。", "method": "研究人员运用Partial Information Decomposition (PID)框架分析了Hopfield网络中单个神经元的的信息处理方式，将信息分解为唯一信息、冗余信息和协同信息。他们以神经元冗余度最大化为学习目标，直接优化每个神经元的权重。", "result": "实验结果表明，在经典Hopfield网络中，神经元活动的信息主要表现为外部模式输入和内部循环输入之间的冗余度高。通过冗余度最大化优化，网络存储容量提升至1.59，是经典Hopfield网络（0.14）的十倍以上，并优于最新的Hopfield网络实现。", "conclusion": "本文提出了冗余度最大化作为联想记忆的新设计原则，为基于信息论目标的联想记忆模型开辟了新的途径，并为理解大脑联想记忆机制提供了新的视角。"}}
{"id": "2511.02087", "title": "Energy Loss Functions for Physical Systems", "authors": ["Sékou-Oumar Kaba", "Kusha Sareen", "Daniel Levy", "Siamak Ravanbakhsh"], "summary": "Effectively leveraging prior knowledge of a system's physics is crucial for applications of machine learning to scientific domains. Previous approaches mostly focused on incorporating physical insights at the architectural level. In this paper, we propose a framework to leverage physical information directly into the loss function for prediction and generative modeling tasks on systems like molecules and spins. We derive energy loss functions assuming that each data sample is in thermal equilibrium with respect to an approximate energy landscape. By using the reverse KL divergence with a Boltzmann distribution around the data, we obtain the loss as an energy difference between the data and the model predictions. This perspective also recasts traditional objectives like MSE as energy-based, but with a physically meaningless energy. In contrast, our formulation yields physically grounded loss functions with gradients that better align with valid configurations, while being architecture-agnostic and computationally efficient. The energy loss functions also inherently respect physical symmetries. We demonstrate our approach on molecular generation and spin ground-state prediction and report significant improvements over baselines.", "abs": "", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种将物理信息直接融入损失函数的方法，用于预测和生成分子、自旋等物理系统的数据。该方法利用反向KL散度，将损失函数定义为数据和模型预测之间的能量差异，从而获得具有物理意义的损失函数。", "motivation": "机器学习在物理科学中的应用面临数据稀缺的挑战。本文旨在探索如何将先验的物理知识融入损失函数中，以提高模型训练效率和物理有效性，并产生更符合物理规律的配置。", "method": "该方法基于系统处于热平衡状态的假设，利用反向KL散度与玻尔兹曼分布，将损失函数定义为数据和模型预测之间的能量差异。这种方法可以重新解释传统的损失函数（如MSE）为基于能量的，但具有物理意义。", "result": "在分子生成和自旋基态预测任务中，该方法相比于基线方法取得了显著的性能提升。该方法具有架构无关性和计算效率，并且能够自然地尊重物理对称性。", "conclusion": "本文提出的能量损失函数框架为机器学习在物理科学中的应用提供了一种新的思路，通过将物理知识直接融入损失函数，可以有效地提高模型性能，并生成更符合物理规律的结果。"}}
{"id": "2511.01464", "title": "Split-Flows: Measure Transport and Information Loss Across Molecular Resolutions", "authors": ["Sander Hummerich", "Tristan Bereau", "Ullrich Köthe"], "summary": "By reducing resolution, coarse-grained models greatly accelerate molecular simulations, unlocking access to long-timescale phenomena, though at the expense of microscopic information. Recovering this fine-grained detail is essential for tasks that depend on atomistic accuracy, making backmapping a central challenge in molecular modeling. We introduce split-flows, a novel flow-based approach that reinterprets backmapping as a continuous-time measure transport across resolutions. Unlike existing generative strategies, split-flows establish a direct probabilistic link between resolutions, enabling expressive conditional sampling of atomistic structures and -- for the first time -- a tractable route to computing mapping entropies, an information-theoretic measure of the irreducible detail lost in coarse-graining. We demonstrate these capabilities on diverse molecular systems, including chignolin, a lipid bilayer, and alanine dipeptide, highlighting split-flows as a principled framework for accurate backmapping and systematic evaluation of coarse-grained models.", "abs": "", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种名为Split-Flows的新型流形模型，用于在不同分辨率之间进行概率测量传输，从而实现精确的逆映射（backmapping）并量化粗粒化过程中的信息损失。", "motivation": "粗粒化模型虽然能加速分子模拟，但会损失微观细节信息。为了在需要原子级精度的任务中恢复这些细节，需要一种有效的逆映射方法，并且需要一种量化粗粒化过程中信息损失的方法。", "method": "Split-Flows通过定义一种连续时间测量传输，将细粒度和粗粒度的密度连接起来。这种方法建立了一种直接的概率链接，允许对原子结构的条件采样，并首次实现了对映射熵的有效计算。", "result": "Split-Flows在多种分子系统（chignolin、脂质双层和丙氨酰二肽）上表现出准确的逆映射能力，并成功计算了粗粒化过程中的信息损失。", "conclusion": "Split-Flows提供了一个有原则的框架，用于精确的逆映射和对粗粒化模型的系统评估，为多尺度建模提供了一种新的信息理论视角。"}}
{"id": "2511.01913", "title": "Delta-learned force fields for nonbonded interactions: Addressing the strength mismatch between covalent-nonbonded interaction for global models", "authors": ["Leonardo Cázares-Trejo", "Marco Loreto-Silva", "Huziel E. Sauceda"], "summary": "Noncovalent interactions--vdW dispersion, hydrogen/halogen bonding, ion-$\\pi$, and $\\pi$-stacking--govern structure, dynamics, and emergent phenomena in materials and molecular systems, yet accurately learning them alongside covalent forces remains a core challenge for machine-learned force fields (MLFFs). This challenge is acute for global models that use Coulomb-matrix (CM) descriptors compared under Euclidean/Frobenius metrics in multifragment settings. We show that the mismatch between predominantly covalent force labels and the CM's overrepresentation of intermolecular features biases single-model training and degrades force-field fidelity. To address this, we introduce \\textit{$\\Delta$-sGDML}, a scale-aware formulation within the sGDML framework that explicitly decouples intra- and intermolecular physics by training fragment-specific models alongside a dedicated binding model, then composing them at inference. Across benzene dimers, host-guest complexes (C$_{60}$@buckycatcher, NO$_3^-$@i-corona[6]arene), benzene-water, and benzene-Na$^+$, \\mbox{$\\Delta$-sGDML} delivers consistent gains over a single global model, with fragment-resolved force-error reductions up to \\textbf{75\\%}, without loss of energy accuracy. Furthermore, molecular-dynamics simulations further confirm that the $\\Delta$-model yields a reliable force field for C$_{60}$@buckycatcher, producing stable trajectories across a wide range of temperatures (10-400~K), unlike the single global model, which loses stability above $\\sim$200~K. The method offers a practical route to homogenize per-fragment errors and recover reliable noncovalent physics in global MLFFs.", "abs": "", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种新的机器学习力场方法∆-sGDML，通过分离分子内和分子间物理，解决了传统全局模型中非共价相互作用学习困难的问题，显著提高了力场的准确性和稳定性。", "motivation": "传统机器学习力场在学习共价键和非共价相互作用时存在困难，尤其是在使用库仑矩阵描述符的全局模型中，分子内和分子间特征的权重不平衡导致力场精度下降。", "method": "∆-sGDML方法在sGDML框架下，通过训练片段特定的模型来学习分子内物理，并使用专门的结合模型来学习分子间物理，然后在推理时将它们组合起来。这种方法有效地解耦了分子内和分子间的物理。", "result": "在苯二聚体、C60@buckycatcher、苯-水和苯-Na+等体系中，∆-sGDML方法相比于单个全局模型，在降低片段误差（高达75%）的同时，保持了能量的准确性。分子动力学模拟表明，∆-sGDML生成的力场在更宽的温度范围内保持了C60@buckycatcher的稳定性。", "conclusion": "∆-sGDML方法提供了一种实用的途径，可以统一片段误差，并在全局机器学习力场中恢复可靠的非共价物理，为分子模拟和材料科学研究提供了新的可能性。"}}
{"id": "2511.01671", "title": "Spin-Adapted Neural Network Wavefunctions in Real Space", "authors": ["Ruichen Li", "Yuzhi Liu", "Du Jiang", "Yixiao Chen", "Xuelan Wen", "Wenrui Li", "Di He", "Liwei Wang", "Ji Chen", "Weiluo Ren"], "summary": "Spin plays a fundamental role in understanding electronic structure, yet many real-space wavefunction methods fail to adequately consider it. We introduce the Spin-Adapted Antisymmetrization Method (SAAM), a general procedure that enforces exact total spin symmetry for antisymmetric many-electron wavefunctions in real space. In the context of neural network-based quantum Monte Carlo (NNQMC), SAAM leverages the expressiveness of deep neural networks to capture electron correlation while enforcing exact spin adaptation via group representation theory. This framework provides a principled route to embed physical priors into otherwise black-box neural network wavefunctions, yielding a compact representation of correlated system with neural network orbitals. Compared with existing treatments of spin in NNQMC, SAAM is more accurate and efficient, achieving exact spin purity without any additional tunable hyperparameters. To demonstrate its effectiveness, we apply SAAM to study the spin ladder of iron-sulfur clusters, a long-standing challenge for many-body methods due to their dense spectrum of nearly degenerate spin states. Our results reveal accurate resolution of low-lying spin states and spin gaps in [Fe$_2$S$_2$] and [Fe$_4$S$_4$] clusters, offering new insights into their electronic structures. In sum, these findings establish SAAM as a robust, hyperparameter-free standard for spin-adapted NNQMC, particularly for strongly correlated systems.", "abs": "", "categories": ["physics.chem-ph", "cs.AI"], "AI": {"tldr": "本文提出了一种名为SAAM（Spin-Adapted Antisymmetrization Method）的新方法，它将自旋信息直接编码到实空间神经网络波函数中，无需额外可调参数，从而更准确高效地处理强关联体系的自旋。", "motivation": "现有神经网络量子蒙特卡洛（NNQMC）方法通常难以准确处理自旋，导致低能态错误、激发态失序等问题。为了解决这些问题，需要一种更准确且高效的自旋适应方法。", "method": "SAAM利用群表示理论，在神经网络轨道（NNO）中构建自旋函数，强制执行精确的自旋对称性，同时保留空间相关性的表达能力。该方法将空间部分建模为强大的神经网络轨道，从而在NNQMC框架内实现准确的自旋适应。", "result": "SAAM在铁硫簇的自旋阶梯研究中表现出优异的性能，准确地解析了低能自旋态和自旋间隙，并为这些体系的电子结构提供了新的见解。此外，在双自由基体系的单重态-三重态间隙计算和碳二聚体的激发态计算中也取得了高精度预测。", "conclusion": "SAAM作为一种无超参数的自旋适应NNQMC标准，为研究强关联体系提供了强大的工具，并有望促进对复杂电子结构的更深入理解。该方法还为NNO提供了化学解释，自然地定义了核心/活性区域。"}}
{"id": "2511.01946", "title": "COFAP: A Universal Framework for COFs Adsorption Prediction through Designed Multi-Modal Extraction and Cross-Modal Synergy", "authors": ["Zihan Li", "Mingyang Wan", "Mingyu Gao", "Zhongshan Chen", "Xiangke Wang", "Feifan Zhang"], "summary": "Covalent organic frameworks (COFs) are promising adsorbents for gas adsorption and separation, while identifying the optimal structures among their vast design space requires efficient high-throughput screening. Conventional machine-learning predictors rely heavily on specific gas-related features. However, these features are time-consuming and limit scalability, leading to inefficiency and labor-intensive processes. Herein, a universal COFs adsorption prediction framework (COFAP) is proposed, which can extract multi-modal structural and chemical features through deep learning, and fuse these complementary features via cross-modal attention mechanism. Without Henry coefficients or adsorption heat, COFAP sets a new SOTA by outperforming previous approaches on hypoCOFs dataset. Based on COFAP, we also found that high-performing COFs for separation concentrate within a narrow range of pore size and surface area. A weight-adjustable prioritization scheme is also developed to enable flexible, application-specific ranking of candidate COFs for researchers. Superior efficiency and accuracy render COFAP directly deployable in crystalline porous materials.", "abs": "", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.chem-ph"], "AI": {"tldr": "本文提出了一种名为COFAP的通用框架，用于预测共价有机骨架（COFs）的吸附性能。该框架通过深度学习提取多模态结构和化学特征，并利用交叉模态注意力机制融合这些特征，无需亨利系数或吸附热即可实现高性能。", "motivation": "传统的机器学习预测器依赖于特定的气体相关特征，耗时且难以扩展。为了解决COFs设计空间庞大、高通量筛选效率低下的问题，需要一种更通用、更高效的预测方法。", "method": "COFAP框架通过深度学习提取COFs的多模态结构和化学特征，并利用交叉模态注意力机制融合这些特征。该框架无需亨利系数或吸附热，即可进行吸附性能预测。", "result": "COFAP在hypoCOFs数据集上取得了最先进的性能（SOTA），优于先前的方法。研究还发现，高性能COFs的孔径和表面积集中在较窄的范围内。", "conclusion": "COFAP具有优越的效率和准确性，可以直接应用于晶体多孔材料的筛选和设计，为研究人员提供灵活的应用特定COFs排序方案，加速了COFs材料的发现和优化。"}}
{"id": "2511.02003", "title": "Bulk-boundary decomposition of neural networks", "authors": ["Donghee Lee", "Hye-Sung Lee", "Jaeok Yi"], "summary": "We present the bulk-boundary decomposition as a new framework for understanding the training dynamics of deep neural networks. Starting from the stochastic gradient descent formulation, we show that the Lagrangian can be reorganized into a data-independent bulk term and a data-dependent boundary term. The bulk captures the intrinsic dynamics set by network architecture and activation functions, while the boundary reflects stochastic interactions from training samples at the input and output layers. This decomposition exposes the local and homogeneous structure underlying deep networks. As a natural extension, we develop a field-theoretic formulation of neural dynamics based on this decomposition.", "abs": "", "categories": ["cs.LG", "cond-mat.dis-nn", "hep-ph"], "AI": {"tldr": "本文提出了一种新的框架——块-边界分解(BBD)，用于理解深度神经网络的训练动态。该框架将训练Lagrangian分解为由网络架构决定的数据无关的“块”和由训练样本决定的数据相关的“边界”，揭示了深度网络中潜在的局部和同质结构。", "motivation": "现有研究对深度学习的理解仍不清晰，且缺乏对神经网络内在局部性的深入研究。虽然有一些基于物理学的解释，但缺乏有效的分析框架，尤其是在处理非局部相互作用时。", "method": "从随机梯度下降公式出发，将训练Lagrangian分解为数据无关的“块”项和数据相关的“边界”项。“块”反映了网络架构和激活函数决定的内在动态，“边界”反映了训练样本在输入和输出层产生的随机相互作用。在此基础上，构建了基于BBD的神经网络动态的场论形式。", "result": "BBD框架揭示了深度网络中潜在的局部和同质结构，使得能够独立分析架构和统计贡献。块部分表现出局部性、平移对称性和沿深度维度的方向各向异性。", "conclusion": "BBD提供了一个统一的理论基础，将深度学习中的优化、泛化和信息传播与场论和统计物理的组织原则联系起来，为理解深度学习的运作机制提供了新的视角。"}}
{"id": "2511.01037", "title": "Binary perceptron computational gap -- a parametric fl RDT view", "authors": ["Mihailo Stojnic"], "summary": "Recent studies suggest that asymmetric binary perceptron (ABP) likely exhibits the so-called statistical-computational gap characterized with the appearance of two phase transitioning constraint density thresholds: \\textbf{\\emph{(i)}} the \\emph{satisfiability threshold} $\\alpha_c$, below/above which ABP succeeds/fails to operate as a storage memory; and \\textbf{\\emph{(ii)}} \\emph{algorithmic threshold} $\\alpha_a$, below/above which one can/cannot efficiently determine ABP's weight so that it operates as a storage memory.   We consider a particular parametric utilization of \\emph{fully lifted random duality theory} (fl RDT) [85] and study its potential ABP's algorithmic implications. A remarkable structural parametric change is uncovered as one progresses through fl RDT lifting levels. On the first two levels, the so-called $\\c$ sequence -- a key parametric fl RDT component -- is of the (natural) decreasing type. A change of such phenomenology on higher levels is then connected to the $\\alpha_c$ -- $\\alpha_a$ threshold change. Namely, on the second level concrete numerical values give for the critical constraint density $\\alpha=\\alpha_c\\approx 0.8331$. While progressing through higher levels decreases this estimate, already on the fifth level we observe a satisfactory level of convergence and obtain $\\alpha\\approx 0.7764$. This allows to draw two striking parallels: \\textbf{\\emph{(i)}} the obtained constraint density estimate is in a remarkable agrement with range $\\alpha\\in (0.77,0.78)$ of clustering defragmentation (believed to be responsible for failure of locally improving algorithms) [17,88]; and \\textbf{\\emph{(ii)}} the observed change of $\\c$ sequence phenomenology closely matches the one of the negative Hopfield model for which the existence of efficient algorithms that closely approach similar type of threshold has been demonstrated recently [87].", "abs": "", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT", "math.PR"], "AI": {"tldr": "本文利用fully lifted random duality theory (fl RDT) 研究了二元感知器的统计-计算差距，揭示了算法阈值与约束密度之间的关系，并将其与聚类碎片化和负霍夫菲德模型联系起来。", "motivation": "近年来，二元感知器（ABP）被认为存在统计-计算差距，即存在满足性和算法阈值。本文旨在利用fl RDT理论研究ABP的算法特性，并探索其阈值行为。", "method": "本文采用fully lifted random duality theory (fl RDT) 的参数化利用方法，研究了ABP的算法含义。通过分析fl RDT的提升层级，观察了c序列的变化，并将其与算法阈值αa和满足性阈值αc联系起来。", "result": "研究发现，随着fl RDT提升层级的增加，约束密度估计值逐渐收敛至α≈0.7764。该值与聚类碎片化范围α∈(0.77,0.78)相符，并且c序列的变化与负霍夫菲德模型相似。", "conclusion": "本文的研究结果表明，fl RDT理论可以有效地分析二元感知器的算法特性，并揭示了算法阈值与约束密度之间的关系。这些发现为理解二元感知器的行为以及设计更有效的机器学习算法提供了新的视角。"}}
{"id": "2511.00746", "title": "Correspondence Between Ising Machines and Neural Networks", "authors": ["Andrew G. Moore"], "summary": "Computation with the Ising model is central to future computing technologies like quantum annealing, adiabatic quantum computing, and thermodynamic classical computing. Traditionally, computed values have been equated with ground states. This paper generalizes computation with ground states to computation with spin averages, allowing computations to take place at high temperatures. It then introduces a systematic correspondence between Ising devices and neural networks and a simple method to run trained feed-forward neural networks on Ising-type hardware. Finally, a mathematical proof is offered that these implementations are always successful.", "abs": "", "categories": ["cond-mat.dis-nn", "cs.ET", "cs.LG", "quant-ph"], "AI": {"tldr": "本文提出了一种将训练好的前馈神经网络映射到Ising模型的系统方法，并提供了数学证明，表明这种映射在一定条件下能够保证计算的正确性。该方法允许在较高温度下进行计算，从而扩展了Ising模型在计算中的应用。", "motivation": "Ising模型在未来的计算技术中扮演着重要角色，但设计Ising系统执行计算仍然具有挑战性。神经网络无处不在，而Ising模型与神经网络之间的联系尚未得到充分研究和严格证明。本文旨在弥补这一差距，探索如何在Ising硬件上运行神经网络。", "method": "本文将训练好的神经网络的参数映射到Ising哈密顿量的系数，并观察Ising系统的自旋平均值来提取计算结果。该方法推广了传统基于低温的Ising计算，允许在较高温度下进行概率性、容错计算。特别地，针对浅tanh网络在高温度下的实现和深sign网络在低温下的实现，提供了具体的实现方法和证明。", "result": "证明了如果将训练好的二元输入/输出神经网络的参数映射到Ising哈密顿量的系数，则结果的Ising系统将表现得像该神经网络。通过观察tanh神经网络和Ising模型平均场近似之间的误差，证明了在合适的参数下，Ising系统可以复制神经网络的行为。", "conclusion": "本文提供了一种将神经网络部署到Ising硬件上的可行方法，为量子退火、经典计算等新兴计算技术提供了新的思路。该研究表明，Ising模型可以作为一种通用的物理基础方法，用于解决NP-complete组合优化问题，并为边缘计算设备的设计提供了新的可能性。"}}
{"id": "2511.02769", "title": "STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation", "authors": ["Bum Chul Kwon", "Ben Shapira", "Moshiko Raboh", "Shreyans Sethi", "Shruti Murarka", "Joseph A Morrone", "Jianying Hu", "Parthasarathy Suryanarayanan"], "summary": "The chemical space of drug-like molecules is vast, motivating the development of generative models that must learn broad chemical distributions, enable conditional generation by capturing structure-property representations, and provide fast molecular generation. Meeting the objectives depends on modeling choices, including the probabilistic modeling approach, the conditional generative formulation, the architecture, and the molecular input representation. To address the challenges, we present STAR-VAE (Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder), a scalable latent-variable framework with a Transformer encoder and an autoregressive Transformer decoder. It is trained on 79 million drug-like molecules from PubChem, using SELFIES to guarantee syntactic validity. The latent-variable formulation enables conditional generation: a property predictor supplies a conditioning signal that is applied consistently to the latent prior, the inference network, and the decoder. Our contributions are: (i) a Transformer-based latent-variable encoder-decoder model trained on SELFIES representations; (ii) a principled conditional latent-variable formulation for property-guided generation; and (iii) efficient finetuning with low-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation with limited property and activity data. On the GuacaMol and MOSES benchmarks, our approach matches or exceeds baselines, and latent-space analyses reveal smooth, semantically structured representations that support both unconditional exploration and property-aware generation. On the Tartarus benchmarks, the conditional model shifts docking-score distributions toward stronger predicted binding. These results suggest that a modernized, scale-appropriate VAE remains competitive for molecular generation when paired with principled conditioning and parameter-efficient finetuning.", "abs": "", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "AI": {"tldr": "STAR-VAE是一种基于Transformer的潜在变量自编码器，通过结合自回归解码器和低秩适配器（LoRA）实现了可扩展且可控的分子生成，在多个基准测试中表现出色。", "motivation": "化学空间巨大且复杂，需要能够学习广泛化学分布、支持条件生成并实现快速分子生成的生成模型，同时解决现有模型在分布学习与目标导向任务整合、大规模数据集处理和数据稀缺条件下的挑战。", "method": "STAR-VAE采用Transformer编码器和自回归Transformer解码器，在7900万个来自PubChem的药物样分子数据集上进行训练，使用SELFIES表示保证语法有效性。通过潜在变量公式实现条件生成，利用低秩适配器（LoRA）进行高效微调。", "result": "STAR-VAE在GuacaMol和MOSES基准测试中达到或超过基线性能，在Tartarus基准测试中，条件模型将对接分数分布向更强的预测结合方向移动，且潜在空间分析显示出平滑且语义结构化的表示。", "conclusion": "STAR-VAE证明了在结合了原则性条件控制和参数高效微调的情况下，现代化的、规模适当的VAE仍然是分子生成的一种有竞争力的选择。"}}
