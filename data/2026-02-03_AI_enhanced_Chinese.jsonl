{"id": "2602.02281", "title": "Backpropagation as Physical Relaxation: Exact Gradients in Finite Time", "authors": ["Antonino Emanuele Scurria"], "summary": "Backpropagation, the foundational algorithm for training neural networks, is typically understood as a symbolic computation that recursively applies the chain rule. We show it emerges exactly as the finite-time relaxation of a physical dynamical system. By formulating feedforward inference as a continuous-time process and applying Lagrangian theory of non-conservative systems to handle asymmetric interactions, we derive a global energy functional on a doubled state space encoding both activations and sensitivities. The saddle-point dynamics of this energy perform inference and credit assignment simultaneously through local interactions. We term this framework ''Dyadic Backpropagation''. Crucially, we prove that unit-step Euler discretization, the natural timescale of layer transitions, recovers standard backpropagation exactly in precisely 2L steps for an L-layer network, with no approximations. Unlike prior energy-based methods requiring symmetric weights, asymptotic convergence, or vanishing perturbations, our framework guarantees exact gradients in finite time. This establishes backpropagation as the digitally optimized shadow of a continuous physical relaxation, providing a rigorous foundation for exact gradient computation in analog and neuromorphic substrates where continuous dynamics are native.", "abs": "", "categories": ["cs.LG", "cs.AI", "cs.NE", "physics.class-ph", "physics.comp-ph"], "AI": {"tldr": "本文将反向传播算法解释为物理系统在有限时间内的弛豫过程，并证明了标准的Euler离散化可以精确地恢复反向传播算法，无需近似。", "motivation": "传统的反向传播算法在物理现实中难以解释，因为它需要拓扑上与推理不同的反向传递、非局部误差信号和同步全局时钟。本文旨在解决反向传播算法与物理系统之间的差距，并理解精确的信贷分配如何通过局部交互和连续弛豫从系统动力学中涌现。", "method": "作者将前馈推理视为连续时间过程，并应用非保守系统的拉格朗日理论，推导出一个全局能量泛函，该泛函编码了激活和敏感度。通过对该能量泛函进行单位步长Euler离散化，并证明其在2L步内精确恢复标准反向传播算法。", "result": "证明了标准反向传播算法是连续物理弛豫的数字优化版本，并且在有限时间内可以获得精确梯度，无需对称权重、渐近收敛或消失扰动。", "conclusion": "本文为精确梯度计算提供了严格的理论基础，为模拟和神经形态基底中的连续动力学提供了新的视角，并揭示了深度学习与物理定律之间的深刻联系。"}}
{"id": "2602.01941", "title": "FluxNet: Learning Capacity-Constrained Local Transport Operators for Conservative and Bounded PDE Surrogates", "authors": ["Zishuo Lan", "Junjie Li", "Lei Wang", "Jincheng Wang"], "summary": "Autoregressive learning of time-stepping operators offers an effective approach to data-driven PDE simulation on grids. For conservation laws, however, long-horizon rollouts are often destabilized when learned updates violate global conservation and, in many applications, additional state bounds such as nonnegative mass and densities or concentrations constrained to [0,1]. Enforcing these coupled constraints via direct next-state regression remains difficult. We introduce a framework for learning conservative transport operators on regular grids, inspired by lattice Boltzmann-style discrete-velocity transport representations. Instead of predicting the next state, the model outputs local transport operators that update cells through neighborhood exchanges, guaranteeing discrete conservation by construction. For bounded quantities, we parameterize transport within a capacity-constrained feasible set, enforcing bounds structurally rather than by post-hoc clipping. We validate FluxNet on 1D convection-diffusion, 2D shallow water equations, 1D traffic flow, and 2D spinodal decomposition. Experiments on shallow-water equations and traffic flow show improved rollout stability and physical consistency over strong baselines. On phase-field spinodal decomposition, the method enables large time-steps with long-range transport, accelerating simulation while preserving microstructure evolution in both pointwise and statistical measures.", "abs": "", "categories": ["cond-mat.mtrl-sci", "cs.CE", "cs.LG", "physics.comp-ph"], "AI": {"tldr": "FluxNet是一种新的框架，用于学习保守且受限的偏微分方程(PDE)代理，它通过学习局部传输算子来保证离散的守恒性，并结构化地强制执行状态边界。", "motivation": "传统的基于自回归神经网络的PDE模拟在长时间演化中容易出现守恒性漂移和状态边界违规问题，现有的软约束和后处理校正方法无法完全解决这些问题。", "method": "FluxNet通过学习容量约束的局部传输算子来解决这个问题。模型输出局部传输算子，通过邻域交换更新单元，从而保证离散的守恒性。对于受限量，参数化传输在容量约束的可行集内，结构化地强制执行边界。", "result": "FluxNet在1D对流扩散、2D浅水方程、1D交通流和2D自旋分解等问题上进行了验证，在浅水方程和交通流问题上显示出比强基线更好的演化稳定性与物理一致性。在自旋分解问题上，该方法能够使用较大的时间步长进行长程传输，同时保留微观结构的演化。", "conclusion": "FluxNet提供了一种有效的方法来构建保守且受限的PDE代理，通过结构化地保证守恒性和边界，可以加速模拟并提高预测的物理可靠性。"}}
{"id": "2602.00378", "title": "Parametrization of subgrid scales in long-term simulations of the shallow-water equations using machine learning and convex limiting", "authors": ["Md Amran Hossan Mojamder", "Zhihang Xu", "Min Wang", "Ilya Timofeyev"], "summary": "We present a method for parametrizing sub-grid processes in the Shallow Water equations. We define coarse variables and local spatial averages and use a feed-forward neural network to learn sub-grid fluxes. Our method results in a local parametrization that uses a four-point computational stencil, which has several advantages over globally coupled parametrizations. We demonstrate numerically that our method improves energy balance in long-term turbulent simulations and also accurately reproduces individual solutions. The neural network parametrization can be easily combined with flux limiting to reduce oscillations near shocks. More importantly, our method provides reliable parametrizations, even in dynamical regimes that are not included in the training data.", "abs": "", "categories": ["physics.flu-dyn", "cs.LG", "physics.ao-ph", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种利用机器学习和凸限的方法，对浅水方程中的亚网格过程进行参数化，该方法在长时模拟中提高了能量平衡，并能准确重现单个解。", "motivation": "气候模型由于计算资源限制，无法完全解析所有重要的物理过程，因此需要参数化方法来近似未解析的亚网格过程。传统的参数化方法可能引入不确定性和偏差，而机器学习提供了一种学习改进参数化的有前景的方法。", "method": "研究人员使用前馈神经网络学习亚网格通量，定义了粗变量和局部空间平均值，并采用四点计算模板进行局部参数化。该方法结合了神经网络参数化和凸限，以减少冲击波附近的振荡。", "result": "数值结果表明，该方法提高了长时湍流模拟中的能量平衡，并准确地重现了单个解。该神经网络参数化即使在训练数据之外的动态状态下也能提供可靠的参数化。", "conclusion": "该方法提供了一种有效且可靠的亚网格参数化方法，尤其适用于需要处理复杂非线性映射和快速评估的大规模气候和地球物理模拟，并且具有良好的泛化能力。"}}
{"id": "2602.01176", "title": "Multi-Fidelity Physics-Informed Neural Networks with Bayesian Uncertainty Quantification and Adaptive Residual Learning for Efficient Solution of Parametric Partial Differential Equations", "authors": ["Olaf Yunus Laitinen Imanov"], "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful paradigm for solving partial differential equations (PDEs) by embedding physical laws directly into neural network training. However, solving high-fidelity PDEs remains computationally prohibitive, particularly for parametric systems requiring multiple evaluations across varying parameter configurations. This paper presents MF-BPINN, a novel multi-fidelity framework that synergistically combines physics-informed neural networks with Bayesian uncertainty quantification and adaptive residual learning. Our approach leverages abundant low-fidelity simulations alongside sparse high-fidelity data through a hierarchical neural architecture that learns nonlinear correlations across fidelity levels. We introduce an adaptive residual network with learnable gating mechanisms that dynamically balances linear and nonlinear fidelity discrepancies. Furthermore, we develop a rigorous Bayesian framework employing Hamiltonian Monte Carlo.", "abs": "", "categories": ["cs.LG", "math.NA", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种名为MF-BPINN的新型多保真物理信息神经网络框架，该框架结合了物理信息神经网络、贝叶斯不确定性量化和自适应残差学习，以高效求解参数化偏微分方程。", "motivation": "求解高保真偏微分方程，尤其是在参数化系统中，计算成本高昂。现有方法在多保真建模和贝叶斯不确定性量化方面存在局限性，例如固定相关模型和缺乏全面的不确定性分解。", "method": "MF-BPINN框架采用分层神经网络架构，利用丰富的低保真模拟和稀疏的高保真数据，学习保真级别之间的非线性相关性。引入自适应残差网络，动态平衡线性与非线性保真差异。并采用哈密顿蒙特卡洛采样进行贝叶斯框架，量化随机和认知不确定性。", "result": "在Burgers方程、Navier-Stokes方程和参数化热传递等基准PDE上的实验表明，MF-BPINN在降低计算成本73-86%的同时，实现了与高保真PINN相当的精度，平均相对误差低于2.1%，且95%置信区间得到蒙特卡洛真实值的验证。在湍流流动模拟中，将求解时间从48.7小时减少到6.9小时。", "conclusion": "MF-BPINN提供了一种高效且可靠的求解参数化偏微分方程的方法，具有广泛的科学计算应用前景，并为多保真机器学习和科学机器学习领域提供了新的思路。"}}
{"id": "2602.02310", "title": "FragmentFlow: Scalable Transition State Generation for Large Molecules", "authors": ["Ron Shprints", "Peter Holderrieth", "Juno Nam", "Rafael Gómez-Bombarelli", "Tommi Jaakkola"], "summary": "Transition states (TSs) are central to understanding and quantitatively predicting chemical reactivity and reaction mechanisms. Although traditional TS generation methods are computationally expensive, recent generative modeling approaches have enabled chemically meaningful TS prediction for relatively small molecules. However, these methods fail to generalize to practically relevant reaction substrates because of distribution shifts induced by increasing molecular sizes. Furthermore, TS geometries for larger molecules are not available at scale, making it infeasible to train generative models from scratch on such molecules. To address these challenges, we introduce FragmentFlow: a divide-and-conquer approach that trains a generative model to predict TS geometries for the reactive core atoms, which define the reaction mechanism. The full TS structure is then reconstructed by re-attaching substituent fragments to the predicted core. By operating on reactive cores, whose size and composition remain relatively invariant across molecular contexts, FragmentFlow mitigates distribution shifts in generative modeling. Evaluated on a new curated dataset of reactions involving reactants with up to 33 heavy atoms, FragmentFlow correctly identifies 90% of TSs while requiring 30% fewer saddle-point optimization steps than classical initialization schemes. These results point toward scalable TS generation for high-throughput reactivity studies.", "abs": "", "categories": ["physics.chem-ph", "cs.AI"], "AI": {"tldr": "FragmentFlow是一种新的过渡态几何生成方法，通过将分子分解为反应核心和取代基，解决了大分子生成模型泛化能力差的问题，并显著减少了优化步骤。", "motivation": "传统过渡态生成方法计算成本高昂，现有生成模型在处理大分子时由于分布偏移而失效，缺乏大规模大分子过渡态数据进行训练。", "method": "FragmentFlow将分子分解为反应核心和取代基，训练生成模型预测反应核心的过渡态几何结构，然后将取代基重新连接到预测的核心上。这种方法将生成任务限制在反应核心上，反应核心的尺寸和组成在不同分子环境中相对不变。", "result": "在包含多达33个重原子反应的新数据集上，FragmentFlow能够正确识别90%的过渡态，并且所需的鞍点优化步骤比传统方法少30%。", "conclusion": "FragmentFlow为大规模反应活性研究提供了可扩展的过渡态生成方法，有望加速化学反应的高通量筛选和新型功能材料的设计。"}}
{"id": "2602.02128", "title": "Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics", "authors": ["Nima Shoghi", "Yuxuan Liu", "Yuning Shen", "Rob Brekelmans", "Pan Li", "Quanquan Gu"], "summary": "Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.", "abs": "", "categories": ["cs.LG", "cs.AI", "physics.bio-ph", "q-bio.BM", "q-bio.QM"], "AI": {"tldr": "STAR-MD是一种新型的SE(3)-equivariant扩散模型，通过联合时空注意力机制，实现了在微秒尺度上生成高质量蛋白质轨迹，显著扩展了蛋白质动力学模拟的时间范围。", "motivation": "传统的分子动力学模拟计算成本高昂，限制了对生物学相关时间尺度的研究。现有的生成模型在长程生成方面存在架构限制、误差累积和时空动态建模不足的问题，亟需一种能够生成更长时间尺度、更高质量蛋白质轨迹的模型。", "method": "STAR-MD采用因果扩散变换器，并引入了联合时空注意力机制，能够高效地捕捉复杂的时空依赖关系，避免了现有方法的内存瓶颈。该模型利用SE(3)-equivariant表示来保证物理合理性，并通过自回归扩散过程生成蛋白质轨迹。", "result": "STAR-MD在ATLAS基准测试中实现了最先进的性能，显著提高了构象覆盖率、结构有效性和动态保真度。它成功地生成了基线方法无法稳定生成的微秒级轨迹，并在整个扩展回滚过程中保持了高结构质量。", "conclusion": "STAR-MD的联合时空建模能力为在生物学相关时间尺度上进行鲁棒的动力学模拟铺平了道路，加速了蛋白质功能探索，并揭示了当前模型在长程生成方面的局限性。"}}
{"id": "2602.00663", "title": "SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent", "authors": ["Fabian P. Krüger", "Andrea Hunklinger", "Adrian Wolny", "Tim J. Adler", "Igor Tetko", "Santiago David Villalba"], "summary": "Optimizing the structure of molecules to achieve desired properties is a central bottleneck across the chemical sciences, particularly in the pharmaceutical industry where it underlies the discovery of new drugs. Since molecular property evaluation often relies on costly and rate-limited oracles, such as experimental assays, molecular optimization must be highly sample-efficient. To address this, we introduce SEISMO, an LLM agent that performs strictly online, inference-time molecular optimization, updating after every oracle call without the need for population-based or batched learning. SEISMO conditions each proposal on the full optimization trajectory, combining natural-language task descriptions with scalar scores and, when available, structured explanatory feedback. Across the Practical Molecular Optimization benchmark of 23 tasks, SEISMO achieves a 2-3 times higher area under the optimisation curve than prior methods, often reaching near-maximal task scores within 50 oracle calls. Our additional medicinal-chemistry tasks show that providing explanatory feedback further improves efficiency, demonstrating that leveraging domain knowledge and structured information is key to sample-efficient molecular optimization.", "abs": "", "categories": ["cs.AI", "cs.LG", "q-bio.BM"], "AI": {"tldr": "SEISMO是一个基于LLM的分子优化代理，通过考虑优化轨迹，显著提高了样本效率，在多个任务中实现了比现有方法高2-3倍的优化曲线下面积。", "motivation": "分子优化是化学科学的核心瓶颈，尤其是在药物发现中。由于分子性质评估通常依赖于昂贵且速率受限的实验，因此需要高度样本效率的优化方法。", "method": "SEISMO采用一种严格的在线推理时分子优化方法，在每次评估后更新，无需基于种群或批处理学习。它将自然语言任务描述、标量分数和可用的结构化解释性反馈结合起来，并基于完整的优化轨迹进行提案。", "result": "在Practical Molecular Optimization (PMO)基准测试的23个任务中，SEISMO的优化曲线下面积比先前方法高2-3倍，通常在50次评估次数内达到接近最大化的任务分数。提供解释性反馈进一步提高了效率。", "conclusion": "利用领域知识和结构化信息对于样本高效的分子优化至关重要。SEISMO展示了LLM在分子优化中的潜力，并为未来开发更高效的药物发现工具提供了方向。"}}
{"id": "2602.02320", "title": "A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method", "authors": ["Feiyang Cai", "Guijuan He", "Yi Hu", "Jingjing Wang", "Joshua Luo", "Tianyu Zhu", "Srikanth Pilla", "Gang Li", "Ling Liu", "Feng Luo"], "summary": "Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.", "abs": "", "categories": ["cs.CL", "cs.AI", "q-bio.BM"], "AI": {"tldr": "本文提出了一种自动化的框架，用于生成大规模的分子结构-语言描述数据集。该数据集包含约16.3万个分子-描述对，并经过严格验证，具有98.6%的描述精度，为分子-语言对齐和化学任务提供了可靠的基础。", "motivation": "现有的大型语言模型（LLMs）在化学领域应用受限，主要原因是缺乏高质量的、结构导向的分子-语言描述数据集。构建此类数据集成本高昂，难以实现大规模化。", "method": "该研究基于规则化的化学命名解析器，将IUPAC名称解析为结构化的XML元数据，明确编码分子结构。然后，利用该元数据引导LLMs生成准确的自然语言描述，从而实现自动化的数据集构建。", "result": "构建了一个包含约16.3万个分子-描述对的大规模数据集。通过LLM和专家评估，数据集的描述精度达到了98.6%。", "conclusion": "该研究提出的数据集为分子-语言对齐提供了可靠的基础，并且该自动化的标注方法易于扩展到更大的数据集和更广泛的化学任务，有望推动化学领域LLMs的应用。"}}
{"id": "2602.00782", "title": "Controlling Repetition in Protein Language Models", "authors": ["Jiahao Zhang", "Zeqing Zhang", "Di Wang", "Lijie Hu"], "summary": "Protein language models (PLMs) have enabled advances in structure prediction and de novo protein design, yet they frequently collapse into pathological repetition during generation. Unlike in text, where repetition merely reduces readability, in proteins it undermines structural confidence and functional viability. To unify this problem, we present the first systematic study of repetition in PLMs. We first propose quantitative metrics to characterize motif-level and homopolymer repetition and then demonstrate their negative impact on folding reliability. To address this challenge, we propose UCCS (Utility-Controlled Contrastive Steering), which steers protein generation with a constrained dataset. Instead of naively contrasting high- vs. low-repetition sequences, we construct contrastive sets that maximize differences in repetition while tightly controlling for structural utility. This disentanglement yields steering vectors that specifically target repetition without degrading foldability. Injected at inference, these vectors consistently reduce repetition without retraining or heuristic decoding. Experiments with ESM-3 and ProtGPT2 in CATH, UniRef50, and SCOP show that our method outperforms decoding penalties and other baselines, substantially lowering repetition while preserving AlphaFold confidence scores. Our results establish repetition control as a central challenge for PLMs and highlight dataset-guided steering as a principled approach for reliable protein generation.", "abs": "", "categories": ["q-bio.BM", "cs.AI"], "AI": {"tldr": "本文系统研究了蛋白质语言模型（PLMs）中病理性的重复问题，并提出了一种名为UCCS（Utility-Controlled Contrastive Steering）的新方法，通过受控数据集引导生成，有效降低重复率，同时保持结构可靠性。", "motivation": "蛋白质语言模型在结构预测和蛋白质设计方面取得了进展，但经常出现病理性的重复问题，这会损害蛋白质的结构稳定性和功能可行性。现有方法（如解码惩罚）往往在降低重复率的同时降低结构置信度，缺乏针对蛋白质领域的专门设计。", "method": "UCCS方法通过构建受控数据集，最大化重复率差异，同时严格控制结构效用。然后，将这些引导向量注入到推理过程中，以专门针对重复问题，而无需重新训练或使用启发式解码。", "result": "实验结果表明，UCCS方法在CATH、UniRef50和SCOP数据集上优于解码惩罚和其他基线方法，显著降低了重复率，同时保持了AlphaFold置信度分数。", "conclusion": "本文将重复控制确立为PLMs的一个核心挑战，并强调了数据集引导的引导方法是实现可靠蛋白质生成的一种有原则的方法。"}}
{"id": "2602.00716", "title": "Emergence of Distortions in High-Dimensional Guided Diffusion Models", "authors": ["Enrico Ventura", "Beatrice Achilli", "Luca Ambrogioni", "Carlo Lucibello"], "summary": "Classifier-free guidance (CFG) is the de facto standard for conditional sampling in diffusion models, yet it often leads to a loss of diversity in generated samples. We formalize this phenomenon as generative distortion, defined as the mismatch between the CFG-induced sampling distribution and the true conditional distribution. Considering Gaussian mixtures and their exact scores, and leveraging tools from statistical physics, we characterize the onset of distortion in a high-dimensional regime as a function of the number of classes. Our analysis reveals that distortions emerge through a phase transition in the effective potential governing the guided dynamics. In particular, our dynamical mean-field analysis shows that distortion persists when the number of modes grows exponentially with dimension, but vanishes in the sub-exponential regime. Consistent with prior finite-dimensional results, we further demonstrate that vanilla CFG shifts the mean and shrinks the variance of the conditional distribution. We show that standard CFG schedules are fundamentally incapable of preventing variance shrinkage. Finally, we propose a theoretically motivated guidance schedule featuring a negative-guidance window, which mitigates loss of diversity while preserving class separability.", "abs": "", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "AI": {"tldr": "本文研究了高维引导扩散模型中分类器自由引导（CFG）导致的生成失真问题，并分析了失真的产生机制，提出了新的引导策略以缓解多样性损失。", "motivation": "尽管CFG已成为扩散模型条件采样标准方法，但它常常导致生成样本多样性降低。本文旨在理解CFG如何改变目标条件分布，并探究这种多样性损失在高维空间中是否是固有现象。", "method": "本文利用统计物理工具，对高维条件下具有高数量类时，CFG诱导的采样分布与真实条件分布之间的偏差（生成失真）进行了形式化定义和分析。通过动力学平均场分析，研究了有效势对引导动态的影响，并提出了带有负引导窗口的新型引导策略。", "result": "研究发现，当模式数量随维度指数增长时，失真会持续存在，但在次指数增长的维度下则消失。CFG会改变条件分布的均值并缩小方差，并且标准的CFG调度无法有效防止方差收缩。", "conclusion": "本文揭示了CFG在高维空间中导致多样性损失的机制，并提供了一种理论上合理的引导策略，可以在保持类别可分离性的同时缓解多样性损失，为改进扩散模型生成样本的多样性提供了新的思路。"}}
{"id": "2602.00302", "title": "Neural Ising Machines via Unrolling and Zeroth-Order Training", "authors": ["Sam Reifenstein", "Timothee Leleu"], "summary": "We propose a data-driven heuristic for NP-hard Ising and Max-Cut optimization that learns the update rule of an iterative dynamical system. The method learns a shared, node-wise update rule that maps local interaction fields to spin updates, parameterized by a compact multilayer perceptron with a small number of parameters. Training is performed using a zeroth-order optimizer, since backpropagation through long, recurrent Ising-machine dynamics leads to unstable and poorly informative gradients. We call this approach a neural network parameterized Ising machine (NPIM). Despite its low parameter count, the learned dynamics recover effective algorithmic structure, including momentum-like behavior and time-varying schedules, enabling efficient search in highly non-convex energy landscapes. Across standard Ising and neural combinatorial optimization benchmarks, NPIM achieves competitive solution quality and time-to-solution relative to recent learning-based methods and strong classical Ising-machine heuristics.", "abs": "", "categories": ["cs.LG", "cond-mat.dis-nn", "nlin.CD"], "AI": {"tldr": "本文提出了一种名为神经伊辛机 (NPIM) 的新型数据驱动优化方法，通过学习迭代动力系统的更新规则来解决 NP-hard 的伊辛和最大割问题，并利用零阶优化器进行训练。", "motivation": "现有手工设计的优化启发式规则设计耗时且效率较低，而数据驱动的神经组合优化 (neural CO) 旨在通过学习优化动力来替代或增强手工规则，但许多现有方法依赖于大型神经网络、长回滚范围或复杂的梯度训练，限制了可扩展性。", "method": "NPIM 通过紧凑的多层感知器参数化伊辛机的更新动态，并使用零阶优化方法训练这些参数。该方法学习一个共享的、节点级的更新规则，将局部交互场映射到自旋更新。", "result": "在标准伊辛和神经组合优化基准测试中，NPIM 实现了与最近的学习方法和强大的经典伊辛机启发式方法相竞争的解决方案质量和求解时间。", "conclusion": "NPIM 证明了使用少量参数和零阶优化器，可以学习到有效的优化动力，包括类似动量和随时间变化的调度行为，从而在高度非凸能量景观中实现高效搜索，为解决 NP-hard 优化问题提供了一种简单且可扩展的方案。"}}
