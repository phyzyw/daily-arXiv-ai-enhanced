{"id": "2509.23629", "title": "How LLMs Learn to Reason: A Complex Network Perspective", "authors": ["Sihan Hu", "Xiansheng Cai", "Yuan Huang", "Zhiyuan Yao", "Linfeng Zhang", "Pan Zhang", "Youjin Deng", "Kun Chen"], "summary": "Training large language models with Reinforcement Learning from Verifiable Rewards (RLVR) exhibits a set of distinctive and puzzling behaviors that remain poorly understood, including a two-stage learning curve, V-shaped response-length trajectories, and a pronounced vulnerability to catastrophic forgetting. In this work, we propose that these seemingly disparate phenomena can be explained using a single unifying theory: the model's reasoning process maps to the self-organization of a semantic complex network whose topology remains persistently sparse, with the average degree pinned close to two. This topology imposes a fundamental mechanism for forgetting and learning: it first drives the system into a maximally frustrated state where ``skill islands'' form, slow-learning happens, and forgetting is induced; then it enters a sharp growth phase where the new skills are ``bolted on'', driven by phase-transition-like learning at the web's frontier. Equipped with the theory, we propose \\textit{Annealed-RLVR}, a principled algorithm that introduces an SFT-based ``heating'' step at the point of maximal frustration to resolve the competitive bottleneck and enhance the reasoning capability of the model. Experiments on a 1.5B-parameter model demonstrate that the approach outperforms standard RLVR on both in-distribution and out-of-distribution benchmarks. By recasting RLVR from black-box optimization into a predictable process of structural self-organization, our work provides a new physical intuition for engineering the emergent reasoning capabilities of future AI systems.", "abs": "", "categories": ["cs.AI", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "physics.soc-ph"], "AI": {"tldr": "本文提出利用复杂网络视角解释RLVR训练的大语言模型中出现的学习曲线、响应长度轨迹和灾难性遗忘等现象，并提出了一种新的算法Annealed-RLVR来提升模型的推理能力。", "motivation": "现有RLVR训练的大语言模型表现出一些令人困惑的行为，例如两阶段学习曲线、V形响应长度轨迹和灾难性遗忘，其原因尚不明确。本文旨在理解这些现象背后的机制，并为构建更高效的推理模型提供指导。", "method": "本文将模型的推理过程建模为语义复杂网络的自组织过程，该网络具有稀疏拓扑结构。通过分析这种拓扑结构，提出了Annealed-RLVR算法，该算法在模型处于最大沮丧状态时引入SFT“加热”步骤，以解决竞争瓶颈。", "result": "实验结果表明，在1.5B参数的模型上，Annealed-RLVR算法在内分布和外分布基准测试中均优于标准RLVR。", "conclusion": "本文将RLVR从黑盒优化转化为可预测的结构自组织过程，提供了一种新的物理直觉来工程化未来AI系统的涌现推理能力。"}}
{"id": "2509.23937", "title": "Diffusion Models are Kelly Gamblers", "authors": ["Akhil Premkumar"], "summary": "We draw a connection between diffusion models and the Kelly criterion for maximizing returns in betting games. We find that conditional diffusion models store additional information to bind the signal $X$ with the conditioning information $Y$, equal to the mutual information between them. Classifier-free guidance effectively boosts the mutual information between $X$ and $Y$ at sampling time. This is especially helpful in image models, since the mutual information between images and their labels is low, a fact which is intimately connected to the manifold hypothesis. Finally, we point out some nuances in the popular perspective that diffusion models are infinitely deep autoencoders. In doing so, we relate the denoising loss to the Fermi Golden Rule from quantum mechanics.", "abs": "", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "cs.IT", "math.IT"], "AI": {"tldr": "本文将扩散模型与凯利标准联系起来，表明扩散模型存储的信息量等于条件变量之间的互信息，并且classifier-free guidance (CFG) 可以有效提升互信息。", "motivation": "理解扩散模型的工作原理，特别是它们如何利用条件信息，以及为什么CFG能够提升生成质量。同时，探讨扩散模型与互信息、凯利标准的联系。", "method": "将扩散模型视为一种在生成过程中进行“凯利式”投注的模型，分析了模型存储的信息量与互信息之间的关系。通过分析图像扩散模型，揭示了图像与标签之间低互信息的原因，并研究了CFG如何提升互信息。", "result": "证明了训练好的条件扩散模型存储的信息量等于条件变量之间的互信息。CFG通过增强条件信号，提升了条件和生成样本之间的互信息。图像扩散模型中，图像与标签之间的互信息较低，因为图像的细节信息在不同类别之间共享。", "conclusion": "本文从互信息和凯利标准的视角重新审视了扩散模型，揭示了扩散模型生成过程中的信息处理机制，并为理解和改进扩散模型提供了新的思路。强调了互信息在扩散模型中的重要性，并解释了CFG提升生成质量的原因。"}}
{"id": "2509.23043", "title": "IsingFormer: Augmenting Parallel Tempering With Learned Proposals", "authors": ["Saleh Bunaiyan", "Corentin Delacour", "Shuvro Chowdhury", "Kyle Lee", "Kerem Y. Camsari"], "summary": "Markov Chain Monte Carlo (MCMC) underlies both statistical physics and combinatorial optimization, but mixes slowly near critical points and in rough landscapes. Parallel Tempering (PT) improves mixing by swapping replicas across temperatures, yet each replica still relies on slow local updates to change its configuration. We introduce IsingFormer, a Transformer trained on equilibrium samples that can generate entire spin configurations resembling those from the target distribution. These uncorrelated samples are used as proposals for global moves within a Metropolis step in PT, complementing the usual single-spin flips. On 2D Ising models (sampling), IsingFormer reproduces magnetization and free-energy curves and generalizes to unseen temperatures, including the critical region. Injecting even a single proposal sharply reduces equilibration time, replacing thousands of local updates. On 3D spin glasses (optimization), PT enhanced with IsingFormer finds substantially lower-energy states, demonstrating how global moves accelerate search in rugged landscapes. Finally, applied to integer factorization encoded as Ising problems, IsingFormer trained on a limited set of semiprimes transfers successfully to unseen semiprimes, boosting success rates beyond the training distribution. Since factorization is a canonical hard benchmark, this ability to generalize across instances highlights the potential of learning proposals that move beyond single problems to entire families of instances. The IsingFormer demonstrates that Monte Carlo methods can be systematically accelerated by neural proposals that capture global structure, yielding faster sampling and stronger performance in combinatorial optimization.", "abs": "", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种名为IsingFormer的Transformer模型，用于生成全局自旋配置作为平行退火(PT)算法中的提案，显著加速了采样和组合优化过程。", "motivation": "传统的MCMC方法，特别是平行退火算法，在复杂景观中混合速度慢，需要大量的局部更新。本文旨在通过学习全局提案来加速MCMC算法，解决其混合速度慢的问题。", "method": "IsingFormer是一个在平衡样本上训练的Transformer模型，能够生成与目标分布相似的完整自旋配置。这些配置作为全局移动提案，与PT算法中的单自旋翻转相结合，用于优化和采样。", "result": "实验结果表明，IsingFormer在2D Ising模型采样、3D spin glass优化以及整数因式分解问题中均能显著减少平衡时间，找到更低能量状态，并在未见过的因式分解实例上表现出泛化能力。", "conclusion": "IsingFormer证明了通过神经网络学习提案可以系统地加速蒙特卡洛方法，捕捉全局结构，从而实现更快的采样和更强的组合优化性能。该方法为解决复杂优化问题提供了一种新的思路。"}}
{"id": "2509.24868", "title": "DRIFT-Net: A Spectral--Coupled Neural Operator for PDEs Learning", "authors": ["Jiayi Li", "Flora D. Salim"], "summary": "Learning PDE dynamics with neural solvers can significantly improve wall-clock efficiency and accuracy compared with classical numerical solvers. In recent years, foundation models for PDEs have largely adopted multi-scale windowed self-attention, with the scOT backbone in \\textsc{Poseidon} serving as a representative example.   However, because of their locality, truly globally consistent spectral coupling can only be propagated gradually through deep stacking and window shifting. This weakens global coupling and leads to error accumulation and drift during closed-loop rollouts. To address this, we propose \\textbf{DRIFT-Net}. It employs a dual-branch design comprising a spectral branch and an image branch. The spectral branch is responsible for capturing global, large-scale low-frequency information, whereas the image branch focuses on local details and nonstationary structures. Specifically, we first perform controlled, lightweight mixing within the low-frequency range. Then we fuse the spectral and image paths at each layer via bandwise weighting, which avoids the width inflation and training instability caused by naive concatenation. The fused result is transformed back into the spatial domain and added to the image branch, thereby preserving both global structure and high-frequency details across scales. Compared with strong attention-based baselines, DRIFT-Net achieves lower error and higher throughput with fewer parameters under identical training settings and budget. On Navier--Stokes benchmarks, the relative $L_{1}$ error is reduced by 7\\%--54\\%, the parameter count decreases by about 15\\%, and the throughput remains higher than scOT. Ablation studies and theoretical analyses further demonstrate the stability and effectiveness of this design. The code is available at https://github.com/cruiseresearchgroup/DRIFT-Net.", "abs": "", "categories": ["cs.LG", "physics.comp-ph"], "AI": {"tldr": "DRIFT-Net是一种新型神经网络算子，通过结合频谱分支和图像分支，实现全局一致性和局部细节的有效学习，从而提高PDE求解的效率和精度。", "motivation": "现有基于多尺度窗口自注意力的PDE基础模型存在全局耦合弱、误差积累和漂移的问题，尤其是在闭环自回归回滚过程中。此外，简单的跨尺度或跨分支连接会导致通道宽度膨胀和训练不稳定。", "method": "DRIFT-Net采用双分支设计：频谱分支负责捕捉全局低频信息，图像分支处理局部细节。通过逐层带状加权融合频谱和图像路径，避免宽度膨胀和训练不稳定，并将融合结果添加到图像分支，从而保留全局结构和高频细节。", "result": "在Navier-Stokes基准测试中，DRIFT-Net相比于强注意力基线模型，降低了7%-54%的相对L1误差，减少了约15%的参数量，并且保持了更高的吞吐量。", "conclusion": "DRIFT-Net提供了一种模块化的算子单元，增强了全局耦合、局部细节保真度和训练稳定性，可用于构建更强大的PDE基础模型，并具有可重用性和模块化特性。"}}
{"id": "2509.24264", "title": "Graph-Based Learning of Free Surface Dynamics in Generalized Newtonian Fluids using Smoothed Particle Hydrodynamics", "authors": ["Hyo-Jin Kim", "Jaekwang Kim", "Hyung-Jun Park"], "summary": "In this study, we propose a graph neural network (GNN) model for efficiently predicting the flow behavior of non-Newtonian fluids with free surface dynamics. The numerical analysis of non-Newtonian fluids presents significant challenges, as traditional algorithms designed for Newtonian fluids with constant viscosity often struggle to converge when applied to non-Newtonian cases, where rheological properties vary dynamically with flow conditions. Among these, power-law fluids exhibit viscosity that decreases exponentially as the shear rate increases, making numerical simulations particularly difficult. The complexity further escalates in free surface flow scenarios, where computational challenges intensify. In such cases, particle-based methods like smoothed particle hydrodynamics (SPH) provide advantages over traditional grid-based techniques, such as the finite element method (FEM). Building on this approach, we introduce a novel GNN-based numerical model to enhance the computational efficiency of non-Newtonian power-law fluid flow simulations. Our model is trained on SPH simulation data, learning the effects of particle accelerations in the presence of SPH interactions based on the fluid's power-law parameters. The GNN significantly accelerates computations while maintaining reliable accuracy in benchmark tests, including dam-break and droplet impact simulations. The results underscore the potential of GNN-based simulation frameworks for efficiently modeling non-Newtonian fluid behavior, paving the way for future advancements in data-driven fluid simulations.", "abs": "", "categories": ["physics.flu-dyn", "cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种基于图神经网络（GNN）的数值模型，用于高效预测非牛顿流体自由表面动力学行为，显著加速了计算过程，同时保持了可靠的精度。", "motivation": "传统算法在模拟非牛顿流体，尤其是具有自由表面的流体时，面临收敛困难的问题。非牛顿流体的流变性质随流动条件动态变化，使得数值模拟复杂。", "method": "该模型基于光滑粒子流体动力学（SPH）方法，利用GNN学习SPH相互作用下粒子加速度的影响，并基于流体的幂律参数进行训练。", "result": "GNN模型在溃坝和液滴撞击等基准测试中显著加速了计算，同时保持了可靠的精度。", "conclusion": "该研究表明基于GNN的模拟框架在高效建模非牛顿流体行为方面具有潜力，为数据驱动流体模拟的未来发展铺平了道路。"}}
{"id": "2509.23144", "title": "Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence", "authors": ["Atma Anand"], "summary": "Information-processing systems coordinating across multiple agents and objectives face fundamental thermodynamic constraints. We show that solutions with maximum utility to act as coordination focal points have much higher selection pressure for being findable across agents rather than accuracy. We derive that the information-theoretic minimum description length of coordination protocols to precision $\\varepsilon$ scales as $L(P)\\geq NK\\log_2 K+N^2d^2\\log (1/\\varepsilon)$ for $N$ agents with $d$ potentially conflicting objectives and internal model complexity $K$. This scaling forces progressive simplification, with coordination dynamics changing the environment itself and shifting optimization across hierarchical levels. Moving from established focal points requires re-coordination, creating persistent metastable states and hysteresis until significant environmental shifts trigger phase transitions through spontaneous symmetry breaking. We operationally define coordination temperature to predict critical phenomena and estimate coordination work costs, identifying measurable signatures across systems from neural networks to restaurant bills to bureaucracies. Extending the topological version of Arrow's theorem on the impossibility of consistent preference aggregation, we find it recursively binds whenever preferences are combined. This potentially explains the indefinite cycling in multi-objective gradient descent and alignment faking in Large Language Models trained with reinforcement learning with human feedback. We term this framework Thermodynamic Coordination Theory (TCT), which demonstrates that coordination requires radical information loss.", "abs": "", "categories": ["cs.AI", "cond-mat.stat-mech", "cs.MA", "nlin.AO", "physics.soc-ph"], "AI": {"tldr": "本文提出了热力学协调理论 (TCT)，表明多目标协调需要极端的的信息损失，并推导了协调协议的长度与代理数量、冲突目标数量和精度之间的关系。", "motivation": "现有形式主义未能解决多个代理在潜在冲突目标下协调预测模型时所面临的信息理论成本和涌现行为问题。研究旨在量化信息处理系统中协调的涌现机制，并解释多目标梯度下降中的不确定循环和大型语言模型中的对齐欺骗现象。", "method": "本文借鉴计算热力学、信息论和计算不可可能性结果，结合了兰道尔原理、本尼特扩展、沃尔珀特合成等理论，并扩展了阿罗定理，推导了协调协议的长度的缩放界限。", "result": "推导出了协调协议长度的公式 L(P)≥NKlog2K+N2d2log(1/ε)，表明协调需要随着代理数量、冲突目标数量和精度变化而进行简化。 发现了协调温度的概念，并估计了协调工作成本，揭示了从神经网络到餐厅账单再到官僚机构等系统中的可测量特征。", "conclusion": "热力学协调理论 (TCT) 证明了协调需要极端的的信息损失，并为理解复杂系统中多目标协调的涌现行为提供了新的视角，并为人工智能领域的对齐问题提供了理论解释。"}}
{"id": "2509.24117", "title": "GeoFunFlow: Geometric Function Flow Matching for Inverse Operator Learning over Complex Geometries", "authors": ["Sifan Wang", "Zhikai Wu", "David van Dijk", "Lu Lu"], "summary": "Inverse problems governed by partial differential equations (PDEs) are crucial in science and engineering. They are particularly challenging due to ill-posedness, data sparsity, and the added complexity of irregular geometries. Classical PDE-constrained optimization methods are computationally expensive, especially when repeated posterior sampling is required. Learning-based approaches improve efficiency and scalability, yet most are designed for regular domains or focus on forward modeling. Here, we introduce {\\em GeoFunFlow}, a geometric diffusion model framework for inverse problems on complex geometries. GeoFunFlow combines a novel geometric function autoencoder (GeoFAE) and a latent diffusion model trained via rectified flow. GeoFAE employs a Perceiver module to process unstructured meshes of varying sizes and produces continuous reconstructions of physical fields, while the diffusion model enables posterior sampling from sparse and noisy data. Across five benchmarks, GeoFunFlow achieves state-of-the-art reconstruction accuracy over complex geometries, provides calibrated uncertainty quantification, and delivers efficient inference compared to operator-learning and diffusion model baselines.", "abs": "", "categories": ["cs.LG", "physics.comp-ph", "stat.ML"], "AI": {"tldr": "GeoFunFlow是一种新的几何扩散模型框架，用于解决复杂几何上的逆问题。它结合了几何函数自动编码器和潜在扩散模型，实现了在复杂几何上进行高效且准确的物理场重建。", "motivation": "传统的PDE约束优化方法在复杂几何上计算成本高昂，现有的基于学习的方法通常针对规则域或侧重于正向建模。因此，需要一种能够处理复杂几何的逆问题的学习方法。", "method": "GeoFunFlow框架结合了几何函数自动编码器（GeoFAE）和潜在扩散模型。GeoFAE使用Perceiver模块处理不同大小的非结构化网格，并生成物理场的连续重建。扩散模型则用于从稀疏和噪声数据中进行后验采样，并通过修正流进行训练。", "result": "在五个基准测试中，GeoFunFlow在复杂几何上实现了最先进的重建精度，提供了校准的不确定性量化，并且与操作符学习和扩散模型基线相比，具有高效的推理速度。", "conclusion": "GeoFunFlow为在复杂几何上解决逆问题提供了一种有效且高效的解决方案，为科学和工程领域中的应用开辟了新的可能性。"}}
{"id": "2509.24779", "title": "MarS-FM: Generative Modeling of Molecular Dynamics via Markov State Models", "authors": ["Kacper Kapuśniak", "Cristian Gabellini", "Michael Bronstein", "Prudencio Tossou", "Francesco Di Giovanni"], "summary": "Molecular Dynamics (MD) is a powerful computational microscope for probing protein functions. However, the need for fine-grained integration and the long timescales of biomolecular events make MD computationally expensive. To address this, several generative models have been proposed to generate surrogate trajectories at lower cost. Yet, these models typically learn a fixed-lag transition density, causing the training signal to be dominated by frequent but uninformative transitions. We introduce a new class of generative models, MSM Emulators, which instead learn to sample transitions across discrete states defined by an underlying Markov State Model (MSM). We instantiate this class with Markov Space Flow Matching (MarS-FM), whose sampling offers more than two orders of magnitude speedup compared to implicit- or explicit-solvent MD simulations. We benchmark Mars-FM ability to reproduce MD statistics through structural observables such as RMSD, radius of gyration, and secondary structure content. Our evaluation spans protein domains (up to 500 residues) with significant chemical and structural diversity, including unfolding events, and enforces strict sequence dissimilarity between training and test sets to assess generalization. Across all metrics, MarS-FM outperforms existing methods, often by a substantial margin.", "abs": "", "categories": ["cs.LG", "q-bio.BM"], "AI": {"tldr": "本文提出了一种新的生成模型MARS-FM，它基于马尔可夫状态模型（MSM）学习分子动力学（MD）模拟中的状态转移，实现了比传统MD模拟快两个数量级的速度提升，并能有效捕捉蛋白质的动态行为。", "motivation": "传统的分子动力学模拟计算成本高昂，而现有的生成模型（MD Emulators）在学习状态转移时受限于固定滞后时间，难以捕捉稀有的大规模构象变化，因此需要一种更有效的方法来模拟分子动力学。", "method": "MARS-FM (MarkovSPACE FLOWMATCHING) 是一种新的生成模型，它将生成模型与马尔可夫状态模型（MSM）相结合，学习在离散状态之间进行采样。该模型通过学习MSM诱导的分布，将生成模型与时间动态解耦，从而更好地学习状态间的转移。", "result": "MARS-FM在蛋白质结构观测指标（如RMSD、回旋半径和二级结构含量）的重现方面表现优于现有方法，速度提升超过两个数量级，并且在不同蛋白质结构和序列上都表现出良好的泛化能力。", "conclusion": "MARS-FM为加速分子动力学模拟提供了一种有效且高效的解决方案，有望在蛋白质功能研究和药物发现等领域得到广泛应用。该方法可以并行生成构象，并可与现有的MD Emulators结合，以捕捉大规模构象变化和状态内的局部动态。"}}
{"id": "2509.23453", "title": "PHASE: Physics-Integrated, Heterogeneity-Aware Surrogates for Scientific Simulations", "authors": ["Dawei Gao", "Dali Wang", "Zhuowei Gu", "Qinglei Cao", "Xiao Wang", "Peter Thornton", "Dan Ricciuto", "Yunhe Feng"], "summary": "Large-scale numerical simulations underpin modern scientific discovery but remain constrained by prohibitive computational costs. AI surrogates offer acceleration, yet adoption in mission-critical settings is limited by concerns over physical plausibility, trustworthiness, and the fusion of heterogeneous data. We introduce PHASE, a modular deep-learning framework for physics-integrated, heterogeneity-aware surrogates in scientific simulations. PHASE combines data-type-aware encoders for heterogeneous inputs with multi-level physics-based constraints that promote consistency from local dynamics to global system behavior. We validate PHASE on the biogeochemical (BGC) spin-up workflow of the U.S. Department of Energy's Energy Exascale Earth System Model (E3SM) Land Model (ELM), presenting-to our knowledge-the first scientifically validated AI-accelerated solution for this task. Using only the first 20 simulation years, PHASE infers a near-equilibrium state that otherwise requires more than 1,200 years of integration, yielding an effective reduction in required integration length by at least 60x. The framework is enabled by a pipeline for fusing heterogeneous scientific data and demonstrates strong generalization to higher spatial resolutions with minimal fine-tuning. These results indicate that PHASE captures governing physical regularities rather than surface correlations, enabling practical, physically consistent acceleration of land-surface modeling and other complex scientific workflows.", "abs": "", "categories": ["cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了PHASE框架，一种用于科学模拟的物理集成、异构性感知代理模型，通过深度学习加速了能源部E3SM陆地模型（ELM）的生物地球化学（BGC）自旋流程，将所需的积分长度缩短了60倍。", "motivation": "大规模数值模拟计算成本高昂，传统的AI代理模型缺乏物理可信度和对异构数据的处理能力，现有物理信息神经网络（PINNs）难以扩展到复杂系统。因此，需要一种能够融合数据驱动效率和物理约束严谨性，并能处理真实世界异构科学数据的框架。", "method": "PHASE框架结合了数据类型感知编码器处理异构输入，并采用多层次基于物理的约束来促进从局部动力学到全局系统行为的一致性。它使用深度学习模型，并融合了来自科学数据的异构数据，并通过物理约束来确保结果的物理合理性。", "result": "PHASE仅使用前20年的模拟数据，就推断出了接近平衡状态，而传统模拟需要超过1200年的积分时间，实现了至少60倍的积分长度缩减。该框架对更高空间分辨率具有良好的泛化能力，且只需少量微调。", "conclusion": "PHASE能够捕捉到控制物理规律，而不是简单的表面相关性，从而实现了对陆地表面建模和其他复杂科学工作流程的实用、物理一致性加速。这表明PHASE为科学模拟加速提供了一种可行的途径。"}}
{"id": "2509.23254", "title": "ABConformer: Physics-inspired Sliding Attention for Antibody-Antigen Interface Prediction", "authors": ["Zhang-Yu You", "Jiahao Ma", "Hongzong Li", "Ye-Fan Hu", "Jian-Dong Huang"], "summary": "Accurate prediction of antibody-antigen (Ab-Ag) interfaces is critical for vaccine design, immunodiagnostics, and therapeutic antibody development. However, achieving reliable predictions from sequences alone remains a challenge. In this paper, we present ABCONFORMER, a model based on the Conformer backbone that captures both local and global features of a biosequence. To accurately capture Ab-Ag interactions, we introduced the physics-inspired sliding attention, enabling residue-level contact recovery without relying on three-dimensional structural data. ABConformer can accurately predict paratopes and epitopes given the antibody and antigen sequence, and predict pan-epitopes on the antigen without antibody information. In comparison experiments, ABCONFORMER achieves state-of-the-art performance on a recent SARS-CoV-2 Ab-Ag dataset, and surpasses widely used sequence-based methods for antibody-agnostic epitope prediction. Ablation studies further quantify the contribution of each component, demonstrating that, compared to conventional cross-attention, sliding attention significantly enhances the precision of epitope prediction. To facilitate reproducibility, we will release the code under an open-source license upon acceptance.", "abs": "", "categories": ["cs.LG", "q-bio.BM"], "AI": {"tldr": "本文提出了ABCONFORMER模型，利用物理启发的滑动注意力机制，仅基于序列信息准确预测抗体-抗原(Ab-Ag)界面，无需三维结构数据。", "motivation": "准确预测Ab-Ag界面对于疫苗设计、免疫诊断和治疗性抗体开发至关重要，但仅基于序列预测可靠界面仍然具有挑战性。", "method": "ABCONFORMER基于Conformer骨干架构，引入了物理启发的滑动注意力机制，用于捕捉生物序列的局部和全局特征，从而实现残基级别的接触恢复。该模型能够预测paratopes和epitopes，并能在没有抗体信息的情况下预测pan-epitopes。", "result": "ABCONFORMER在SARS-CoV-2 Ab-Ag数据集上取得了最先进的性能，并优于常用的基于序列的方法进行抗体无关的表位预测。消融研究表明，滑动注意力显著提高了表位预测的精度。", "conclusion": "ABCONFORMER模型为基于序列的Ab-Ag界面预测提供了一种新的有效方法，具有重要的理论和应用价值，有望促进疫苗设计、免疫诊断和治疗性抗体开发。"}}
{"id": "2509.24914", "title": "Inductive Bias and Spectral Properties of Single-Head Attention in High Dimensions", "authors": ["Fabrizio Boncoraglio", "Vittorio Erba", "Emanuele Troiani", "Florent Krzakala", "Lenka Zdeborová"], "summary": "We study empirical risk minimization in a single-head tied-attention layer trained on synthetic high-dimensional sequence tasks, given by the recently introduced attention-indexed model. Using tools from random matrix theory, spin-glass physics, and approximate message passing, we derive sharp asymptotics for training and test errors, locate interpolation and recovery thresholds, and characterize the limiting spectral distribution of the learned weights. Weight decay induces an implicit nuclear-norm regularization, favoring low-rank query and key matrices. Leveraging this, we compare the standard factorized training of query and key matrices with a direct parameterization in which their product is trained element-wise, revealing the inductive bias introduced by the factorized form. Remarkably, the predicted spectral distribution echoes empirical trends reported in large-scale transformers, offering a theoretical perspective consistent with these phenomena.", "abs": "", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "AI": {"tldr": "本文研究了高维单头注意力层在经验风险最小化中的训练和泛化性能，揭示了权重衰减带来的隐式核范数正则化以及因子化参数化形式引入的诱导偏置，并预测了学习到的权重谱分布。", "motivation": "尽管注意力机制在现代机器学习中取得了巨大成功，但对其学习过程的理论理解仍然有限。本文旨在解释注意力权重中出现的结构化谱模式，并研究这些模式与模型泛化能力之间的关系，以及不同参数化形式对模型的影响。", "method": "利用随机矩阵理论、自旋玻璃物理和近似消息传递工具，对基于注意力索引模型的合成高维序列任务中的单头注意力层进行分析。研究了权重衰减对查询和键矩阵的影响，并比较了标准因子化训练与直接参数化训练。", "result": "研究结果表明，权重衰减诱导了隐式的核范数正则化，倾向于低秩查询和键矩阵。预测的谱分布与大型Transformer中观察到的经验趋势一致，证实了因子化形式引入的诱导偏置。同时，研究还定位了插值和恢复阈值。", "conclusion": "本文提供了一个理论视角来理解大型Transformer中观察到的谱现象，并揭示了注意力机制的诱导偏置。研究结果对理解注意力机制的泛化能力和设计更有效的注意力模型具有重要意义。"}}
{"id": "2509.24882", "title": "Scaling Laws and Spectra of Shallow Neural Networks in the Feature Learning Regime", "authors": ["Leonardo Defilippis", "Yizhou Xu", "Julius Girardin", "Emanuele Troiani", "Vittorio Erba", "Lenka Zdeborová", "Bruno Loureiro", "Florent Krzakala"], "summary": "Neural scaling laws underlie many of the recent advances in deep learning, yet their theoretical understanding remains largely confined to linear models. In this work, we present a systematic analysis of scaling laws for quadratic and diagonal neural networks in the feature learning regime. Leveraging connections with matrix compressed sensing and LASSO, we derive a detailed phase diagram for the scaling exponents of the excess risk as a function of sample complexity and weight decay. This analysis uncovers crossovers between distinct scaling regimes and plateau behaviors, mirroring phenomena widely reported in the empirical neural scaling literature. Furthermore, we establish a precise link between these regimes and the spectral properties of the trained network weights, which we characterize in detail. As a consequence, we provide a theoretical validation of recent empirical observations connecting the emergence of power-law tails in the weight spectrum with network generalization performance, yielding an interpretation from first principles.", "abs": "", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "stat.ML"], "AI": {"tldr": "本文系统地分析了浅层神经网络在特征学习状态下的缩放定律，揭示了权重谱与泛化性能之间的联系，并对经验观察进行了理论验证。", "motivation": "现有理论对神经网络缩放定律的理解主要集中在线性模型上，而本文旨在研究更广泛的浅层神经网络的缩放行为，以应对深度学习中资源规模扩展带来的性能瓶颈。", "method": "研究人员分析了二次和对角神经网络的缩放定律，利用矩阵压缩感知和LASSO的联系，推导了过剩风险的缩放指数与样本复杂度、权重衰减之间的关系。同时，详细分析了训练网络权重的谱特性。", "result": "研究揭示了不同的缩放状态之间的交叉点和平台行为，并建立了权重谱中幂律尾部出现与网络泛化性能之间的精确联系。", "conclusion": "本文为神经网络的缩放定律提供了理论验证，解释了权重谱的幂律尾部与泛化性能之间的关系，为设计高效、资源节约的模型提供了理论指导。"}}
