{"id": "2601.04765", "title": "Differential syntactic and semantic encoding in LLMs", "authors": ["Santiago Acevedo", "Alessandro Laio", "Marco Baroni"], "summary": "We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.", "published": "2026-01-08", "categories": ["cs.CL", "cs.AI", "cs.LG", "physics.comp-ph"], "pdf_url": "https://arxiv.org/pdf/2601.04765v1", "primary_category": "cs.CL"}
{"id": "2601.05240", "title": "Robust Reasoning as a Symmetry-Protected Topological Phase", "authors": ["Ilmo Sung"], "summary": "Large language models suffer from \"hallucinations\"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a \"Metric Phase,\" where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic \"mass gap,\" maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \\times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\\times$ beyond training ($L=50 \\to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.", "published": "2026-01-08", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI", "hep-th"], "pdf_url": "https://arxiv.org/pdf/2601.05240v1", "primary_category": "cs.LG"}
