{"id": "2512.18147", "title": "Estimating Solvation Free Energies with Boltzmann Generators", "authors": ["Maximilian Schebek", "Nikolas M. Frob√∂se", "Bettina G. Keller", "Jutta Rogal"], "summary": "Accurate calculations of solvation free energies remain a central challenge in molecular simulations, often requiring extensive sampling and numerous alchemical intermediates to ensure sufficient overlap between phase-space distributions of a solute in the gas phase and in solution. Here, we introduce a computational framework based on normalizing flows that directly maps solvent configurations between solutes of different sizes, and compare the accuracy and efficiency to conventional free energy estimates. For a Lennard-Jones solvent, we demonstrate that this approach yields acceptable accuracy in estimating free energy differences for challenging transformations, such as solute growth or increased solute-solute separation, which typically demand multiple intermediate simulation steps along the transformation. Analysis of radial distribution functions indicates that the flow generates physically meaningful solvent rearrangements, substantially enhancing configurational overlap between states in configuration space. These results suggest flow-based models as a promising alternative to traditional free energy estimation methods.", "published": "2025-12-20", "categories": ["cond-mat.stat-mech", "cs.LG", "physics.comp-ph"], "pdf_url": "https://arxiv.org/pdf/2512.18147v1", "primary_category": "cond-mat.stat-mech"}
{"id": "2512.19196", "title": "Self-Consistent Probability Flow for High-Dimensional Fokker-Planck Equations", "authors": ["Xiaolong Wu", "Qifeng Liao"], "summary": "Solving high-dimensional Fokker-Planck (FP) equations is a challenge in computational physics and stochastic dynamics, due to the curse of dimensionality (CoD) and the bottleneck of evaluating second-order diffusion terms. Existing deep learning approaches, such as Physics-Informed Neural Networks (PINNs), face computational challenges as dimensionality increases, driven by the $O(D^2)$ complexity of automatic differentiation for second-order derivatives. While recent probability flow approaches bypass this by learning score functions or matching velocity fields, they often involve serial computational operations or depend on sampling efficiency in complex distributions. To address these issues, we propose the Self-Consistent Probability Flow (SCPF) method. We reformulate the second-order FP equation into an equivalent first-order deterministic Probability Flow ODE (PF-ODE) constraint. Unlike score matching or velocity matching, SCPF solves this problem by minimizing the residual of the PF-ODE continuity equation, which avoids explicit Hessian computation. We leverage Continuous Normalizing Flows (CNF) combined with the Hutchinson Trace Estimator (HTE) to reduce the training complexity to linear scale $O(D)$, achieving an effective $O(1)$ wall-clock time on GPUs. To address data sparsity in high dimensions, we apply a generative adaptive sampling strategy and theoretically prove that dynamically aligning collocation points with the evolving probability mass is a necessary condition to bound the approximation error. Experiments on diverse benchmarks -- ranging from anisotropic Ornstein-Uhlenbeck (OU) processes and high-dimensional Brownian motions with time-varying diffusion terms, to Geometric OU processes featuring non-Gaussian solutions -- demonstrate that SCPF effectively mitigates the CoD, maintaining high accuracy and constant computational cost for problems up to 100 dimensions.", "published": "2025-12-22", "categories": ["physics.comp-ph", "cs.LG", "math.NA"], "pdf_url": "https://arxiv.org/pdf/2512.19196v1", "primary_category": "physics.comp-ph"}
{"id": "2512.18251", "title": "CrystalFormer-CSP: Thinking Fast and Slow for Crystal Structure Prediction", "authors": ["Zhendong Cao", "Shigang Ou", "Lei Wang"], "summary": "Crystal structure prediction is a fundamental problem in materials science. We present CrystalFormer-CSP, an efficient framework that unifies data-driven heuristic and physics-driven optimization approaches to predict stable crystal structures for given chemical compositions. The approach combines pretrained generative models for space-group-informed structure generation and a universal machine learning force field for energy minimization. Reinforcement fine-tuning can be employed to further boost the accuracy of the framework. We demonstrate the effectiveness of CrystalFormer-CSP on benchmark problems and showcase its usage via web interface and language model integration.", "published": "2025-12-20", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "pdf_url": "https://arxiv.org/pdf/2512.18251v1", "primary_category": "cond-mat.mtrl-sci"}
{"id": "2512.18029", "title": "Long-range electrostatics for machine learning interatomic potentials is easier than we thought", "authors": ["Dongjin Kim", "Bingqing Cheng"], "summary": "The lack of long-range electrostatics is a key limitation of modern machine learning interatomic potentials (MLIPs), hindering reliable applications to interfaces, charge-transfer reactions, polar and ionic materials, and biomolecules. In this Perspective, we distill two design principles behind the Latent Ewald Summation (LES) framework, which can capture long-range interactions, charges, and electrical response just by learning from standard energy and force training data: (i) use a Coulomb functional form with environment-dependent charges to capture electrostatic interactions, and (ii) avoid explicit training on ambiguous density functional theory (DFT) partial charges. When both principles are satisfied, substantial flexibility remains: essentially any short-range MLIP can be augmented; charge equilibration schemes can be added when desired; dipoles and Born effective charges can be inferred or finetuned; and charge/spin-state embeddings or tensorial targets can be further incorporated. We also discuss current limitations and open challenges. Together, these minimal, physics-guided design rules suggest that incorporating long-range electrostatics into MLIPs is simpler and perhaps more broadly applicable than is commonly assumed.", "published": "2025-12-19", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "pdf_url": "https://arxiv.org/pdf/2512.18029v1", "primary_category": "physics.comp-ph"}
{"id": "2512.18531", "title": "Pushing the limits of one-dimensional NMR spectroscopy for automated structure elucidation using artificial intelligence", "authors": ["Frank Hu", "Jonathan M. Tubb", "Dimitris Argyropoulos", "Sergey Golotvin", "Mikhail Elyashberg", "Grant M. Rotskoff", "Matthew W. Kanan", "Thomas E. Markland"], "summary": "One-dimensional NMR spectroscopy is one of the most widely used techniques for the characterization of organic compounds and natural products. For molecules with up to 36 non-hydrogen atoms, the number of possible structures has been estimated to range from $10^{20} - 10^{60}$. The task of determining the structure (formula and connectivity) of a molecule of this size using only its one-dimensional $^1$H and/or $^{13}$C NMR spectrum, i.e. de novo structure generation, thus appears completely intractable. Here we show how it is possible to achieve this task for systems with up to 40 non-hydrogen atoms across the full elemental coverage typically encountered in organic chemistry (C, N, O, H, P, S, Si, B, and the halogens) using a deep learning framework, thus covering a vast portion of the drug-like chemical space. Leveraging insights from natural language processing, we show that our transformer-based architecture predicts the correct molecule with 55.2% accuracy within the first 15 predictions using only the $^1$H and $^{13}$C NMR spectra, thus overcoming the combinatorial growth of the chemical space while also being extensible to experimental data via fine-tuning.", "published": "2025-12-20", "categories": ["physics.chem-ph", "cs.LG"], "pdf_url": "https://arxiv.org/pdf/2512.18531v1", "primary_category": "physics.chem-ph"}
