{"id": "2510.09784", "title": "Combined Representation and Generation with Diffusive State Predictive Information Bottleneck", "authors": ["Richard John", "Yunrui Qiu", "Lukas Herron", "Pratyush Tiwary"], "summary": "Generative modeling becomes increasingly data-intensive in high-dimensional spaces. In molecular science, where data collection is expensive and important events are rare, compression to lower-dimensional manifolds is especially important for various downstream tasks, including generation. We combine a time-lagged information bottleneck designed to characterize molecular important representations and a diffusion model in one joint training objective. The resulting protocol, which we term Diffusive State Predictive Information Bottleneck (D-SPIB), enables the balancing of representation learning and generation aims in one flexible architecture. Additionally, the model is capable of combining temperature information from different molecular simulation trajectories to learn a coherent and useful internal representation of thermodynamics. We benchmark D-SPIB on multiple molecular tasks and showcase its potential for exploring physical conditions outside the training set.", "abs": "", "categories": ["cs.LG", "cond-mat.stat-mech", "q-bio.QM"], "AI": {"tldr": "本文提出了一种名为D-SPIB的新模型，它将时间滞后信息瓶颈和扩散模型结合起来，以实现分子数据的降维表示学习和生成，并能有效利用多温度数据。", "motivation": "在分子科学等领域，数据收集成本高昂且重要事件稀少，因此需要对高维数据进行降维，以便进行生成等下游任务。传统的生成模型在高维空间中容易出现过拟合问题，而SPIB方法可以提供有意义的低维空间。", "method": "D-SPIB模型将时间滞后信息瓶颈设计用于表征分子重要表示，并将其与扩散模型结合到一个联合训练目标中。该模型能够结合不同分子模拟轨迹的温度信息，学习热力学方面的内部表示。", "result": "D-SPIB模型在多个分子任务上表现出良好的性能，并能够探索训练集之外的物理条件。实验表明，该模型能够从有限的多温度数据中推断出非稳态状态的温度依赖性。", "conclusion": "D-SPIB模型提供了一种灵活的架构，能够平衡表示学习和生成目标，并有望在分子建模和相关科学领域中得到广泛应用，尤其是在数据稀缺的情况下。"}}
{"id": "2510.11209", "title": "Cross-Scale Reservoir Computing for large spatio-temporal forecasting and modeling", "authors": ["Nicola Alboré", "Gabriele Di Antonio", "Fabrizio Coccetti", "Andrea Gabrielli"], "summary": "We propose a new reservoir computing method for forecasting high-resolution spatiotemporal datasets. By combining multi-resolution inputs from coarser to finer layers, our architecture better captures both local and global dynamics. Applied to Sea Surface Temperature data, it outperforms standard parallel reservoir models in long-term forecasting, demonstrating the effectiveness of cross-layers coupling in improving predictive accuracy. Finally, we show that the optimal network dynamics in each layer become increasingly linear, revealing the slow modes propagated to subsequent layers.", "abs": "", "categories": ["cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种跨尺度储备计算方法，通过结合不同分辨率层面的输入，有效预测大规模时空数据集，并在海面温度数据预测中优于标准并行储备模型。", "motivation": "传统方法在建模具有不同时间尺度复杂时空系统时面临挑战，尤其是在缺乏详细方程知识或计算成本过高的情况下。储备计算作为一种数据驱动的建模方法，在预测混沌行为方面表现出潜力，但传统实现难以同时捕捉不同时间尺度下的动态。", "method": "该方法构建了一种跨尺度的储备计算结构，利用低分辨率层传递信息给高分辨率层，模拟物理系统中长程相互作用。该结构将领域划分为局部相互作用的储备池网络，并引入了跨层耦合，以捕捉长程依赖关系。在海面温度数据预测中应用该方法。", "result": "在海面温度数据预测中，跨尺度储备计算方法优于单层模型，能够更好地重现长期动态。低分辨率层过滤了快速模式，强调了缓慢的相干动态，从而帮助高分辨率层更好地解析这些信息。此外，各层最佳RNN动态变得越来越线性，揭示了线性演化的慢模。", "conclusion": "该研究表明，跨尺度储备计算方法能够有效提高大规模时空数据集的预测精度，并提供了一种可解释的动态系统分解，揭示了慢模的传播机制，为复杂时空系统的建模和预测提供了新的思路。"}}
{"id": "2510.11148", "title": "Enhanced Sampling for Efficient Learning of Coarse-Grained Machine Learning Potentials", "authors": ["Weilong Chen", "Franz Görlich", "Paul Fuchs", "Julija Zavadlav"], "summary": "Coarse-graining (CG) enables molecular dynamics (MD) simulations of larger systems and longer timescales that are otherwise infeasible with atomistic models. Machine learning potentials (MLPs), with their capacity to capture many-body interactions, can provide accurate approximations of the potential of mean force (PMF) in CG models. Current CG MLPs are typically trained in a bottom-up manner via force matching, which in practice relies on configurations sampled from the unbiased equilibrium Boltzmann distribution to ensure thermodynamic consistency. This convention poses two key limitations: first, sufficiently long atomistic trajectories are needed to reach convergence; and second, even once equilibrated, transition regions remain poorly sampled. To address these issues, we employ enhanced sampling to bias along CG degrees of freedom for data generation, and then recompute the forces with respect to the unbiased potential. This strategy simultaneously shortens the simulation time required to produce equilibrated data and enriches sampling in transition regions, while preserving the correct PMF. We demonstrate its effectiveness on the M\\\"uller-Brown potential and capped alanine, achieving notable improvements. Our findings support the use of enhanced sampling for force matching as a promising direction to improve the accuracy and reliability of CG MLPs.", "abs": "", "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种利用增强采样技术来改进粗粒化机器学习势能（CG MLP）训练的方法，该方法能够缩短模拟时间并丰富过渡区域的采样，从而提高CG MLP的准确性和可靠性。", "motivation": "传统的粗粒化机器学习势能训练依赖于未偏倚的平衡Boltzmann分布采样，这需要较长的原子轨迹才能收敛，并且过渡区域的采样仍然不足。为了解决这些问题，本文旨在开发一种更有效的方法。", "method": "本文采用增强采样技术来偏向粗粒化自由度，生成数据，然后重新计算相对于未偏置势能的力。这种策略同时缩短了产生平衡数据的模拟时间，并丰富了过渡区域的采样，同时保持正确的PMF。", "result": "在Müller–Brown势能和capped alanine的例子中，本文的增强采样方法取得了显著的改进，证明了其有效性。", "conclusion": "本文的研究结果表明，将增强采样应用于力匹配是一种有前景的方向，可以提高粗粒化机器学习势能的准确性和可靠性，从而扩展分子动力学模拟的可行范围。"}}
{"id": "2510.09768", "title": "Scaling Laws and Symmetry, Evidence from Neural Force Fields", "authors": ["Khang Ngo", "Siamak Ravanbakhsh"], "summary": "We present an empirical study in the geometric task of learning interatomic potentials, which shows equivariance matters even more at larger scales; we show a clear power-law scaling behaviour with respect to data, parameters and compute with ``architecture-dependent exponents''. In particular, we observe that equivariant architectures, which leverage task symmetry, scale better than non-equivariant models. Moreover, among equivariant architectures, higher-order representations translate to better scaling exponents. Our analysis also suggests that for compute-optimal training, the data and model sizes should scale in tandem regardless of the architecture. At a high level, these results suggest that, contrary to common belief, we should not leave it to the model to discover fundamental inductive biases such as symmetry, especially as we scale, because they change the inherent difficulty of the task and its scaling laws.", "abs": "", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "AI": {"tldr": "本研究通过对原子间势学习任务的实验，发现对称性（equivariant）在更大规模下至关重要，且高阶表示的 equivariant 架构具有更好的扩展性。数据和模型规模应同步增长，以实现计算最优的训练。", "motivation": "现有观点认为，随着模型规模的扩大，模型可以自行学习归纳偏差，例如对称性，因此无需显式编码。本研究旨在检验这一观点，并探索对称性在更大规模下的作用。", "method": "研究人员对基于神经网络的原子间势学习任务进行了实证研究，比较了 equivariant 和非 equivariant 架构的扩展行为，并分析了不同架构复杂度的影响，包括低阶和高阶表示。", "result": "实验结果表明，equivariant 架构比非 equivariant 架构具有更好的扩展性，且高阶表示的 equivariant 架构具有更好的扩展指数。数据和模型规模应同步增长，以实现计算最优的训练。对称性对任务的难度和扩展规律有显著影响。", "conclusion": "本研究表明，在模型规模扩大时，不应忽视对称性等归纳偏差，因为它们会影响任务的难度和扩展规律。显式编码对称性可以改善扩展性能，挑战了模型自行学习归纳偏差的常见观点。"}}
{"id": "2510.11188", "title": "Protein as a Second Language for LLMs", "authors": ["Xinhui Chen", "Zuchao Li", "Mengqi Gao", "Yufeng Zhang", "Chak Tou Leong", "Haoyang Li", "Jiaqi Chen"], "summary": "Deciphering the function of unseen protein sequences is a fundamental challenge with broad scientific impact, yet most existing methods depend on task-specific adapters or large-scale supervised fine-tuning. We introduce the \"Protein-as-Second-Language\" framework, which reformulates amino-acid sequences as sentences in a novel symbolic language that large language models can interpret through contextual exemplars. Our approach adaptively constructs sequence-question-answer triples that reveal functional cues in a zero-shot setting, without any further training. To support this process, we curate a bilingual corpus of 79,926 protein-QA instances spanning attribute prediction, descriptive understanding, and extended reasoning. Empirically, our method delivers consistent gains across diverse open-source LLMs and GPT-4, achieving up to 17.2% ROUGE-L improvement (average +7%) and even surpassing fine-tuned protein-specific language models. These results highlight that generic LLMs, when guided with protein-as-language cues, can outperform domain-specialized models, offering a scalable pathway for protein understanding in foundation models.", "abs": "", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "AI": {"tldr": "本文提出了一种名为“蛋白质作为第二语言”的框架，将氨基酸序列视为一种符号语言，利用大型语言模型（LLMs）进行蛋白质功能理解，无需额外训练即可实现优异性能。", "motivation": "现有蛋白质功能理解方法依赖于特定任务的适配器或大规模的监督微调，存在数据需求高、计算成本高、泛化能力有限等瓶颈。研究旨在探索利用通用LLMs进行蛋白质理解的可扩展途径。", "method": "该框架将蛋白质序列重新定义为一种符号语言，通过构建序列-问题-答案三元组，引导LLMs在零样本设置下理解蛋白质功能。研究人员构建了一个包含79,926个蛋白质-QA实例的双语语料库，用于支持这一过程。", "result": "实验结果表明，该方法在各种开源LLMs和GPT-4o上均能获得一致的性能提升，ROUGE-L指标平均提升7%，最高提升17.2%，甚至超越了专门的蛋白质语言模型。", "conclusion": "研究表明，当引导时，通用LLMs可以胜过领域专用模型，为蛋白质理解提供了一种可扩展的、基于基础模型的途径，有望推动蛋白质功能研究。"}}
{"id": "2510.10483", "title": "Gradient Enhanced Self-Training Physics-Informed Neural Network (gST-PINN) for Solving Nonlinear Partial Differential Equations", "authors": ["Narayan S Iyer", "Bivas Bhaumik", "Ram S Iyer", "Satyasaran Changdar"], "summary": "Partial differential equations (PDEs) provide a mathematical foundation for simulating and understanding intricate behaviors in both physical sciences and engineering. With the growing capabilities of deep learning, data$-$driven approaches like Physics$-$Informed Neural Networks (PINNs) have been developed, offering a mesh$-$free, analytic type framework for efficiently solving PDEs across a wide range of applications. However, traditional PINNs often struggle with challenges such as limited precision, slow training dynamics, lack of labeled data availability, and inadequate handling of multi$-$physics interactions. To overcome these challenging issues of PINNs, we proposed a Gradient Enhanced Self$-$Training PINN (gST$-$PINN) method that specifically introduces a gradient based pseudo point self$-$learning algorithm for solving PDEs. We tested the proposed method on three different types of PDE problems from various fields, each representing distinct scenarios. The effectiveness of the proposed method is evident, as the PINN approach for solving the Burgers$'$ equation attains a mean square error (MSE) on the order of $10^{-3}$, while the diffusion$-$sorption equation achieves an MSE on the order of $10^{-4}$ after 12,500 iterations, with no further improvement as the iterations increase. In contrast, the MSE for both PDEs in the gST$-$PINN model continues to decrease, demonstrating better generalization and reaching an MSE on the order of $10^{-5}$ after 18,500 iterations. Furthermore, the results show that the proposed purely semi$-$supervised gST$-$PINN consistently outperforms the standard PINN method in all cases, even when solution of the PDEs are unavailable. It generalizes both PINN and Gradient$-$enhanced PINN (gPINN), and can be effectively applied in scenarios prone to low accuracy and convergence issues, particularly in the absence of labeled data.", "abs": "", "categories": ["cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种名为gST-PINN的梯度增强自训练物理信息神经网络方法，用于解决非线性偏微分方程，该方法通过梯度伪点自学习算法提升了PINN的精度和泛化能力。", "motivation": "传统PINN在精度、训练速度、数据依赖性和多物理场交互处理等方面存在挑战，为了克服这些问题，需要一种更有效、更鲁棒的PDE求解方法。", "method": "gST-PINN引入了基于梯度的伪点自学习算法，将数值分析问题转化为优化问题，并利用自训练策略，在无需大量标注数据的情况下提升模型性能。该方法在损失函数中编码了PDE本身、边界条件、初始条件等物理信息。", "result": "在Burgers方程和扩散-吸附方程的实验中，gST-PINN的均方误差分别达到10⁻⁵和10⁻⁴，显著优于标准PINN方法，并且在迭代次数增加后误差持续下降，表明了更好的泛化能力。", "conclusion": "gST-PINN是一种有效的半监督学习方法，能够克服传统PINN的局限性，尤其适用于缺乏标注数据或存在低精度和收敛问题的场景，具有广泛的应用前景。"}}
{"id": "2510.10693", "title": "High-Dimensional Learning Dynamics of Quantized Models with Straight-Through Estimator", "authors": ["Yuma Ichikawa", "Shuhei Kashiwamura", "Ayaka Sakata"], "summary": "Quantized neural network training optimizes a discrete, non-differentiable objective. The straight-through estimator (STE) enables backpropagation through surrogate gradients and is widely used. While previous studies have primarily focused on the properties of surrogate gradients and their convergence, the influence of quantization hyperparameters, such as bit width and quantization range, on learning dynamics remains largely unexplored. We theoretically show that in the high-dimensional limit, STE dynamics converge to a deterministic ordinary differential equation. This reveals that STE training exhibits a plateau followed by a sharp drop in generalization error, with plateau length depending on the quantization range. A fixed-point analysis quantifies the asymptotic deviation from the unquantized linear model. We also extend analytical techniques for stochastic gradient descent to nonlinear transformations of weights and inputs.", "abs": "", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "AI": {"tldr": "本文理论分析了直通估计器 (STE) 在高维量化模型训练中的学习动态，揭示了量化参数对训练过程的影响，并预测了泛化误差的非单调行为。", "motivation": "尽管直通估计器 (STE) 在量化神经网络训练中广泛应用，但其理论基础薄弱，量化超参数（如比特宽度和量化范围）对学习动态的影响尚不明确。", "method": "研究人员分析了具有联合量化权重和输入的线性回归模型，在高维输入极限下，将微观参数更新转化为连续时间随机微分方程 (SDE)，并将宏观状态描述为确定性常微分方程 (ODE)。同时，将分析方法扩展到参数和输入都存在非线性变换的场景。", "result": "理论分析表明，STE 训练会经历一个扩展的平台期，随后是泛化误差的急剧下降，最终饱和。平台期的长度取决于量化范围。此外，还量化了与未量化线性模型之间的渐近偏差。", "conclusion": "该研究为理解 STE 训练过程提供了理论基础，揭示了量化参数对学习动态的关键影响，并为量化神经网络的超参数选择提供了指导意义。"}}
{"id": "2510.10020", "title": "Calibrating Generative Models", "authors": ["Henry D. Smith", "Nathaniel L. Diamant", "Brian L. Trippe"], "summary": "Generative models frequently suffer miscalibration, wherein class probabilities and other statistics of the sampling distribution deviate from desired values. We frame calibration as a constrained optimization problem and seek the closest model in Kullback-Leibler divergence satisfying calibration constraints. To address the intractability of imposing these constraints exactly, we introduce two surrogate objectives for fine-tuning: (1) the relax loss, which replaces the constraint with a miscalibration penalty, and (2) the reward loss, which converts calibration into a reward fine-tuning problem. We demonstrate that these approaches substantially reduce calibration error across hundreds of simultaneous constraints and models with up to one billion parameters, spanning applications in protein design, image generation, and language modeling.", "abs": "", "categories": ["stat.ML", "cs.LG", "q-bio.BM"], "AI": {"tldr": "本文将生成模型校准问题建模为受约束优化问题，并提出了两种新的微调算法（CGM-relax和CGM-reward），以在满足校准约束的同时，最小化与原始模型的KL散度。", "motivation": "生成模型经常出现校准问题，即采样分布的概率和其他统计数据与期望值偏差。这在图像生成、语言建模和蛋白质设计等领域都存在，并可能导致偏见和不准确的结果。", "method": "本文将校准问题转化为受约束优化问题，目标是在KL散度上找到最接近原始模型的校准模型。为了解决精确施加约束的困难，提出了两种替代目标函数：放松损失（relax loss）和奖励损失（reward loss），分别通过惩罚校准误差和将校准转化为奖励微调问题来实现。", "result": "实验表明，提出的CGM-relax和CGM-reward算法能够显著减少校准误差，在蛋白质设计、图像生成和语言建模等多个应用中，成功校准了高达十亿参数的生成模型，并满足了数百个同时的约束。", "conclusion": "本文提供了一种有效且通用的校准生成模型的方法，能够解决大规模生成模型校准的挑战，并为后续研究提供了新的思路和工具。"}}
