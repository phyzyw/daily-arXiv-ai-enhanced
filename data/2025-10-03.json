{"id": "2510.02218", "title": "Quantum Fisher information matrices from Rényi relative entropies", "authors": ["Mark M. Wilde"], "summary": "Quantum generalizations of the Fisher information are important in quantum information science, with applications in high energy and condensed matter physics and in quantum estimation theory, machine learning, and optimization. One can derive a quantum generalization of the Fisher information matrix in a natural way as the Hessian matrix arising in a Taylor expansion of a smooth divergence. Such an approach is appealing for quantum information theorists, given the ubiquity of divergences in quantum information theory. In contrast to the classical case, there is not a unique quantum generalization of the Fisher information matrix, similar to how there is not a unique quantum generalization of the relative entropy or the R\\'enyi relative entropy. In this paper, I derive information matrices arising from the log-Euclidean, $\\alpha$-$z$, and geometric R\\'enyi relative entropies, with the main technical tool for doing so being the method of divided differences for calculating matrix derivatives. Interestingly, for all non-negative values of the R\\'enyi parameter $\\alpha$, the log-Euclidean R\\'enyi relative entropy leads to the Kubo-Mori information matrix, and the geometric R\\'enyi relative entropy leads to the right-logarithmic derivative Fisher information matrix. Thus, the resulting information matrices obey the data-processing inequality for all non-negative values of the R\\'enyi parameter $\\alpha$ even though the original quantities do not. Additionally, I derive and establish basic properties of $\\alpha$-$z$ information matrices resulting from the $\\alpha$-$z$ R\\'enyi relative entropies. For parameterized thermal states, I establish formulas for their $\\alpha$-$z$ information matrices and hybrid quantum-classical algorithms for estimating them, with applications in quantum Boltzmann machine learning.", "published": "2025-10-02", "categories": ["quant-ph", "cond-mat.stat-mech", "cs.IT", "cs.LG", "hep-th", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2510.02218v1", "primary_category": "quant-ph"}
{"id": "2510.01396", "title": "Neural Network Surrogates for Free Energy Computation of Complex Chemical Systems", "authors": ["Wasut Pornpatcharapong"], "summary": "Free energy reconstruction methods such as Gaussian Process Regression (GPR) require Jacobians of the collective variables (CVs), a bottleneck that restricts the use of complex or machine-learned CVs. We introduce a neural network surrogate framework that learns CVs directly from Cartesian coordinates and uses automatic differentiation to provide Jacobians, bypassing analytical forms. On an MgCl2 ion-pairing system, our method achieved high accuracy for both a simple distance CV and a complex coordination-number CV. Moreover, Jacobian errors also followed a near-Gaussian distribution, making them suitable for GPR pipelines. This framework enables gradient-based free energy methods to incorporate complex and machine-learned CVs, broadening the scope of biochemistry and materials simulations.", "published": "2025-10-01", "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2510.01396v1", "primary_category": "cs.LG"}
{"id": "2510.01370", "title": "SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs", "authors": ["Abu Bucker Siddik", "Diane Oyen", "Alexander Most", "Michal Kucer", "Ayan Biswas"], "summary": "We introduce Small PDE U-Net Solver (SPUS), a compact and efficient foundation model (FM) designed as a unified neural operator for solving a wide range of partial differential equations (PDEs). Unlike existing state-of-the-art PDE FMs-primarily based on large complex transformer architectures with high computational and parameter overhead-SPUS leverages a lightweight residual U-Net-based architecture that has been largely underexplored as a foundation model architecture in this domain. To enable effective learning in this minimalist framework, we utilize a simple yet powerful auto-regressive pretraining strategy which closely replicates the behavior of numerical solvers to learn the underlying physics. SPUS is pretrained on a diverse set of fluid dynamics PDEs and evaluated across 6 challenging unseen downstream PDEs spanning various physical systems. Experimental results demonstrate that SPUS using residual U-Net based architecture achieves state-of-the-art generalization on these downstream tasks while requiring significantly fewer parameters and minimal fine-tuning data, highlighting its potential as a highly parameter-efficient FM for solving diverse PDE systems.", "published": "2025-10-01", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2510.01370v1", "primary_category": "cs.CV"}
{"id": "2510.00698", "title": "Physics-Informed Extreme Learning Machine (PIELM) for Tunnelling-Induced Soil-Pile Interactions", "authors": ["Fu-Chen Guo", "Pei-Zhi Zhuang", "Fei Ren", "Hong-Ya Yue", "He Yang"], "summary": "Physics-informed machine learning has been a promising data-driven and physics-informed approach in geotechnical engineering. This study proposes a physics-informed extreme learning machine (PIELM) framework for analyzing tunneling-induced soil-pile interactions. The pile foundation is modeled as an Euler-Bernoulli beam, and the surrounding soil is modeled as a Pasternak foundation. The soil-pile interaction is formulated into a fourth-order ordinary differential equation (ODE) that constitutes the physics-informed component, while measured data are incorporated into PIELM as the data-driven component. Combining physics and data yields a loss vector of the extreme learning machine (ELM) network, which is trained within 1 second by the least squares method. After validating the PIELM approach by the boundary element method (BEM) and finite difference method (FDM), parametric studies are carried out to examine the effects of ELM network architecture, data monitoring locations and numbers on the performance of PIELM. The results indicate that monitored data should be placed at positions where the gradients of pile deflections are significant, such as at the pile tip/top and near tunneling zones. Two application examples highlight the critical role of physics-informed and data-driven approach for tunnelling-induced soil-pile interactions. The proposed approach shows great potential for real-time monitoring and safety assessment of pile foundations, and benefits for intelligent early-warning systems in geotechnical engineering.", "published": "2025-10-01", "categories": ["cs.LG", "cs.NE", "physics.comp-ph", "physics.geo-ph"], "pdf_url": "http://arxiv.org/pdf/2510.00698v1", "primary_category": "cs.LG"}
{"id": "2510.00282", "title": "Electron neural closure for turbulent magnetosheath simulations: energy channels", "authors": ["George Miloshevich", "Luka Vranckx", "Felipe Nathan de Oliveira Lopes", "Pietro Dazzi", "Giuseppe Arrò", "Giovanni Lapenta"], "summary": "In this work, we introduce a non-local five-moment electron pressure tensor closure parametrized by a Fully Convolutional Neural Network (FCNN). Electron pressure plays an important role in generalized Ohm's law, competing with electron inertia. This model is used in the development of a surrogate model for a fully kinetic energy-conserving semi-implicit Particle-in-Cell simulation of decaying magnetosheath turbulence. We achieve this by training FCNN on a representative set of simulations with a smaller number of particles per cell and showing that our results generalise to a simulation with a large number of particles per cell. We evaluate the statistical properties of the learned equation of state, with a focus on pressure-strain interaction, which is crucial for understanding energy channels in turbulent plasmas. The resulting equation of state learned via FCNN significantly outperforms local closures, such as those learned by Multi-Layer Perceptron (MLP) or double adiabatic expressions. We report that the overall spatial distribution of pressure-strain and its conditional averages are reconstructed well. However, some small-scale features are missed, especially for the off-diagonal components of the pressure tensor. Nevertheless, the results are substantially improved with more training data, indicating favorable scaling and potential for improvement, which will be addressed in future work.", "published": "2025-09-30", "categories": ["physics.plasm-ph", "cs.LG", "physics.comp-ph"], "pdf_url": "http://arxiv.org/pdf/2510.00282v1", "primary_category": "physics.plasm-ph"}
{"id": "2510.00129", "title": "BigBang-Proton Technical Report: Next-Word-Prediction is Scientific Multitask Learner", "authors": ["Hengkui Wu", "Liujiang Liu", "Jihua He", "Qihao Wang", "Keke Zhao", "Shuyang Hu", "Renle Fu", "Dahao Liang", "Lingyu Zeng", "Bruce Liu", "Yuan Liu", "Jin Zhan", "Jiaqiang Niu", "Xinglong Jia", "Yaqin Hu", "Wenjun Ji", "Panpan Chi", "Ken Chen", "Hengyuan Wu", "Yingsi Xin", "Yongfeng Zhu", "Yuexin Wang", "Manqi Ruan", "Ningtao Bian", "Xiaohua Wu", "Weipeng Xu"], "summary": "We introduce BigBang-Proton, a unified sequence-based architecture for auto-regressive language modeling pretrained on cross-scale, cross-structure, cross-discipline real-world scientific tasks to construct a scientific multi-task learner. BigBang-Proton incorporates three fundamental innovations compared to mainstream general-purpose LLMs: Theory-Experiment Learning paradigm aligns large-scale numerical experimental data with theoretical text corpora; Binary Patch Encoding replaces byte pair encoding(BPE) tokenization; Monte Carlo Attention substitutes traditional transformer architectures. Through next-word-prediction pretraining on cross-discipline scientific datasets of real-world problems mixed with general textual corpus, followed by fine-tuning and inference on downstream tasks, BigBang-Proton demonstrates 100\\% accuracy in up to 50-digit arithmetic addition operations, performance on par with leading specialized models in particle physics jet tagging, matching MAE of specialized models in inter-atomic potential simulation, performance comparable to traditional spatiotemporal models in water quality prediction, and benchmark-exceeding performance in genome modeling. These results prove that language-guided scientific computing can match or exceed the performance of task-specific scientific models while maintaining multitask learning capabilities. We further hypothesize to scale the pretraining to the universe scale as a fundamental step toward developing material world foundational model.", "published": "2025-09-30", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.comp-ph", "68T05, 68T50, 00A69, 94A99", "I.2.6; I.2.7; J.2; I.6.3; K.4.1"], "pdf_url": "http://arxiv.org/pdf/2510.00129v1", "primary_category": "cs.LG"}
{"id": "2510.02259", "title": "Transformers Discover Molecular Structure Without Graph Priors", "authors": ["Tobias Kreiman", "Yutong Bai", "Fadi Atieh", "Elizabeth Weaver", "Eric Qu", "Aditi S. Krishnapriyan"], "summary": "Graph Neural Networks (GNNs) are the dominant architecture for molecular machine learning, particularly for molecular property prediction and machine learning interatomic potentials (MLIPs). GNNs perform message passing on predefined graphs often induced by a fixed radius cutoff or k-nearest neighbor scheme. While this design aligns with the locality present in many molecular tasks, a hard-coded graph can limit expressivity due to the fixed receptive field and slows down inference with sparse graph operations. In this work, we investigate whether pure, unmodified Transformers trained directly on Cartesian coordinates$\\unicode{x2013}$without predefined graphs or physical priors$\\unicode{x2013}$can approximate molecular energies and forces. As a starting point for our analysis, we demonstrate how to train a Transformer to competitive energy and force mean absolute errors under a matched training compute budget, relative to a state-of-the-art equivariant GNN on the OMol25 dataset. We discover that the Transformer learns physically consistent patterns$\\unicode{x2013}$such as attention weights that decay inversely with interatomic distance$\\unicode{x2013}$and flexibly adapts them across different molecular environments due to the absence of hard-coded biases. The use of a standard Transformer also unlocks predictable improvements with respect to scaling training resources, consistent with empirical scaling laws observed in other domains. Our results demonstrate that many favorable properties of GNNs can emerge adaptively in Transformers, challenging the necessity of hard-coded graph inductive biases and pointing toward standardized, scalable architectures for molecular modeling.", "published": "2025-10-02", "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.chem-ph", "q-bio.BM"], "pdf_url": "http://arxiv.org/pdf/2510.02259v1", "primary_category": "cs.LG"}
{"id": "2510.00224", "title": "Learning from the electronic structure of molecules across the periodic table", "authors": ["Manasa Kaniselvan", "Benjamin Kurt Miller", "Meng Gao", "Juno Nam", "Daniel S. Levine"], "summary": "Machine-Learned Interatomic Potentials (MLIPs) require vast amounts of atomic structure data to learn forces and energies, and their performance continues to improve with training set size. Meanwhile, the even greater quantities of accompanying data in the Hamiltonian matrix H behind these datasets has so far gone unused for this purpose. Here, we provide a recipe for integrating the orbital interaction data within H towards training pipelines for atomic-level properties. We first introduce HELM (\"Hamiltonian-trained Electronic-structure Learning for Molecules\"), a state-of-the-art Hamiltonian prediction model which bridges the gap between Hamiltonian prediction and universal MLIPs by scaling to H of structures with 100+ atoms, high elemental diversity, and large basis sets including diffuse functions. To accompany HELM, we release a curated Hamiltonian matrix dataset, 'OMol_CSH_58k', with unprecedented elemental diversity (58 elements), molecular size (up to 150 atoms), and basis set (def2-TZVPD). Finally, we introduce 'Hamiltonian pretraining' as a method to extract meaningful descriptors of atomic environments even from a limited number atomic structures, and repurpose this shared embedding space to improve performance on energy-prediction in low-data regimes. Our results highlight the use of electronic interactions as a rich and transferable data source for representing chemical space.", "published": "2025-09-30", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2510.00224v1", "primary_category": "physics.chem-ph"}
{"id": "2510.02073", "title": "Inferring Optical Tissue Properties from Photoplethysmography using Hybrid Amortized Inference", "authors": ["Jens Behrmann", "Maria R. Cervera", "Antoine Wehenkel", "Andrew C. Miller", "Albert Cerussi", "Pranay Jain", "Vivek Venugopal", "Shijie Yan", "Guillermo Sapiro", "Luca Pegolotti", "Jörn-Henrik Jacobsen"], "summary": "Smart wearables enable continuous tracking of established biomarkers such as heart rate, heart rate variability, and blood oxygen saturation via photoplethysmography (PPG). Beyond these metrics, PPG waveforms contain richer physiological information, as recent deep learning (DL) studies demonstrate. However, DL models often rely on features with unclear physiological meaning, creating a tension between predictive power, clinical interpretability, and sensor design. We address this gap by introducing PPGen, a biophysical model that relates PPG signals to interpretable physiological and optical parameters. Building on PPGen, we propose hybrid amortized inference (HAI), enabling fast, robust, and scalable estimation of relevant physiological parameters from PPG signals while correcting for model misspecification. In extensive in-silico experiments, we show that HAI can accurately infer physiological parameters under diverse noise and sensor conditions. Our results illustrate a path toward PPG models that retain the fidelity needed for DL-based features while supporting clinical interpretation and informed hardware design.", "published": "2025-10-02", "categories": ["cs.LG", "physics.bio-ph", "stat.ML"], "pdf_url": "http://arxiv.org/pdf/2510.02073v1", "primary_category": "cs.LG"}
{"id": "2510.01571", "title": "From Supervision to Exploration: What Does Protein Language Model Learn During Reinforcement Learning?", "authors": ["Hanqun Cao", "Hongrui Zhang", "Junde Xu", "Zhou Zhang", "Lingdong Shen", "Minghao Sun", "Ge Liu", "Jinbo Xu", "Wu-Jun Li", "Jinren Ni", "Cesar de la Fuente-Nunez", "Tianfan Fu", "Yejin Choi", "Pheng-Ann Heng", "Fang Wu"], "summary": "Protein language models (PLMs) have advanced computational protein science through large-scale pretraining and scalable architectures. In parallel, reinforcement learning (RL) has broadened exploration and enabled precise multi-objective optimization in protein design. Yet whether RL can push PLMs beyond their pretraining priors to uncover latent sequence-structure-function rules remains unclear. We address this by pairing RL with PLMs across four domains: antimicrobial peptide design, kinase variant optimization, antibody engineering, and inverse folding. Using diverse RL algorithms and model classes, we ask if RL improves sampling efficiency and, more importantly, if it reveals capabilities not captured by supervised learning. Across benchmarks, RL consistently boosts success rates and sample efficiency. Performance follows a three-factor interaction: task headroom, reward fidelity, and policy capacity jointly determine gains. When rewards are accurate and informative, policies have sufficient capacity, and tasks leave room beyond supervised baselines, improvements scale; when rewards are noisy or capacity is constrained, gains saturate despite exploration. This view yields practical guidance for RL in protein design: prioritize reward modeling and calibration before scaling policy size, match algorithm and regularization strength to task difficulty, and allocate capacity where marginal gains are largest. Implementation is available at https://github.com/chq1155/RL-PLM.", "published": "2025-10-02", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf_url": "http://arxiv.org/pdf/2510.01571v1", "primary_category": "cs.LG"}
{"id": "2510.00774", "title": "GeoGraph: Geometric and Graph-based Ensemble Descriptors for Intrinsically Disordered Proteins", "authors": ["Eoin Quinn", "Marco Carobene", "Jean Quentin", "Sebastien Boyer", "Miguel Arbesú", "Oliver Bent"], "summary": "While deep learning has revolutionized the prediction of rigid protein structures, modelling the conformational ensembles of Intrinsically Disordered Proteins (IDPs) remains a key frontier. Current AI paradigms present a trade-off: Protein Language Models (PLMs) capture evolutionary statistics but lack explicit physical grounding, while generative models trained to model full ensembles are computationally expensive. In this work we critically assess these limits and propose a path forward. We introduce GeoGraph, a simulation-informed surrogate trained to predict ensemble-averaged statistics of residue-residue contact-map topology directly from sequence. By featurizing coarse-grained molecular dynamics simulations into residue- and sequence-level graph descriptors, we create a robust and information-rich learning target. Our evaluation demonstrates that this approach yields representations that are more predictive of key biophysical properties than existing methods.", "published": "2025-10-01", "categories": ["q-bio.BM", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2510.00774v1", "primary_category": "q-bio.BM"}
{"id": "2510.00352", "title": "AReUReDi: Annealed Rectified Updates for Refining Discrete Flows with Multi-Objective Guidance", "authors": ["Tong Chen", "Yinuo Zhang", "Pranam Chatterjee"], "summary": "Designing sequences that satisfy multiple, often conflicting, objectives is a central challenge in therapeutic and biomolecular engineering. Existing generative frameworks largely operate in continuous spaces with single-objective guidance, while discrete approaches lack guarantees for multi-objective Pareto optimality. We introduce AReUReDi (Annealed Rectified Updates for Refining Discrete Flows), a discrete optimization algorithm with theoretical guarantees of convergence to the Pareto front. Building on Rectified Discrete Flows (ReDi), AReUReDi combines Tchebycheff scalarization, locally balanced proposals, and annealed Metropolis-Hastings updates to bias sampling toward Pareto-optimal states while preserving distributional invariance. Applied to peptide and SMILES sequence design, AReUReDi simultaneously optimizes up to five therapeutic properties (including affinity, solubility, hemolysis, half-life, and non-fouling) and outperforms both evolutionary and diffusion-based baselines. These results establish AReUReDi as a powerful, sequence-based framework for multi-property biomolecule generation.", "published": "2025-09-30", "categories": ["cs.LG", "q-bio.BM"], "pdf_url": "http://arxiv.org/pdf/2510.00352v1", "primary_category": "cs.LG"}
{"id": "2510.00351", "title": "Flow Autoencoders are Effective Protein Tokenizers", "authors": ["Rohit Dilip", "Evan Zhang", "Ayush Varshney", "David Van Valen"], "summary": "Protein structure tokenizers enable the creation of multimodal models of protein structure, sequence, and function. Current approaches to protein structure tokenization rely on bespoke components that are invariant to spatial symmetries, but that are challenging to optimize and scale. We present Kanzi, a flow-based tokenizer for tokenization and generation of protein structures. Kanzi consists of a diffusion autoencoder trained with a flow matching loss. We show that this approach simplifies several aspects of protein structure tokenizers: frame-based representations can be replaced with global coordinates, complex losses are replaced with a single flow matching loss, and SE(3)-invariant attention operations can be replaced with standard attention. We find that these changes stabilize the training of parameter-efficient models that outperform existing tokenizers on reconstruction metrics at a fraction of the model size and training cost. An autoregressive model trained with Kanzi outperforms similar generative models that operate over tokens, although it does not yet match the performance of state-of-the-art continuous diffusion models. Code is available here: https://github.com/rdilip/kanzi/.", "published": "2025-09-30", "categories": ["cs.LG", "q-bio.BM"], "pdf_url": "http://arxiv.org/pdf/2510.00351v1", "primary_category": "cs.LG"}
{"id": "2510.01632", "title": "BioBlobs: Differentiable Graph Partitioning for Protein Representation Learning", "authors": ["Xin Wang", "Carlos Oliver"], "summary": "Protein function is driven by coherent substructures which vary in size and topology, yet current protein representation learning models (PRL) distort these signals by relying on rigid substructures such as k-hop and fixed radius neighbourhoods. We introduce BioBlobs, a plug-and-play, fully differentiable module that represents proteins by dynamically partitioning structures into flexibly-sized, non-overlapping substructures (\"blobs\"). The resulting blobs are quantized into a shared and interpretable codebook, yielding a discrete vocabulary of function-relevant protein substructures used to compute protein embeddings. We show that BioBlobs representations improve the performance of widely used protein encoders such as GVP-GNN across various PRL tasks. Our approach highlights the value of architectures that directly capture function-relevant protein substructures, enabling both improved predictive performance and mechanistic insight into protein function.", "published": "2025-10-02", "categories": ["q-bio.BM", "cs.AI"], "pdf_url": "http://arxiv.org/pdf/2510.01632v1", "primary_category": "q-bio.BM"}
{"id": "2510.01930", "title": "Precise Dynamics of Diagonal Linear Networks: A Unifying Analysis by Dynamical Mean-Field Theory", "authors": ["Sota Nishiyama", "Masaaki Imaizumi"], "summary": "Diagonal linear networks (DLNs) are a tractable model that captures several nontrivial behaviors in neural network training, such as initialization-dependent solutions and incremental learning. These phenomena are typically studied in isolation, leaving the overall dynamics insufficiently understood. In this work, we present a unified analysis of various phenomena in the gradient flow dynamics of DLNs. Using Dynamical Mean-Field Theory (DMFT), we derive a low-dimensional effective process that captures the asymptotic gradient flow dynamics in high dimensions. Analyzing this effective process yields new insights into DLN dynamics, including loss convergence rates and their trade-off with generalization, and systematically reproduces many of the previously observed phenomena. These findings deepen our understanding of DLNs and demonstrate the effectiveness of the DMFT approach in analyzing high-dimensional learning dynamics of neural networks.", "published": "2025-10-02", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2510.01930v1", "primary_category": "stat.ML"}
{"id": "2510.01335", "title": "Quantum-inspired Benchmark for Estimating Intrinsic Dimension", "authors": ["Aritra Das", "Joseph T. Iosue", "Victor V. Albert"], "summary": "Machine learning models can generalize well on real-world datasets. According to the manifold hypothesis, this is possible because datasets lie on a latent manifold with small intrinsic dimension (ID). There exist many methods for ID estimation (IDE), but their estimates vary substantially. This warrants benchmarking IDE methods on manifolds that are more complex than those in existing benchmarks. We propose a Quantum-Inspired Intrinsic-dimension Estimation (QuIIEst) benchmark consisting of infinite families of topologically non-trivial manifolds with known ID. Our benchmark stems from a quantum-optical method of embedding arbitrary homogeneous spaces while allowing for curvature modification and additive noise. The IDE methods tested were generally less accurate on QuIIEst manifolds than on existing benchmarks under identical resource allocation. We also observe minimal performance degradation with increasingly non-uniform curvature, underscoring the benchmark's inherent difficulty. As a result of independent interest, we perform IDE on the fractal Hofstadter's butterfly and identify which methods are capable of extracting the effective dimension of a space that is not a manifold.", "published": "2025-10-01", "categories": ["cs.LG", "cond-mat.dis-nn", "math.MG", "physics.data-an", "quant-ph"], "pdf_url": "http://arxiv.org/pdf/2510.01335v1", "primary_category": "cs.LG"}
{"id": "2510.01328", "title": "Combining complex Langevin dynamics with score-based and energy-based diffusion models", "authors": ["Gert Aarts", "Diaa E. Habibi", "Lingxiao Wang", "Kai Zhou"], "summary": "Theories with a sign problem due to a complex action or Boltzmann weight can sometimes be numerically solved using a stochastic process in the complexified configuration space. However, the probability distribution effectively sampled by this complex Langevin process is not known a priori and notoriously hard to understand. In generative AI, diffusion models can learn distributions, or their log derivatives, from data. We explore the ability of diffusion models to learn the distributions sampled by a complex Langevin process, comparing score-based and energy-based diffusion models, and speculate about possible applications.", "published": "2025-10-01", "categories": ["hep-lat", "cond-mat.dis-nn", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2510.01328v1", "primary_category": "hep-lat"}
{"id": "2510.01098", "title": "Theory of Scaling Laws for In-Context Regression: Depth, Width, Context and Time", "authors": ["Blake Bordelon", "Mary I. Letey", "Cengiz Pehlevan"], "summary": "We study in-context learning (ICL) of linear regression in a deep linear self-attention model, characterizing how performance depends on various computational and statistical resources (width, depth, number of training steps, batch size and data per context). In a joint limit where data dimension, context length, and residual stream width scale proportionally, we analyze the limiting asymptotics for three ICL settings: (1) isotropic covariates and tasks (ISO), (2) fixed and structured covariance (FS), and (3) where covariances are randomly rotated and structured (RRS). For ISO and FS settings, we find that depth only aids ICL performance if context length is limited. Alternatively, in the RRS setting where covariances change across contexts, increasing the depth leads to significant improvements in ICL, even at infinite context length. This provides a new solvable toy model of neural scaling laws which depends on both width and depth of a transformer and predicts an optimal transformer shape as a function of compute. This toy model enables computation of exact asymptotics for the risk as well as derivation of powerlaws under source/capacity conditions for the ICL tasks.", "published": "2025-10-01", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG"], "pdf_url": "http://arxiv.org/pdf/2510.01098v1", "primary_category": "stat.ML"}
{"id": "2510.00504", "title": "A universal compression theory: Lottery ticket hypothesis and superpolynomial scaling laws", "authors": ["Hong-Yi Wang", "Di Luo", "Tomaso Poggio", "Isaac L. Chuang", "Liu Ziyin"], "summary": "When training large-scale models, the performance typically scales with the number of parameters and the dataset size according to a slow power law. A fundamental theoretical and practical question is whether comparable performance can be achieved with significantly smaller models and substantially less data. In this work, we provide a positive and constructive answer. We prove that a generic permutation-invariant function of $d$ objects can be asymptotically compressed into a function of $\\operatorname{polylog} d$ objects with vanishing error. This theorem yields two key implications: (Ia) a large neural network can be compressed to polylogarithmic width while preserving its learning dynamics; (Ib) a large dataset can be compressed to polylogarithmic size while leaving the loss landscape of the corresponding model unchanged. (Ia) directly establishes a proof of the \\textit{dynamical} lottery ticket hypothesis, which states that any ordinary network can be strongly compressed such that the learning dynamics and result remain unchanged. (Ib) shows that a neural scaling law of the form $L\\sim d^{-\\alpha}$ can be boosted to an arbitrarily fast power law decay, and ultimately to $\\exp(-\\alpha' \\sqrt[m]{d})$.", "published": "2025-10-01", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "pdf_url": "http://arxiv.org/pdf/2510.00504v1", "primary_category": "stat.ML"}
