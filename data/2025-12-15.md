<div id=toc></div>

# Table of Contents

- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [1] [Stable spectral neural operator for learning stiff PDE systems from limited data](https://arxiv.org/abs/2512.11686)
*Rui Zhang, Han Wan, Yang Liu, Hao Sun*

Main category: physics.comp-ph

TL;DR: 本文提出了一种名为Stable Spectral Neural Operator (SSNO) 的新型神经网络框架，用于从有限数据中学习 stiff PDEs 系统，它在频谱域中嵌入物理结构，并采用鲁棒的积分因子时间步进方案。


<details>
  <summary>Details</summary>
Motivation: 现有方法在建模 stiff PDEs 系统时面临挑战：纯数据驱动方法需要大量数据，而基于已知方程的方法受限于对时间步长的要求。本文旨在克服这些限制，实现数据效率高、泛化能力强的 PDE 建模。

Method: SSNO 是一种无方程学习框架，它通过在神经网络架构中嵌入频谱感知的结构来学习底层物理规律。它自动学习频率域中的局部和全局空间交互，并使用积分因子时间步进方案处理 stiff 系统。

Result: 在多个 2D 和 3D 基准测试中，SSNO 的预测误差比领先模型低一个到两个数量级，并且只需要少量（2-5）训练轨迹即可实现强大的泛化能力，对分布外条件具有鲁棒性。

Conclusion: SSNO 提供了一种鲁棒且可泛化的方法，可以在没有显式先验知识的情况下，从有限数据中学习 stiff 空间时间动态，为科学和工程领域提供了一种新的建模工具。

Abstract: Accurate modeling of spatiotemporal dynamics is crucial to understanding complex phenomena across science and engineering. However, this task faces a fundamental challenge when the governing equations are unknown and observational data are sparse. System stiffness, the coupling of multiple time-scales, further exacerbates this problem and hinders long-term prediction. Existing methods fall short: purely data-driven methods demand massive datasets, whereas physics-aware approaches are constrained by their reliance on known equations and fine-grained time steps. To overcome these limitations, we introduce an equation-free learning framework, namely, the Stable Spectral Neural Operator (SSNO), for modeling stiff partial differential equation (PDE) systems based on limited data. Instead of encoding specific equation terms, SSNO embeds spectrally inspired structures in its architecture, yielding strong inductive biases for learning the underlying physics. It automatically learns local and global spatial interactions in the frequency domain, while handling system stiffness with a robust integrating factor time-stepping scheme. Demonstrated across multiple 2D and 3D benchmarks in Cartesian and spherical geometries, SSNO achieves prediction errors one to two orders of magnitude lower than leading models. Crucially, it shows remarkable data efficiency, requiring only very few (2--5) training trajectories for robust generalization to out-of-distribution conditions. This work offers a robust and generalizable approach to learning stiff spatiotemporal dynamics from limited data without explicit \textit{a priori} knowledge of PDE terms.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [2] [Emergence of Nonequilibrium Latent Cycles in Unsupervised Generative Modeling](https://arxiv.org/abs/2512.11415)
*Marco Baiesi, Alberto Rosso*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种基于非平衡态马尔可夫链的生成模型，该模型通过训练自发地产生潜变量循环，从而避免了传统平衡态模型在探索配置空间时的局限性，并提升了生成性能。


<details>
  <summary>Details</summary>
Motivation: 传统生成模型（如RBM）依赖于可逆的吉布斯采样，导致探索配置空间缓慢，难以充分学习数据分布。本文旨在探索将非平衡态统计物理引入到生成模型中，以提升生成性能。

Method: 引入了一种具有两个独立参数化转移矩阵的马尔可夫链模型，定义了非平衡态的稳态。通过最大化似然函数，该系统趋向于具有有限熵产和持久潜变量空间概率流的非平衡态稳态。模型训练过程中，潜变量循环并非由架构预设，而是自发产生。

Result: 训练得到的模型总是违反详细平衡，即前向和反向条件转移之间的平衡被打破。性能最佳的模型表现出非平衡态动态，并且能够更忠实地重现数据的经验分布。

Conclusion: 本文的研究表明，在潜变量模型中引入不可逆性可以增强生成性能，为机器学习和非平衡态统计物理的交叉研究提供了新的视角。

Abstract: We show that nonequilibrium dynamics can play a constructive role in unsupervised machine learning by inducing the spontaneous emergence of latent-state cycles. We introduce a model in which visible and hidden variables interact through two independently parametrized transition matrices, defining a Markov chain whose steady state is intrinsically out of equilibrium. Likelihood maximization drives this system toward nonequilibrium steady states with finite entropy production, reduced self-transition probabilities, and persistent probability currents in the latent space. These cycles are not imposed by the architecture but arise from training, and models that develop them avoid the low-log-likelihood regime associated with nearly reversible dynamics while more faithfully reproducing the empirical distribution of data classes. Compared with equilibrium approaches such as restricted Boltzmann machines, our model breaks the detailed balance between the forward and backward conditional transitions and relies on a log-likelihood gradient that depends explicitly on the last two steps of the Markov chain. Hence, this exploration of the interface between nonequilibrium statistical physics and modern machine learning suggests that introducing irreversibility into latent-variable models can enhance generative performance.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [3] [Task-Specific Sparse Feature Masks for Molecular Toxicity Prediction with Chemical Language Models](https://arxiv.org/abs/2512.11412)
*Kwun Sy Lee, Jiawei Chen, Fuk Sheng Ford Chung, Tianyu Zhao, Zhenyuan Chen, Debby D. Wang*

Main category: cs.CE

TL;DR: 本文提出了一种新的多任务学习框架，通过稀疏化注意力模块，在分子毒性预测中提升模型准确性和可解释性，并揭示影响预测的关键分子片段。


<details>
  <summary>Details</summary>
Motivation: 现有分子毒性预测模型通常是黑盒模型，缺乏结构洞察力，难以应用于高风险的安全决策。同时，传统的共享参数多任务学习方法缺乏任务特定特征选择机制，可能导致负迁移。

Method: 该框架整合了共享的化学语言模型和任务特定的注意力模块，并对注意力模块施加L1稀疏惩罚，迫使模型关注每个毒性终点站的关键分子片段。该框架端到端训练，并可应用于各种基于Transformer的骨干网络。

Result: 在ClinTox、SIDER和Tox21基准数据集上，该方法始终优于单任务和标准多任务学习基线。稀疏的注意力权重提供了化学直观的可视化，揭示了影响预测的具体片段。

Conclusion: 该研究提供了一种在分子毒性预测中提高准确性和可解释性的有效方法，有助于理解模型决策过程，并为药物发现和化学安全筛选提供更可靠的依据。

Abstract: Reliable in silico molecular toxicity prediction is a cornerstone of modern drug discovery, offering a scalable alternative to experimental screening. However, the black-box nature of state-of-the-art models remains a significant barrier to adoption, as high-stakes safety decisions demand verifiable structural insights alongside predictive performance. To address this, we propose a novel multi-task learning (MTL) framework designed to jointly enhance accuracy and interpretability. Our architecture integrates a shared chemical language model with task-specific attention modules. By imposing an L1 sparsity penalty on these modules, the framework is constrained to focus on a minimal set of salient molecular fragments for each distinct toxicity endpoint. The resulting framework is trained end-to-end and is readily adaptable to various transformer-based backbones. Evaluated on the ClinTox, SIDER, and Tox21 benchmark datasets, our approach consistently outperforms both single-task and standard MTL baselines. Crucially, the sparse attention weights provide chemically intuitive visualizations that reveal the specific fragments influencing predictions, thereby enhancing insight into the model's decision-making process.

</details>
