{"id": "2602.08216", "title": "Thermodynamic Isomorphism of Transformers: A Lagrangian Approach to Attention Dynamics", "authors": ["Gunn Kim"], "summary": "Although the Transformer architecture has revolutionized artificial intelligence, its underlying mechanisms remain largely heuristic and lack a unified physical theory. In this work, we propose a first-principles framework for information dynamics, treating the attention mechanism as a physical system governed by the principle of least action rather than as an algorithmic optimization. By mapping information states to a Riemannian manifold with the Fisher information metric, we derive the intelligence Lagrangian. We show that the softmax function corresponds to the unique thermodynamic equilibrium state that minimizes the Helmholtz free energy of the information gas. In addition, we identify the query-key interaction as an electrodynamic coupling between an external field and an intrinsic dipole moment. This theory establishes the first law of information thermodynamics, unifying inference (mechanical work) and learning (chemical evolution). It also explains emergent phenomena, such as scaling laws and grokking, as phase transitions characterized by the divergence of specific heat. Finally, we discuss how rotational symmetry breaking in the attention manifold generates massless Goldstone bosons, providing a field-theoretic perspective on rotary positional embeddings (RoPE). Our work connects Statistical Physics and Deep Learning, laying the groundwork for a general theory of physics-based intelligence.", "abs": "", "categories": ["cs.LG", "cond-mat.stat-mech", "stat.ML"], "AI": {"tldr": "本文将Transformer的注意力机制视为一个物理系统，通过拉格朗日方法分析其信息动力学，揭示了其与统计物理的联系，并解释了Transformer的涌现现象。", "motivation": "Transformer架构虽然取得了巨大成功，但其底层机制缺乏统一的物理理论。本文旨在建立一个基于物理原理的信息动力学框架，解释Transformer的运作机制和涌现行为。", "method": "将信息状态映射到黎曼流形，使用Fisher信息度量，推导了智能拉格朗日量。通过变分计算，证明了Softmax函数对应于信息气体亥姆霍兹自由能的最小化状态，并将query-key交互视为外部场与内禀偶极矩之间的电动力耦合。", "result": "建立了信息热力学第一定律，将推理和学习统一起来。解释了Scaling Laws和Grokking等涌现现象为特定热容发散的相变。发现了旋转对称性破缺与Goldstone玻色子的关系，为旋转位置嵌入（RoPE）提供了场论视角。", "conclusion": "本文将统计物理和深度学习联系起来，为基于物理的智能通用理论奠定了基础，为理解和设计更强大的AI模型提供了新的思路。"}}
{"id": "2602.07548", "title": "Capturing the Topological Phase Transition and Thermodynamics of the 2D XY Model via Manifold-Aware Score-Based Generative Modeling", "authors": ["Pratyush Jha"], "summary": "The application of generative modeling to many-body physics offers a promising pathway for analyzing high-dimensional state spaces of spin systems. However, unlike computer vision tasks where visual fidelity suffices, physical systems require the rigorous reproduction of higher-order statistical moments and thermodynamic quantities. While Score-Based Generative Models (SGMs) have emerged as a powerful tool, their standard formulation on Euclidean embedding space is ill-suited for continuous spin systems, where variables inherently reside on a manifold. In this work, we demonstrate that training on the Euclidean space compromises the model's ability to learn the target distribution as it prioritizes to learn the manifold constraints. We address this limitation by proposing the use of Manifold-Aware Score-Based Generative Modeling framework applied to the 64x64 2D XY model (a 4096-dimensional torus). We show that our method estimates the theoretical Boltzmann score with superior precision compared to standard diffusion models. Consequently, we successfully capture the Berezinskii-Kosterlitz Thouless (BKT) phase transition and accurately reproduce second-moment quantities, such as heat capacity without explicit feature engineering. Furthermore, we demonstrate zero-shot generalization to unseen lattice sizes, accurately recovering the physics of variable system scales without retraining. Since this approach bypasses domain-specific feature engineering, it remains intrinsically generalizable to other continuous spin systems.", "abs": "", "categories": ["cond-mat.stat-mech", "cs.LG"], "AI": {"tldr": "本文提出了一种基于流形感知的得分生成模型，用于精确捕捉二维XY模型的拓扑相变和热力学性质，避免了传统方法在欧几里得空间中训练带来的局限性。", "motivation": "传统生成模型在处理高维物理系统时，尤其是在连续自旋系统中，由于变量位于流形上，在欧几里得空间中训练会导致模型无法有效学习目标分布，难以准确重现高阶统计矩和热力学量。", "method": "本文提出了一种流形感知的得分生成模型框架，将其应用于64×64的二维XY模型。该方法在流形空间中进行训练，避免了对流形约束的学习优先级问题。", "result": "实验结果表明，该方法能够以更高的精度估计理论玻尔兹曼得分，成功捕捉Berezinskii-Kosterlitz-Thouless (BKT) 相变，并准确重现比热容等二阶统计量，且无需显式特征工程，并实现了对未见过的晶格尺寸的零样本泛化。", "conclusion": "该方法绕过了领域特定的特征工程，具有内在的泛化性，适用于其他连续自旋系统，为分析高维物理系统提供了一种通用的、无需特定特征工程的解决方案。"}}
{"id": "2602.07087", "title": "Electron-Informed Coarse-Graining Molecular Representation Learning for Real-World Molecular Physics", "authors": ["Gyoung S. Na", "Chanyoung Park"], "summary": "Various representation learning methods for molecular structures have been devised to accelerate data-driven chemistry. However, the representation capabilities of existing methods are essentially limited to atom-level information, which is not sufficient to describe real-world molecular physics. Although electron-level information can provide fundamental knowledge about chemical compounds beyond the atom-level information, obtaining the electron-level information in real-world molecules is computationally impractical and sometimes infeasible. We propose a method for learning electron-informed molecular representations without additional computation costs by transferring readily accessible electron-level information about small molecules to large molecules of our interest. The proposed method achieved state-of-the-art prediction accuracy on extensive benchmark datasets containing experimentally observed molecular physics. The source code for HEDMoL is available at https://github.com/ngs00/HEDMoL.", "abs": "", "categories": ["physics.chem-ph", "cs.AI", "cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种名为HEDMoL的新方法，通过将小分子的电子信息迁移到大分子，学习电子信息驱动的分子表示，从而提升对真实分子物理性质的预测能力。", "motivation": "现有基于图神经网络(GNN)的分子表示学习方法主要依赖原子层结构，忽略了电子层信息，而电子层信息对于理解和预测分子物理性质至关重要。直接计算复杂分子的电子结构计算成本过高，难以实现。", "method": "HEDMoL方法通过一种分层的方式，将小分子的电子信息迁移到感兴趣的大分子，从而在不增加额外计算成本的情况下，学习电子信息驱动的分子表示。该方法利用图神经网络学习潜在的分子嵌入。", "result": "HEDMoL在多个实验数据集上取得了最先进的预测准确率，证明了其有效性。", "conclusion": "HEDMoL提供了一种有效且高效的方法，利用电子信息改进分子表示学习，为数据驱动的化学研究提供了新的思路，并有望推动分子物理性质的预测和理解。"}}
{"id": "2602.07192", "title": "Systematic Performance Assessment of Deep Material Networks for Multiscale Material Modeling", "authors": ["Xiaolong He", "Haoyan Wei", "Wei Hu", "Henan Mao", "C. T. Wu"], "summary": "Deep Material Networks (DMNs) are structure-preserving, mechanistic machine learning models that embed micromechanical principles into their architectures, enabling strong extrapolation capabilities and significant potential to accelerate multiscale modeling of complex microstructures. A key advantage of these models is that they can be trained exclusively on linear elastic data and then generalized to nonlinear inelastic regimes during online prediction. Despite their growing adoption, systematic evaluations of their performance across the full offline-online pipeline remain limited. This work presents a comprehensive comparative assessment of DMNs with respect to prediction accuracy, computational efficiency, and training robustness. We investigate the effects of offline training choices, including initialization, batch size, training data size, and activation regularization on online generalization performance and uncertainty. The results demonstrate that both prediction error and variance decrease with increasing training data size, while initialization and batch size can significantly influence model performance. Moreover, activation regularization is shown to play a critical role in controlling network complexity and therefore generalization performance. Compared with the original DMN, the rotation-free Interaction-based Material Network (IMN) formulation achieves a 3.4x - 4.7x speed-up in offline training, while maintaining comparable online prediction accuracy and computational efficiency. These findings clarify key trade-offs between model expressivity and efficiency in structure-preserving material networks and provide practical guidance for their deployment in multiscale material modeling.", "abs": "", "categories": ["cs.LG", "cs.CE", "math.NA", "physics.comp-ph"], "AI": {"tldr": "本文系统评估了深材料网络 (DMN) 在多尺度材料建模中的性能，重点关注离线训练选择对在线泛化和不确定性的影响，并比较了改进的 IMN 模型。", "motivation": "尽管深材料网络 (DMN) 在加速多尺度材料建模方面具有潜力，但对其完整离线-在线流程的系统评估仍然有限。本文旨在填补这一空白，并为 DMN 的实际部署提供指导。", "method": "研究人员对 DMN 进行了全面的比较评估，考察了离线训练选择（如初始化、批次大小、训练数据大小和激活正则化）对在线泛化性能和不确定性的影响。此外，他们还比较了原始 DMN 和改进的旋转自由交互式材料网络 (IMN) 的性能。", "result": "研究结果表明，预测误差和方差随着训练数据大小的增加而减小，初始化和批次大小会显著影响模型性能，而激活正则化在控制网络复杂性和泛化性能方面起着关键作用。IMN 在离线训练中实现了 3.4-4.7 倍的加速，同时保持了可比的在线预测精度和计算效率。", "conclusion": "本文阐明了结构保持材料网络中模型表达性和效率之间的关键权衡，并为多尺度材料建模中的 DMN 部署提供了实用指导，有助于加速先进材料的发现、优化和设计。"}}
{"id": "2602.08849", "title": "Cutting Through the Noise: On-the-fly Outlier Detection for Robust Training of Machine Learning Interatomic Potentials", "authors": ["Terry C. W. Lam", "Niamh O'Neill", "Christoph Schran", "Lars L. Schaaf"], "summary": "The accuracy of machine learning interatomic potentials suffers from reference data that contains numerical noise. Often originating from unconverged or inconsistent electronic-structure calculations, this noise is challenging to identify. Existing mitigation strategies such as manual filtering or iterative refinement of outliers, require either substantial expert effort or multiple expensive retraining cycles, making them difficult to scale to large datasets. Here, we introduce an on-the-fly outlier detection scheme that automatically down-weights noisy samples, without requiring additional reference calculations. By tracking the loss distribution via an exponential moving average, this unsupervised method identifies outliers throughout a single training run. We show that this approach prevents overfitting and matches the performance of iterative refinement baselines with significantly reduced overhead. The method's effectiveness is demonstrated by recovering accurate physical observables for liquid water from unconverged reference data, including diffusion coefficients. Furthermore, we validate its scalability by training a foundation model for organic chemistry on the SPICE dataset, where it reduces energy errors by a factor of three. This framework provides a simple, automated solution for training robust models on imperfect datasets across dataset sizes.", "abs": "", "categories": ["stat.ML", "cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "AI": {"tldr": "本文提出了一种无需额外参考计算的在线异常值检测方案，用于训练更鲁棒的机器学习原子势（MLIP），有效降低了噪声数据对模型训练的影响。", "motivation": "机器学习原子势（MLIP）的准确性受参考数据中数值噪声的影响，现有的过滤或迭代优化方法需要大量人工干预或多次昂贵的重训练，难以扩展到大型数据集。", "method": "通过跟踪损失分布的指数移动平均，该方法在单次训练过程中自动识别和降权异常值，实现无监督的异常值检测。", "result": "实验表明，该方法可以防止过拟合，并达到迭代优化基线的性能，同时显著减少了计算开销。在液态水和有机化学SPICE数据集上验证了其有效性和可扩展性，分别恢复了准确的物理可观数和将能量误差降低了三倍。", "conclusion": "该框架提供了一种简单、自动的解决方案，用于在不同规模的数据集上训练鲁棒的模型，特别适用于处理不完美的数据集，为机器学习原子势的训练提供了新的思路。"}}
{"id": "2602.07735", "title": "TerraBind: Fast and Accurate Binding Affinity Prediction through Coarse Structural Representations", "authors": ["Matteo Rossi", "Ryan Pederson", "Miles Wang-Henderson", "Ben Kaufman", "Edward C. Williams", "Carl Underkoffler", "Owen Lewis Howell", "Adrian Layer", "Stephan Thaler", "Narbe Mardirossian", "John Anthony Parkhill"], "summary": "We present TerraBind, a foundation model for protein-ligand structure and binding affinity prediction that achieves 26-fold faster inference than state-of-the-art methods while improving affinity prediction accuracy by $\\sim$20\\%. Current deep learning approaches to structure-based drug design rely on expensive all-atom diffusion to generate 3D coordinates, creating inference bottlenecks that render large-scale compound screening computationally intractable. We challenge this paradigm with a critical hypothesis: full all-atom resolution is unnecessary for accurate small molecule pose and binding affinity prediction. TerraBind tests this hypothesis through a coarse pocket-level representation (protein C$_β$ atoms and ligand heavy atoms only) within a multimodal architecture combining COATI-3 molecular encodings and ESM-2 protein embeddings that learns rich structural representations, which are used in a diffusion-free optimization module for pose generation and a binding affinity likelihood prediction module. On structure prediction benchmarks (FoldBench, PoseBusters, Runs N' Poses), TerraBind matches diffusion-based baselines in ligand pose accuracy. Crucially, TerraBind outperforms Boltz-2 by $\\sim$20\\% in Pearson correlation for binding affinity prediction on both a public benchmark (CASP16) and a diverse proprietary dataset (18 biochemical/cell assays). We show that the affinity prediction module also provides well-calibrated affinity uncertainty estimates, addressing a critical gap in reliable compound prioritization for drug discovery. Furthermore, this module enables a continual learning framework and a hedged batch selection strategy that, in simulated drug discovery cycles, achieves 6$\\times$ greater affinity improvement of selected molecules over greedy-based approaches.", "abs": "", "categories": ["cs.LG", "q-bio.BM"], "AI": {"tldr": "TerraBind是一种新的蛋白质-配体结合亲和力预测模型，它采用粗粒度结构表示，实现了比现有方法快26倍的推理速度，同时将亲和力预测准确率提高了约20%。", "motivation": "现有基于深度学习的药物设计方法依赖于昂贵的全原子扩散过程，导致大规模化合物筛选计算不可行。研究旨在挑战全原子分辨率对于准确预测小分子姿态和结合亲和力是否必要，并解决现有模型计算效率低下的问题。", "method": "TerraBind采用多模态架构，结合COATI-3分子编码和ESM-2蛋白质嵌入，使用蛋白质Cβ原子和配体重原子进行粗粒度口袋级表示。该模型包含一个无扩散优化模块用于姿态生成和一个结合亲和力似然预测模块，并在结构预测基准测试中与扩散基线方法相匹配。", "result": "TerraBind在CASP16公共基准和专有数据集上，在皮尔逊相关系数方面比Boltz-2提高了约20%的结合亲和力预测准确率。此外，该模型还提供了校准良好的亲和力不确定性估计，并在模拟药物发现周期中，通过持续学习框架和对冲批次选择策略，实现了比基于贪婪方法6倍的分子亲和力改进。", "conclusion": "TerraBind证明了粗粒度结构表示在结合亲和力预测中的有效性，显著提高了计算效率，并提供了可靠的不确定性估计，为药物发现提供了更快的化合物筛选和更可靠的化合物优先级排序。"}}
