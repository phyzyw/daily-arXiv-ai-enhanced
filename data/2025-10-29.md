<div id=toc></div>

# Table of Contents

- [stat.ML](#stat.ML) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [1] [Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation](https://arxiv.org/abs/2510.24616)
*Jean Barbier, Francesco Camilli, Minh-Toan Nguyen, Mauro Pastore, Rudy Skerk*

Main category: stat.ML

TL;DR: 本文利用统计物理方法研究了多层感知机（MLP）在插值状态下的监督学习，揭示了深度学习模型在特征学习过程中的学习过渡和层间、神经元间的非均匀专业化现象。


<details>
  <summary>Details</summary>
Motivation: 现有统计物理方法难以有效分析深度学习模型中的特征学习效果，尤其是在模型宽度和数据量相当的插值状态下。本文旨在填补这一空白，深入理解深度学习模型的表达能力和泛化能力。

Method: 本文采用匹配的教师-学生设置，研究了宽度与输入维度成比例的多层感知机在插值状态下的监督学习。通过分析贝叶斯最优设置，考察了深度、非线性以及有限宽度对神经网络的影响。

Result: 研究发现，在充足的数据下，模型通过“专业化”向目标进行学习，但训练算法可能陷入次优解。专业化过程在层间和神经元间呈现非均匀性，且更深的目标更难学习。

Conclusion: 本文的研究为理解深度学习模型中的特征学习机制提供了新的视角，揭示了深度、非线性、有限宽度等因素的影响，这些发现可能对更广泛的神经网络研究具有潜在意义。

Abstract: For three decades statistical physics has been providing a framework to analyse neural networks. A long-standing question remained on its capacity to tackle deep learning models capturing rich feature learning effects, thus going beyond the narrow networks or kernel methods analysed until now. We positively answer through the study of the supervised learning of a multi-layer perceptron. Importantly, (i) its width scales as the input dimension, making it more prone to feature learning than ultra wide networks, and more expressive than narrow ones or with fixed embedding layers; and (ii) we focus on the challenging interpolation regime where the number of trainable parameters and data are comparable, which forces the model to adapt to the task. We consider the matched teacher-student setting. It provides the fundamental limits of learning random deep neural network targets and helps in identifying the sufficient statistics describing what is learnt by an optimally trained network as the data budget increases. A rich phenomenology emerges with various learning transitions. With enough data optimal performance is attained through model's "specialisation" towards the target, but it can be hard to reach for training algorithms which get attracted by sub-optimal solutions predicted by the theory. Specialisation occurs inhomogeneously across layers, propagating from shallow towards deep ones, but also across neurons in each layer. Furthermore, deeper targets are harder to learn. Despite its simplicity, the Bayesian-optimal setting provides insights on how the depth, non-linearity and finite (proportional) width influence neural networks in the feature learning regime that are potentially relevant way beyond it.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Accelerating IC Thermal Simulation Data Generation via Block Krylov and Operator Action](https://arxiv.org/abs/2510.23221)
*Hong Wang, Wenkai Yang, Jie Wang, Huanshuo Dong, Zijie Geng, Zhen Huang, Depeng Xie, Zhezheng Hao, Hande Dong*

Main category: cs.AI

TL;DR: 本文提出了一种名为BlocKOA的新算法，用于加速集成电路(IC)热模拟数据的生成，同时提高生成数据的精度。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法（如神经网络算子）在IC热模拟中表现出潜力，但需要大量的训练数据，导致计算成本高昂。现有算法未能有效利用IC热方程的特定结构，造成冗余计算。

Method: BlocKOA算法首先利用块 Krylov 算法基于热方程的结构快速获得少数基本解，然后将这些基本解组合成满足物理约束的众多温度分布。最后，对这些函数应用热算子以确定热源分布，从而高效地生成精确的数据点。

Result: 实验结果表明，BlocKOA在生成5000个具有不同物理参数和IC结构的芯片的热模拟数据时，实现了420倍的速度提升。使用BlocKOA生成的数据训练的数据驱动方法，仅需4%的生成时间，就能达到与现有方法相当的性能。

Conclusion: BlocKOA算法显著加速了IC热模拟数据的生成，并提高了数据精度，为数据驱动方法在IC热模拟中的实际应用提供了有力支持。

Abstract: Recent advances in data-driven approaches, such as neural operators (NOs), have shown substantial efficacy in reducing the solution time for integrated circuit (IC) thermal simulations. However, a limitation of these approaches is requiring a large amount of high-fidelity training data, such as chip parameters and temperature distributions, thereby incurring significant computational costs. To address this challenge, we propose a novel algorithm for the generation of IC thermal simulation data, named block Krylov and operator action (BlocKOA), which simultaneously accelerates the data generation process and enhances the precision of generated data. BlocKOA is specifically designed for IC applications. Initially, we use the block Krylov algorithm based on the structure of the heat equation to quickly obtain a few basic solutions. Then we combine them to get numerous temperature distributions that satisfy the physical constraints. Finally, we apply heat operators on these functions to determine the heat source distributions, efficiently generating precise data points. Theoretical analysis shows that the time complexity of BlocKOA is one order lower than the existing method. Experimental results further validate its efficiency, showing that BlocKOA achieves a 420-fold speedup in generating thermal simulation data for 5000 chips with varying physical parameters and IC structures. Even with just 4% of the generation time, data-driven approaches trained on the data generated by BlocKOA exhibits comparable performance to that using the existing method.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [A Physics-informed Multi-resolution Neural Operator](https://arxiv.org/abs/2510.23810)
*Sumanta Roy, Bahador Bahmani, Ioannis G. Kevrekidis, Michael D. Shields*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息的、多分辨率神经网络算子 (Physics-informed Multi-resolution Neural Operator) 框架，该框架无需训练数据即可学习偏微分方程的解算子，并能处理不同分辨率的输入数据。


<details>
  <summary>Details</summary>
Motivation: 传统的神经网络算子学习方法依赖大量的训练数据，且需要额外的求解器生成数据，成本高昂。此外，当参数变化时需要重新训练。本文旨在解决这些问题，提出一种数据自由且能处理多分辨率数据的算子学习方法。

Method: 该方法将任意分辨率的输入函数投影到潜在嵌入空间，使用预训练的基函数。然后，通过一个简单的多层感知机 (MLP) 逼近偏微分方程对应的算子，该MLP接收潜在编码和时空坐标作为输入，输出物理空间中的解。同时，利用有限差分法在物理空间中强制执行偏微分方程。

Result: 在多个具有多分辨率数据的数值例子中，对该方法进行了验证和性能评估，结果表明其有效性。

Conclusion: 该研究提供了一种数据自由且适用于多分辨率数据的物理信息神经网络算子学习框架，减少了对传统求解器的依赖，并为解决参数变化频繁的偏微分方程问题提供了一种新的途径。

Abstract: The predictive accuracy of operator learning frameworks depends on the quality and quantity of available training data (input-output function pairs), often requiring substantial amounts of high-fidelity data, which can be challenging to obtain in some real-world engineering applications. These datasets may be unevenly discretized from one realization to another, with the grid resolution varying across samples. In this study, we introduce a physics-informed operator learning approach by extending the Resolution Independent Neural Operator (RINO) framework to a fully data-free setup, addressing both challenges simultaneously. Here, the arbitrarily (but sufficiently finely) discretized input functions are projected onto a latent embedding space (i.e., a vector space of finite dimensions), using pre-trained basis functions. The operator associated with the underlying partial differential equations (PDEs) is then approximated by a simple multi-layer perceptron (MLP), which takes as input a latent code along with spatiotemporal coordinates to produce the solution in the physical space. The PDEs are enforced via a finite difference solver in the physical space. The validation and performance of the proposed method are benchmarked on several numerical examples with multi-resolution data, where input functions are sampled at varying resolutions, including both coarse and fine discretizations.

</details>
