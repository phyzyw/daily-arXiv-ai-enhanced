<div id=toc></div>

# Table of Contents

- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [1] [Data coarse graining can improve model performance](https://arxiv.org/abs/2509.14498)
*Alex Nguyen, David J. Schwab, Vudtiwat Ngampruetikorn*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了数据粗粒化（coarse graining）如何改善模型性能，揭示了在特定条件下，去除不相关特征反而能提升泛化能力，并提供了一个基于统计物理的理论解释。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习中存在信息损失却能提升泛化性能的现象（如数据剪枝、数据增强），以及双下降现象，本文旨在理解这些现象的本质，并探索如何利用数据粗粒化来引导算法关注更相关的特征。

Method: 本文构建了一个高维、岭回归的解析模型，并借鉴了统计物理中的重整化群思想，分析了系统地丢弃特征的粗粒化方案，考察了不同粗粒化方案（高通滤波和低通滤波）对预测风险的影响。

Result: 研究发现预测风险与粗粒化程度呈非单调关系。高通滤波（去除不相关、低信号特征）可以改善泛化能力，而低通滤波（整合相关、高信号特征）则会降低性能。通过最优正则化，证明了这种非单调性是数据粗粒化的独特效应，而非双下降的伪影。

Conclusion: 本文提供了一个清晰的解析解释，说明了为什么谨慎的数据增强有效：它去除了不相关的自由度，并隔离了更具预测性的信号。研究结果强调了数据结构对风险景观的复杂影响，并表明统计物理的思想可以为理解现代机器学习现象提供有益的视角。

Abstract: Lossy data transformations by definition lose information. Yet, in modern machine learning, methods like data pruning and lossy data augmentation can help improve generalization performance. We study this paradox using a solvable model of high-dimensional, ridge-regularized linear regression under 'data coarse graining.' Inspired by the renormalization group in statistical physics, we analyze coarse-graining schemes that systematically discard features based on their relevance to the learning task. Our results reveal a nonmonotonic dependence of the prediction risk on the degree of coarse graining. A 'high-pass' scheme--which filters out less relevant, lower-signal features--can help models generalize better. By contrast, a 'low-pass' scheme that integrates out more relevant, higher-signal features is purely detrimental. Crucially, using optimal regularization, we demonstrate that this nonmonotonicity is a distinct effect of data coarse graining and not an artifact of double descent. Our framework offers a clear, analytical explanation for why careful data augmentation works: it strips away less relevant degrees of freedom and isolates more predictive signals. Our results highlight a complex, nonmonotonic risk landscape shaped by the structure of the data, and illustrate how ideas from statistical physics provide a principled lens for understanding modern machine learning phenomena.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [2] [Towards universal property prediction in Cartesian space: TACE is all you need](https://arxiv.org/abs/2509.14961)
*Zemin Xu, Wenbo Xie, Daiqian Xie, P. Hu*

Main category: stat.ML

TL;DR: 本文提出了一种名为TACE的统一框架，它完全在笛卡尔空间中表征原子环境，用于系统地预测任意结构相关的张量性质，无需依赖球谐函数。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习原子间势能函数方法通常依赖于球谐函数表示，而本文旨在克服其局限性，建立一种更通用、更高效的框架，以预测各种物理性质，包括张量性质。

Method: TACE通过将原子环境分解为笛卡尔张量的完整层次结构，确保对称性一致的表示，并自然地编码不变性和协变性约束。它还整合了通用嵌入，灵活地集成各种属性，并使用潜在埃瓦尔求和模块处理长程相互作用。

Result: TACE在有限分子和扩展材料的各种基准测试中，在准确性、稳定性和效率方面达到了或超过了领先的等变框架，包括域内和域外基准、谱、海森矩阵、外部场响应、带电系统、磁性系统、多保真度训练和多相催化系统。

Conclusion: TACE弥合了标量和张量建模之间的差距，建立了一种笛卡尔空间范例，统一并扩展了基于球谐函数的方法，为新一代通用原子学机器学习模型奠定了基础，能够系统地捕捉几何形状、场和材料性质之间的复杂相互作用。

Abstract: Machine learning has revolutionized atomistic simulations and materials science, yet current approaches often depend on spherical-harmonic representations. Here we introduce the Tensor Atomic Cluster Expansion and Tensor Moment Potential, the first unified framework formulated entirely in Cartesian space for the systematic prediction of arbitrary structure-determined tensorial properties. TACE achieves this by decomposing atomic environments into a complete hierarchy of (irreducible) Cartesian tensors, ensuring symmetry-consistent representations that naturally encode invariance and equivariance constraints. Beyond geometry, TACE incorporates universal embeddings that flexibly integrate diverse attributes including basis sets, charges, magnetic moments and field perturbations. This allows explicit control over external invariants and equivariants in the prediction process. Long-range interactions are also accurately described through the Latent Ewald Summation module within the short-range approximation, providing a rigorous yet computationally efficient treatment of electrostatic interactions. We demonstrate that TACE attains accuracy, stability, and efficiency on par with or surpassing leading equivariant frameworks across finite molecules and extended materials, including in-domain and out-of-domain benchmarks, spectra, hessians, external-field response, charged systems, magnetic systems, multi-fidelity training, and heterogeneous catalytic systems. Crucially, TACE bridges scalar and tensorial modeling and establishes a Cartesian-space paradigm that unifies and extends beyond the design space of spherical-harmonic-based methods. This work lays the foundation for a new generation of universal atomistic machine learning models capable of systematically capturing the rich interplay of geometry, fields and material properties within a single coherent framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [TICA-Based Free Energy Matching for Machine-Learned Molecular Dynamics](https://arxiv.org/abs/2509.14600)
*Alexander Aghili, Andy Bruce, Daniel Sabo, Razvan Marinescu*

Main category: cs.LG

TL;DR: 本文提出了一种将能量匹配融入机器学习分子动力学模型训练的框架，旨在更好地捕捉分子系统的全貌热力学景观。虽然当前实现未见显著性能提升，但揭示了模型泛化自由能表面的趋势。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的力匹配方法在捕捉分子系统全局热力学结构方面存在局限性，可能无法区分低能量的亚稳态。为了解决这个问题，研究者希望通过能量匹配来改进粗粒化建模。

Method: 研究者将能量匹配项添加到损失函数中，利用玻尔兹曼关系将自由能与概率密度联系起来，从而监督模型不仅学习力数据，还学习近似自由能估计。实验使用CGSchNet模型，并在Chignolin蛋白上评估该框架，系统性地调整能量损失项的权重。

Result: 能量匹配没有带来统计学上显著的准确性提升，但揭示了模型在泛化自由能表面方面的不同趋势。

Conclusion: 研究结果表明，未来可以通过改进能量估计技术和多模态损失公式来增强粗粒化建模。该研究为进一步优化方法并实现更准确、更稳健的结果奠定了基础。

Abstract: Molecular dynamics (MD) simulations provide atomistic insight into biomolecular systems but are often limited by high computational costs required to access long timescales. Coarse-grained machine learning models offer a promising avenue for accelerating sampling, yet conventional force matching approaches often fail to capture the full thermodynamic landscape as fitting a model on the gradient may not fit the absolute differences between low-energy conformational states. In this work, we incorporate a complementary energy matching term into the loss function. We evaluate our framework on the Chignolin protein using the CGSchNet model, systematically varying the weight of the energy loss term. While energy matching did not yield statistically significant improvements in accuracy, it revealed distinct tendencies in how models generalize the free energy surface. Our results suggest future opportunities to enhance coarse-grained modeling through improved energy estimation techniques and multi-modal loss formulations.

</details>


### [4] [Structure-Aware Contrastive Learning with Fine-Grained Binding Representations for Drug Discovery](https://arxiv.org/abs/2509.14788)
*Jing Lan, Hexiao Ding, Hongzhao Chen, Yufeng Jiang, Nga-Chun Ng, Gwing Kei Yip, Gerald W. Y. Cheng, Yunlin Mao, Jing Cai, Liang-ting Lin, Jung Sun Yoo*

Main category: cs.LG

TL;DR: 本文提出了一种结构感知的对比学习框架，通过将局部几何信息融入蛋白质序列表示，实现了在保持高通量筛选能力的同时，提高药物-靶标相互作用（DTI）预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的DTI预测方法通常依赖序列信息，但忽略了蛋白质结构的几何信息。为了提高预测的准确性和效率，需要一种能够整合结构信息的、同时保持高通量筛选能力的DTI预测框架。

Method: 该框架使用结构感知的蛋白质序列表示，将每个残基标记与局部几何描述符配对。利用预训练的大型蛋白质语言模型学习结构上下文，并采用基于注意力的聚合模块，通过对比学习目标对药物和蛋白质嵌入进行对齐，从而预测DTI。

Result: 在多个基准数据集（Human, BioSNAP, BindingDB）上，该模型均取得了领先或具有竞争力的性能。在虚拟筛选任务中，在LIT-PCBA数据集上优于现有方法，显著提高了AUROC和BEDROC指标。消融研究验证了学习到的聚合、双线性注意力以及对比对齐在增强预测鲁棒性中的关键作用。

Conclusion: 该框架验证了其在可扩展和结构感知的DTI预测中的实用性，为药物发现提供了更快速、更准确的筛选工具，并提供了可解释的注意力模式，有助于理解药物与靶标之间的相互作用。

Abstract: Accurate identification of drug-target interactions (DTI) remains a central challenge in computational pharmacology, where sequence-based methods offer scalability. This work introduces a sequence-based drug-target interaction framework that integrates structural priors into protein representations while maintaining high-throughput screening capability. Evaluated across multiple benchmarks, the model achieves state-of-the-art performance on Human and BioSNAP datasets and remains competitive on BindingDB. In virtual screening tasks, it surpasses prior methods on LIT-PCBA, yielding substantial gains in AUROC and BEDROC. Ablation studies confirm the critical role of learned aggregation, bilinear attention, and contrastive alignment in enhancing predictive robustness. Embedding visualizations reveal improved spatial correspondence with known binding pockets and highlight interpretable attention patterns over ligand-residue contacts. These results validate the framework's utility for scalable and structure-aware DTI prediction.

</details>


### [5] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey, Julian Hoßbach, Sandro Kuppel, Tobias Ensslen, Jan C. Behrends, Christian Holm*

Main category: cs.LG

TL;DR: 本文提出了一种基于小波变换将生物纳米孔电流信号转换为图像，并利用深度学习算法进行肽分类的新方法，实现了高精度肽分类，为实时疾病诊断提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 传统的蛋白质鉴定方法昂贵且耗时，难以实现实时临床诊断。生物纳米孔技术具有快速、低成本的潜力，但其信号复杂性限制了分类的准确性，因此需要改进方法以提高分类精度。

Method: 将纳米孔电流信号通过小波变换转换为图像（即尺度图），捕捉信号的幅值、频率和时间信息，然后利用深度学习算法对这些图像进行肽分类。同时，研究人员还探索了模型迁移技术。

Result: 在42种肽的测试中，该方法实现了81%的分类准确率，达到了该领域的最新水平。

Conclusion: 该研究为生物纳米孔肽/蛋白质诊断开辟了新方法，并为实时疾病诊断提供了有前景的途径。模型迁移技术的应用为实际硬件部署奠定了基础。

Abstract: A device capable of performing real time classification of proteins in a clinical setting would allow for inexpensive and rapid disease diagnosis. One such candidate for this technology are nanopore devices. These devices work by measuring a current signal that arises when a protein or peptide enters a nanometer-length-scale pore. Should this current be uniquely related to the structure of the peptide and its interactions with the pore, the signals can be used to perform identification. While such a method would allow for real time identification of peptides and proteins in a clinical setting, to date, the complexities of these signals limit their accuracy. In this work, we tackle the issue of classification by converting the current signals into scaleogram images via wavelet transforms, capturing amplitude, frequency, and time information in a modality well-suited to machine learning algorithms. When tested on 42 peptides, our method achieved a classification accuracy of ~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward practical peptide/protein diagnostics at the point of care. In addition, we demonstrate model transfer techniques that will be critical when deploying these models into real hardware, paving the way to a new method for real-time disease diagnosis.

</details>
