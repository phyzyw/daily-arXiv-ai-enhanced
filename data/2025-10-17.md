<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Coder as Editor: Code-driven Interpretable Molecular Optimization](https://arxiv.org/abs/2510.14455)
*Wenyu Zhu, Chengzhu Li, Xiaohe Tian, Yifan Wang, Yinjun Jia, Jianhui Wang, Bowen Gao, Ya-Qin Zhang, Wei-Ying Ma, Yanyan Lan*

Main category: cs.LG

TL;DR: MECo是一个将LLM的推理转化为可执行代码的框架，用于解决分子优化中LLM难以精确执行结构修改的问题。它通过代码生成实现可解释、可控和一致的分子设计。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在分子优化中，虽然能生成高层次的编辑意图，但由于SMILES等线性表示的限制，难以准确执行这些修改，导致结果不可靠且难以解释，阻碍了人机协作和迭代优化。

Method: MECo将分子优化问题分解为两个阶段：首先，LLM生成人类可理解的编辑意图；然后，通过代码生成将这些意图转化为可执行的结构编辑操作，直接作用于分子图。

Result: MECo在模拟化学反应和目标化合物对上实现了98%的编辑重现准确率，在物理化学性质和目标活性优化基准测试中，一致性提高了38-86个百分点，成功率显著提升，同时保持了良好的结构相似性。

Conclusion: MECo通过意图与执行的对齐，实现了分子设计的一致性、可控性和可解释性，为药物发现中的高保真反馈循环和人机协作工作流程奠定了基础。

Abstract: Molecular optimization is a central task in drug discovery that requires precise structural reasoning and domain knowledge. While large language models (LLMs) have shown promise in generating high-level editing intentions in natural language, they often struggle to faithfully execute these modifications-particularly when operating on non-intuitive representations like SMILES. We introduce MECo, a framework that bridges reasoning and execution by translating editing actions into executable code. MECo reformulates molecular optimization for LLMs as a cascaded framework: generating human-interpretable editing intentions from a molecule and property goal, followed by translating those intentions into executable structural edits via code generation. Our approach achieves over 98% accuracy in reproducing held-out realistic edits derived from chemical reactions and target-specific compound pairs. On downstream optimization benchmarks spanning physicochemical properties and target activities, MECo substantially improves consistency by 38-86 percentage points to 90%+ and achieves higher success rates over SMILES-based baselines while preserving structural similarity. By aligning intention with execution, MECo enables consistent, controllable and interpretable molecular design, laying the foundation for high-fidelity feedback loops and collaborative human-AI workflows in drug discovery.

</details>


### [2] [Spectral Analysis of Molecular Kernels: When Richer Features Do Not Guarantee Better Generalization](https://arxiv.org/abs/2510.14217)
*Asma Jamali, Tin Sum Cheng, Rodrigo A. Vargas-Hernández*

Main category: cs.LG

TL;DR: 本研究对QM9数据集上的七个分子性质的核岭回归进行了全面的谱分析，结果表明，更丰富的谱特征并不总是能提高预测准确性，甚至可能与性能呈负相关。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在分子性质预测中表现出色，核方法在小数据场景下仍然具有优势。本研究旨在系统地分析分子核的谱特性，以了解其与泛化能力和表示质量之间的关系，挑战了“更丰富的谱特征带来更好泛化”的常见假设。

Method: 研究人员对基于不同分子表示（全局、局部3D、预训练的Transformer等）的七个分子性质的核岭回归进行了谱分析，使用了四种谱指标来衡量谱的丰富度，并进行了Pearson相关性测试。此外，还通过截断核来探究谱与预测性能之间的关系。

Result: 研究发现，更丰富的谱特征并不总是能提高预测准确性，对于基于Transformer和局部3D表示的核函数，谱丰富度甚至与性能呈负相关。保留仅2%的特征值就能恢复近乎全部的性能，表明前导特征值捕获了大部分信息。

Conclusion: 本研究挑战了“更丰富的谱特征带来更好泛化”的常见假设，强调了表示、核特征和预测性能之间细微的关系。这些发现对评估核方法和自监督学习方法在数据有限的科学和实际任务中的应用具有指导意义。

Abstract: Understanding the spectral properties of kernels offers a principled perspective on generalization and representation quality. While deep models achieve state-of-the-art accuracy in molecular property prediction, kernel methods remain widely used for their robustness in low-data regimes and transparent theoretical grounding. Despite extensive studies of kernel spectra in machine learning, systematic spectral analyses of molecular kernels are scarce. In this work, we provide the first comprehensive spectral analysis of kernel ridge regression on the QM9 dataset, molecular fingerprint, pretrained transformer-based, global and local 3D representations across seven molecular properties. Surprisingly, richer spectral features, measured by four different spectral metrics, do not consistently improve accuracy. Pearson correlation tests further reveal that for transformer-based and local 3D representations, spectral richness can even have a negative correlation with performance. We also implement truncated kernels to probe the relationship between spectrum and predictive performance: in many kernels, retaining only the top 2% of eigenvalues recovers nearly all performance, indicating that the leading eigenvalues capture the most informative features. Our results challenge the common heuristic that "richer spectra yield better generalization" and highlight nuanced relationships between representation, kernel features, and predictive performance. Beyond molecular property prediction, these findings inform how kernel and self-supervised learning methods are evaluated in data-limited scientific and real-world tasks.

</details>
