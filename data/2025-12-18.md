<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [physics.optics](#physics.optics) [Total: 1]
- [physics.chem-ph](#physics.chem-ph) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Evaluating Large Language Models in Scientific Discovery](https://arxiv.org/abs/2512.15567)
*Zhangde Song, Jieyu Lu, Yuanqi Du, Botao Yu, Thomas M. Pruyn, Yue Huang, Kehan Guo, Xiuzhe Luo, Yuanhao Qu, Yi Qu, Yinkai Wang, Haorui Wang, Jeff Guo, Jingru Gan, Parshin Shojaee, Di Luo, Andres M Bran, Gen Li, Qiyuan Zhao, Shao-Xiong Lennon Luo, Yuxuan Zhang, Xiang Zou, Wanru Zhao, Yifan F. Zhang, Wucheng Zhang, Shunan Zheng, Saiyang Zhang, Sartaaj Takrim Khan, Mahyar Rajabi-Kochi, Samantha Paradi-Maropakis, Tony Baltoiu, Fengyu Xie, Tianyang Chen, Kexin Huang, Weiliang Luo, Meijing Fang, Xin Yang, Lixue Cheng, Jiajun He, Soha Hassoun, Xiangliang Zhang, Wei Wang, Chandan K. Reddy, Chao Zhang, Zhiling Zheng, Mengdi Wang, Le Cong, Carla P. Gomes, Chang-Yu Hsieh, Aditya Nandy, Philippe Schwaller, Heather J. Kulik, Haojun Jia, Huan Sun, Seyed Mohamad Moosavi, Chenru Duan*

Main category: cs.AI

TL;DR: 本文提出了一种新的科学发现评估框架SDE，用于评估大型语言模型（LLMs）在生物、化学、材料和物理等领域的科学研究能力，超越了传统的知识测试，更侧重于迭代推理和实验设计。


<details>
  <summary>Details</summary>
Motivation: 现有的科学基准主要测试LLMs的知识储备，而忽略了科学发现过程中重要的迭代推理、假设生成和实验结果解释等环节。因此，需要一个更全面的评估框架来衡量LLMs在科学研究中的实际应用能力。

Method: 研究人员构建了一个基于场景的评估基准，由领域专家定义真实的科研项目，并将其分解为模块化的研究场景，从中抽取经过验证的问题。评估框架分为两阶段：第一阶段评估模型在场景相关的特定问题上的准确性；第二阶段评估模型在整个科研项目中的表现，包括提出可验证的假设、设计模拟或实验以及解释结果。

Result: 应用SDE框架对当前最先进的LLMs进行评估，揭示了模型在科学发现任务中存在一致的性能瓶颈，表明LLMs在科学研究中仍有很大的提升空间。

Conclusion: SDE框架为评估LLMs在科学发现中的能力提供了一个更全面、更具挑战性的方法，有助于推动LLMs在科学研究领域的应用和发展。

Abstract: Large language models (LLMs) are increasingly applied to scientific research, yet prevailing science benchmarks probe decontextualized knowledge and overlook the iterative reasoning, hypothesis generation, and observation interpretation that drive scientific discovery. We introduce a scenario-grounded benchmark that evaluates LLMs across biology, chemistry, materials, and physics, where domain experts define research projects of genuine interest and decompose them into modular research scenarios from which vetted questions are sampled. The framework assesses models at two levels: (i) question-level accuracy on scenario-tied items and (ii) project-level performance, where models must propose testable hypotheses, design simulations or experiments, and interpret results. Applying this two-phase scientific discovery evaluation (SDE) framework to state-of-the-art LLMs reveals a consistent performance gap relative to general science benchmarks, diminishing return of scaling up model sizes and reasoning, and systematic weaknesses shared across top-tier models from different providers. Large performance variation in research scenarios leads to changing choices of the best performing model on scientific discovery projects evaluated, suggesting all current LLMs are distant to general scientific "superintelligence". Nevertheless, LLMs already demonstrate promise in a great variety of scientific discovery projects, including cases where constituent scenario scores are low, highlighting the role of guided exploration and serendipity in discovery. This SDE framework offers a reproducible benchmark for discovery-relevant evaluation of LLMs and charts practical paths to advance their development toward scientific discovery.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)
*Hyakka Nakada, Shu Tanaka*

Main category: cs.LG

TL;DR: 本文研究了随机矩阵中最小值-最大值归一化特征值的统计特性，并推导了矩阵因子分解过程中的残差误差，并通过数值实验验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 数据科学中，输入数据通常需要归一化处理。本文旨在研究这种归一化处理对随机矩阵特征值统计性质的影响，并为机器学习模型中的特征缩放提供理论依据。

Method: 本文应用了先前提出的有效分布来评估累积分布的缩放规律，并推导了矩阵因子分解过程中的残差误差。通过数值实验验证了理论预测，并基于Wigner半圆定律和最大特征值分布理论，对特征值期望值进行了近似。

Result: 推导出了不同σ值条件下min-max归一化特征值的累积分布公式，并给出了归一化第二大特征值的确定性值r的表达式。通过数值实验验证了理论预测的准确性。

Conclusion: 本文的研究结果为理解随机矩阵的特征值统计性质提供了新的见解，并为机器学习中的特征缩放方法提供了理论支持，尤其是在因子机模型和量子退火等应用中具有重要意义。

Abstract: Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max normalized eigenvalues in random matrices. Previously, the effective distribution for such normalized eigenvalues has been proposed. In this study, we apply it to evaluate a scaling law of the cumulative distribution. Furthermore, we derive the residual error that arises during matrix factorization of random matrices. We conducted numerical experiments to verify these theoretical predictions.

</details>


### [3] [PIP$^2$ Net: Physics-informed Partition Penalty Deep Operator Network](https://arxiv.org/abs/2512.15086)
*Hongjin Mi, Huiqiang Lun, Changhong Mou, Yeyu Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种新的基于分区惩罚的深度算子网络（PIP2Net），通过改进分区单元方法，提高了算子学习的稳定性和表达能力，从而更准确地预测偏微分方程的解。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习方法（如DeepONet和FNO）通常需要大量训练数据，缺乏显式的物理结构，并且可能存在不稳定性和模式失衡问题，因此需要一种更稳定、更具表达力的算子学习框架。

Method: PIP2Net基于经典的分区单元（PoU）方法，引入了一种简化的分区惩罚机制，改进了DeepONet框架，协调了主干网络的输出，从而提高了表达能力。

Result: 在粘性Burgers方程、Allen-Cahn方程和扩散-反应系统三个非线性偏微分方程上，PIP2Net在预测精度和鲁棒性方面均优于DeepONet、PI-DeepONet和POU-DeepONet。

Conclusion: PIP2Net提供了一种更有效和稳定的算子学习方法，有望加速偏微分方程相关的模拟，并在不确定性量化、逆问题和实时控制等领域得到应用。

Abstract: Operator learning has become a powerful tool for accelerating the solution of parameterized partial differential equations (PDEs), enabling rapid prediction of full spatiotemporal fields for new initial conditions or forcing functions. Existing architectures such as DeepONet and the Fourier Neural Operator (FNO) show strong empirical performance but often require large training datasets, lack explicit physical structure, and may suffer from instability in their trunk-network features, where mode imbalance or collapse can hinder accurate operator approximation. Motivated by the stability and locality of classical partition-of-unity (PoU) methods, we investigate PoU-based regularization techniques for operator learning and develop a revised formulation of the existing POU--PI--DeepONet framework. The resulting \emph{P}hysics-\emph{i}nformed \emph{P}artition \emph{P}enalty Deep Operator Network (PIP$^{2}$ Net) introduces a simplified and more principled partition penalty that improved the coordinated trunk outputs that leads to more expressiveness without sacrificing the flexibility of DeepONet. We evaluate PIP$^{2}$ Net on three nonlinear PDEs: the viscous Burgers equation, the Allen--Cahn equation, and a diffusion--reaction system. The results show that it consistently outperforms DeepONet, PI-DeepONet, and POU-DeepONet in prediction accuracy and robustness.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [4] [Photonics-Enhanced Graph Convolutional Networks](https://arxiv.org/abs/2512.15549)
*Yuan Wang, Oleksandr Kyriienko*

Main category: physics.optics

TL;DR: 本文提出了一种结合光子定位嵌入 (PE) 和图卷积网络 (GCN) 的混合方法，利用光子在合成频率晶格上的传播来增强 GCN 的性能，特别是在分子数据集中。


<details>
  <summary>Details</summary>
Motivation: 现有 GCN 在处理大型分子图时存在局限性，例如信息过度平滑和过度压缩，难以捕捉长程分子相互作用。同时，光子系统具有并行性和低延迟的优势，有望加速图机器学习。

Method: 该方法利用光子在与输入图耦合的合成频率晶格上的传播，模拟光子传播并读取节点间强度相关性矩阵，将其作为光子定位嵌入 (PE) 输入到 GCN 中，提供全局结构信息。使用两层 GCN 作为基线，在 Long Range Graph Benchmark 分子数据集上进行评估。

Result: 实验结果表明，该方法优于基于拉普拉斯算子 PE 的基线 GCN，在回归任务中平均绝对误差降低了 6.3%，在分类任务中平均精度提高了 2.3%。在高速光子硬件中实现时，相关性测量可以绕过 PE 的数字模拟，实现快速特征生成。

Conclusion: 该研究表明，光子 PE 可以提高 GCN 的性能，并支持图机器学习的光学加速，为将光子系统应用于图机器学习提供了一种有前景的途径。

Abstract: Photonics can offer a hardware-native route for machine learning (ML). However, efficient deployment of photonics-enhanced ML requires hybrid workflows that integrate optical processing with conventional CPU/GPU based neural network architectures. Here, we propose such a workflow that combines photonic positional embeddings (PEs) with advanced graph ML models. We introduce a photonics-based method that augments graph convolutional networks (GCNs) with PEs derived from light propagation on synthetic frequency lattices whose couplings match the input graph. We simulate propagation and readout to obtain internode intensity correlation matrices, which are used as PEs in GCNs to provide global structural information. Evaluated on Long Range Graph Benchmark molecular datasets, the method outperforms baseline GCNs with Laplacian based PEs, achieving $6.3\%$ lower mean absolute error for regression and $2.3\%$ higher average precision for classification tasks using a two-layer GCN as a baseline. When implemented in high repetition rate photonic hardware, correlation measurements can enable fast feature generation by bypassing digital simulation of PEs. Our results show that photonic PEs improve GCN performance and support optical acceleration of graph ML.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [5] [Learning continuous SOC-dependent thermal decomposition kinetics for Li-ion cathodes using KA-CRNNs](https://arxiv.org/abs/2512.15628)
*Benjamin C. Koenig, Sili Deng*

Main category: physics.chem-ph

TL;DR: 本文提出了一种基于Kolmogorov-Arnold化学反应神经网络（KA-CRNN）的框架，用于学习锂离子电池正极与电解液之间连续的、与荷电状态（SOC）相关的放热反应动力学参数，从而更准确地预测热失控。


<details>
  <summary>Details</summary>
Motivation: 现有热失控预测模型通常将动力学参数视为固定值或仅在少数离散SOC水平下进行推断，无法捕捉到SOC对放热行为的连续影响。由于SOC显著影响锂离子电池的热失控严重程度，因此需要开发能够反映SOC依赖性的动力学模型。

Method: 研究人员将物理编码的KA-CRNN应用于正极-电解液分解的DSC数据，直接学习SOC相关的动力学参数。该框架将反应路径嵌入到网络架构中，使得活化能、前指数因子、焓等参数能够表示为SOC的连续且可解释的函数。

Result: 该框架成功应用于NCA、NM和NMA正极，生成了能够重现所有SOC范围内的DSC放热特征的模型，并提供了关于SOC相关的氧释放和相变机制的可解释性见解。

Conclusion: 该研究为扩展动力学参数依赖性到其他环境和电化学变量奠定了基础，支持更准确和可解释的热失控预测和监测，具有重要的实际应用价值。

Abstract: Thermal runaway in lithium-ion batteries is strongly influenced by the state of charge (SOC). Existing predictive models typically infer scalar kinetic parameters at a full SOC or a few discrete SOC levels, preventing them from capturing the continuous SOC dependence that governs exothermic behavior during abuse conditions. To address this, we apply the Kolmogorov-Arnold Chemical Reaction Neural Network (KA-CRNN) framework to learn continuous and realistic SOC-dependent exothermic cathode-electrolyte interactions. We apply a physics-encoded KA-CRNN to learn SOC-dependent kinetic parameters for cathode-electrolyte decomposition directly from differential scanning calorimetry (DSC) data. A mechanistically informed reaction pathway is embedded into the network architecture, enabling the activation energies, pre-exponential factors, enthalpies, and related parameters to be represented as continuous and fully interpretable functions of the SOC. The framework is demonstrated for NCA, NM, and NMA cathodes, yielding models that reproduce DSC heat-release features across all SOCs and provide interpretable insight into SOC-dependent oxygen-release and phase-transformation mechanisms. This approach establishes a foundation for extending kinetic parameter dependencies to additional environmental and electrochemical variables, supporting more accurate and interpretable thermal-runaway prediction and monitoring.

</details>
