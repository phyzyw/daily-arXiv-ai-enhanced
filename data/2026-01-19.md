<div id=toc></div>

# Table of Contents

- [physics.plasm-ph](#physics.plasm-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [1] [Learning collision operators from plasma phase space data using differentiable simulators](https://arxiv.org/abs/2601.10885)
*Diogo D. Carvalho, Pablo J. Bilbao, Warren B. Mori, Luis O. Silva, E. Paulo Alves*

Main category: physics.plasm-ph

TL;DR: 本文提出了一种利用可微模拟器从等离子体相空间数据中推断碰撞算子的方法，该方法无需预先假设时间尺度，并显著降低了内存需求。


<details>
  <summary>Details</summary>
Motivation: 在非平衡和强耦合等离子体状态下，特别是当碰撞动力学由电磁相互作用介导或小角度散射假设失效时，难以建立有效的碰撞算子模型，而这些状态在惯性约束聚变、天体物理等领域普遍存在。

Method: 该方法结合了可微的运动学模拟器（核心为可微的福克-普朗克求解器）和基于梯度的优化方法，通过优化碰撞算子来最好地描述相空间动力学。使用粒子模拟数据进行训练，并与理论预测进行比较。

Result: 学习到的碰撞算子比基于粒子轨迹的估计更准确，并且与非相对论电磁场景的理论预测一致。该方法在计算效率上具有优势。

Conclusion: 可微模拟器提供了一种强大的、计算效率高的推断新算子的方法，可用于研究电磁主导的碰撞动力学和随机波粒相互作用等问题，为等离子体物理理论发展提供新的途径。

Abstract: We propose a methodology to infer collision operators from phase space data of plasma dynamics. Our approach combines a differentiable kinetic simulator, whose core component in this work is a differentiable Fokker-Planck solver, with a gradient-based optimisation method to learn the collisional operators that best describe the phase space dynamics. We test our method using data from two-dimensional Particle-in-Cell simulations of spatially uniform thermal plasmas, and learn the collision operator that captures the self-consistent electromagnetic interaction between finite-size charged particles over a wide variety of simulation parameters. We demonstrate that the learned operators are more accurate than alternative estimates based on particle tracks, while making no prior assumptions about the relevant time-scales of the processes and significantly reducing memory requirements. We find that the retrieved operators, obtained in the non-relativistic regime, are in excellent agreement with theoretical predictions derived for electrostatic scenarios. Our results show that differentiable simulators offer a powerful and computational efficient approach to infer novel operators for a wide rage of problems, such as electromagnetically dominated collisional dynamics and stochastic wave-particle interactions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Transient learning dynamics drive escape from sharp valleys in Stochastic Gradient Descent](https://arxiv.org/abs/2601.10962)
*Ning Yang, Yikuan Zhang, Qi Ouyang, Chao Tang, Yuhai Tu*

Main category: cs.LG

TL;DR: 本文研究了随机梯度下降 (SGD) 如何选择更平坦、更泛化良好的解，揭示了训练过程中一个短暂的探索阶段，以及随后出现的“冻结”机制。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在各个领域取得了巨大成功，但其底层机制仍然不清楚。本文旨在理解 SGD 偏好于更平坦解的动态起源，并探索损失景观几何与泛化能力之间的联系。

Method: 通过分析 SGD 学习动态，结合数值实验和可处理的物理模型，研究了 SGD 在损失景观中的运动轨迹，并考察了噪声强度对解选择的影响。

Result: 研究发现，SGD 学习过程中存在一个短暂的探索阶段，SGD 轨迹会反复逃离尖锐的山谷并过渡到更平坦的区域。随着训练的进行，能量壁垒的增长会抑制谷间转换，最终将动态束缚在单个盆地内，即“冻结”机制。增加噪声强度可以延缓这种冻结，从而促进对更平坦极小值的收敛。

Conclusion: 本文提供了一个统一的物理框架，将学习动态、损失景观几何和泛化联系起来，并为设计更有效的优化算法提供了原则，揭示了 SGD 如何通过噪声重塑损失景观，从而选择更平坦的解。

Abstract: Stochastic gradient descent (SGD) is central to deep learning, yet the dynamical origin of its preference for flatter, more generalizable solutions remains unclear. Here, by analyzing SGD learning dynamics, we identify a nonequilibrium mechanism governing solution selection. Numerical experiments reveal a transient exploratory phase in which SGD trajectories repeatedly escape sharp valleys and transition toward flatter regions of the loss landscape. By using a tractable physical model, we show that the SGD noise reshapes the landscape into an effective potential that favors flat solutions. Crucially, we uncover a transient freezing mechanism: as training proceeds, growing energy barriers suppress inter-valley transitions and ultimately trap the dynamics within a single basin. Increasing the SGD noise strength delays this freezing, which enhances convergence to flatter minima. Together, these results provide a unified physical framework linking learning dynamics, loss-landscape geometry, and generalization, and suggest principles for the design of more effective optimization algorithms.

</details>
