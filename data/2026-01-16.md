<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders](https://arxiv.org/abs/2601.10588)
*I. K. Kominis, C. Xie, S. Li, M. Skotiniotis, G. P. Tsironis*

Main category: quant-ph

TL;DR: 本文提出了一种无需假设微观细节的、基于信息论的非经典性测试方法，用于探测自编码器中潜在表示的非经典结构。该方法通过贝尔型一致性测试，考察不同解码情境下的解码统计信息是否能由单个正的潜在变量分布联合解释。


<details>
  <summary>Details</summary>
Motivation: 长期以来，关于量子效应是否在脑部发挥功能的争论不断。传统方法侧重于寻找生物物理基底中的量子相干性，但缺乏可测试的方案。本文旨在从信息处理的角度出发，探索神经系统信息压缩和表示的效率，并寻找潜在的量子效应。

Method: 利用自编码器作为透明的模型系统，引入了一种贝尔型一致性测试，在潜在空间中进行。通过改变解码器设置，获取不同的解码统计信息，并检验这些信息是否能由单个正的潜在变量分布联合解释。

Result: 该研究提出了一种纯粹统计的非经典性测试，用于评估自编码器学习的潜在表示。通过分析解码统计信息，可以判断是否存在无法用单一经典描述解释的非经典结构。

Conclusion: 这项工作开辟了一条新的途径，用于探测神经计算的基本物理规律，将寻找神经系统中量子特征的重点从微观动力学转移到信息处理的可测试约束上，为探索脑部信息处理的潜在量子机制提供了新的思路。

Abstract: Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution. By shifting the search for quantum-like signatures in neural systems from microscopic dynamics to experimentally testable constraints on information processing, this work opens a new route for probing the fundamental physics of neural computation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [2] [Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics](https://arxiv.org/abs/2601.10453)
*Victor Zheleznov, Stefan Bilbao, Alec Wright, Simon King*

Main category: cs.SD

TL;DR: 本文结合了标量辅助变量技术（SAV）和神经常微分方程（NODE），提出了一种稳定且可微分的模型，用于学习非线性动力学，并保持了物理参数的可访问性。


<details>
  <summary>Details</summary>
Motivation: 传统的物理建模合成方法在数值稳定性方面存在挑战，而机器学习方法虽然能从数据中学习，但缺乏稳定性保证且难以改变训练后系统的物理参数。本文旨在将物理知识更深入地融入机器学习框架，解决这些问题。

Method: 该方法采用模态分解构建有限维系统，将非线性部分用神经网络（梯度网络GradNets）替代，并结合NODE和SAV技术，构建稳定可微分模型。利用线性振动的解析解，确保物理参数在训练后易于访问。

Result: 通过对非线性横向弦振动合成数据的训练，证明了该模型能够重现系统的非线性动力学，并提供了听觉示例。

Conclusion: 该研究提供了一种新的方法，将物理建模与机器学习相结合，实现了稳定、可微分且易于控制物理参数的模型，为学习非线性动力学提供了新的思路，并有望应用于更广泛的物理建模合成领域。

Abstract: Modal methods are a long-standing approach to physical modelling synthesis. Extensions to nonlinear problems are possible, including the case of a high-amplitude vibration of a string. A modal decomposition leads to a densely coupled nonlinear system of ordinary differential equations. Recent work in scalar auxiliary variable techniques has enabled construction of explicit and stable numerical solvers for such classes of nonlinear systems. On the other hand, machine learning approaches (in particular neural ordinary differential equations) have been successful in modelling nonlinear systems automatically from data. In this work, we examine how scalar auxiliary variable techniques can be combined with neural ordinary differential equations to yield a stable differentiable model capable of learning nonlinear dynamics. The proposed approach leverages the analytical solution for linear vibration of system's modes so that physical parameters of a system remain easily accessible after the training without the need for a parameter encoder in the model architecture. As a proof of concept, we generate synthetic data for the nonlinear transverse vibration of a string and show that the model can be trained to reproduce the nonlinear dynamics of the system. Sound examples are presented.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [3] [Parametric RDT approach to computational gap of symmetric binary perceptron](https://arxiv.org/abs/2601.10628)
*Mihailo Stojnic*

Main category: stat.ML

TL;DR: 本文利用提升的随机对偶理论（fl-RDT）研究了对称二元感知器（SBP）中统计-计算差距（SCG）的存在，并观察到关键的c-序列排序变化与算法约束密度的阈值变化相关。


<details>
  <summary>Details</summary>
Motivation: 机器学习和神经网络的理论和算法发展依赖于对经典感知器的研究。本文旨在深入理解对称二元感知器的存储容量，并探索其统计-计算差距，以推动人工智能理论的发展。

Method: 本文采用提升的随机对偶理论（fl-RDT）对对称二元感知器进行分析，重点关注c-序列排序的变化，并将其与算法约束密度的阈值变化联系起来。通过对不同层次的估计，试图确定统计约束密度（αc）和算法约束密度（αa）。

Result: 研究发现，第二层次的估计与理论上的αc相符，而第7层次的估计则对应于αa。对于标准SBP，αc≈1.8159，αa≈1.6021。研究结果与局部熵方法和重叠间隙性质预测相符，并与非对称二元感知器和负Hopfield模型中的现象相似。

Conclusion: 本文的研究结果为理解对称二元感知器的存储容量和统计-计算差距提供了新的见解，并为设计基于CLuP算法的实际性能预测提供了理论基础，为人工智能理论研究贡献了新的视角。

Abstract: We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \emph{satisfiability} ($α_c$) -- \emph{algorithmic} ($α_a$) constraints density threshold change thereby suggesting a potential existence of a nonzero computational gap $SCG=α_c-α_a$. The second level estimate is shown to match the theoretical $α_c$ whereas the $r\rightarrow \infty$ level one is proposed to correspond to $α_a$. For example, for the canonical SBP ($κ=1$ margin) we obtain $α_c\approx 1.8159$ on the second and $α_a\approx 1.6021$ (with converging tendency towards $\sim 1.59$ range) on the seventh level. Our propositions remarkably well concur with recent literature: (i) in [20] local entropy replica approach predicts $α_{LE}\approx 1.58$ as the onset of clustering defragmentation (presumed driving force behind locally improving algorithms failures); (ii) in $α\rightarrow 0$ regime we obtain on the third lifting level $κ\approx 1.2385\sqrt{\frac{α_a}{-\log\left ( α_a \right ) }}$ which qualitatively matches overlap gap property (OGP) based predictions of [43] and identically matches local entropy based predictions of [24]; (iii) $c$-sequence ordering change phenomenology mirrors the one observed in asymmetric binary perceptron (ABP) in [98] and the negative Hopfield model in [100]; and (iv) as in [98,100], we here design a CLuP based algorithm whose practical performance closely matches proposed theoretical predictions.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [On the origin of neural scaling laws: from random graphs to natural language](https://arxiv.org/abs/2601.10684)
*Maissam Barkeshli, Alberto Alfarano, Andrey Gromov*

Main category: cs.LG

TL;DR: 本文研究了神经网络缩放定律的起源，发现即使在数据中没有幂律结构的情况下，简单的模型也能产生缩放定律，并揭示了自然语言复杂性递减过程中的缩放指数演变。


<details>
  <summary>Details</summary>
Motivation: 神经网络缩放定律在人工智能领域至关重要，但其起源尚不明确。一种常见的假设是缩放定律源于数据中已存在的幂律结构，本文旨在验证这一假设，并探索缩放定律的更深层机制。

Method: 研究人员通过在图上训练预测随机游走（双词）的 Transformer 模型，并系统性地降低自然语言的复杂性（从多层 Transformer 到双词语言），来研究缩放定律。此外，他们还研究了在 Erdős-Renyi 和 Barabási-Albert 随机图上训练的结果，并重新审视了语言建模的传统缩放定律。

Result: 研究表明，即使在数据中没有幂律结构的情况下，简单的模型也能产生神经网络缩放定律。自然语言复杂性递减过程中，缩放指数呈现单调演变。研究还成功复现了传统语言建模的缩放定律，并提出了计算最优曲线的新方法。

Conclusion: 本文的发现表明，神经网络缩放定律的起源可能并不完全依赖于数据中的幂律结构，为理解和优化深度学习方法的效率提供了新的视角，并为未来提高算法效率提供了潜在方向。

Abstract: Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization.

</details>
