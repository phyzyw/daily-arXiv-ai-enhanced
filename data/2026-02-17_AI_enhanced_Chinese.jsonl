{"id": "2602.14928", "title": "From Classical to Quantum: Extending Prometheus for Unsupervised Discovery of Phase Transitions in Three Dimensions and Quantum Systems", "authors": ["Brandon Yee", "Wilson Collins", "Maximilian Rutkowski"], "summary": "We extend the Prometheus framework for unsupervised phase transition discovery from 2D classical systems to 3D classical and quantum many-body systems, addressing scalability in higher dimensions and generalization to quantum fluctuations. For the 3D Ising model ($L \\leq 32$), the framework detects the critical temperature within 0.01\\% of literature values ($T_c/J = 4.511 \\pm 0.005$) and extracts critical exponents with $\\geq 70\\%$ accuracy ($β= 0.328 \\pm 0.015$, $γ= 1.24 \\pm 0.06$, $ν= 0.632 \\pm 0.025$), correctly identifying the 3D Ising universality class via $χ^2$ comparison ($p = 0.72$) without analytical guidance. For quantum systems, we developed quantum-aware VAE (Q-VAE) architectures using complex-valued wavefunctions and fidelity-based loss. Applied to the transverse field Ising model, we achieve 2\\% accuracy in quantum critical point detection ($h_c/J = 1.00 \\pm 0.02$) and successfully discover ground state magnetization as the order parameter ($r = 0.97$). Notably, for the disordered transverse field Ising model, we detect exotic infinite-randomness criticality characterized by activated dynamical scaling $\\ln ξ\\sim |h - h_c|^{-ψ}$, extracting a tunneling exponent $ψ= 0.48 \\pm 0.08$ consistent with theoretical predictions ($ψ= 0.5$). This demonstrates that unsupervised learning can identify qualitatively different types of critical behavior, not just locate critical points. Our systematic validation across classical thermal transitions ($T = 0$ to $T > 0$) and quantum phase transitions ($T = 0$, varying $h$) establishes that VAE-based discovery generalizes across fundamentally different physical domains, providing robust tools for exploring phase diagrams where analytical solutions are unavailable.", "abs": "", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "AI": {"tldr": "本文将Prometheus框架扩展到三维经典系统和量子系统，实现了无需人工干预的自监督相变发现，并成功提取了关键物理量，验证了其在不同物理领域中的普适性。", "motivation": "现有监督学习方法需要预先知道相结构，且无法发现新的相变。本文旨在开发一种自监督学习框架，能够在缺乏标签的情况下发现相变、提取关键物理量并识别新的相变类型。", "method": "基于变分自编码器（VAE）构建Prometheus框架，并针对量子系统开发了量子感知的VAE（Q-VAE），使用保真度损失函数处理复数波函数。通过对三维Ising模型和横向磁场Ising模型进行训练，并进行统计分析，验证了框架的有效性。", "result": "在三维Ising模型中，成功检测临界温度，提取临界指数，并正确识别了其普适类。在量子系统中，实现了对横向磁场Ising模型临界点的2%精度检测，并发现了基态磁化强度作为序参量。更重要的是，在无序横向磁场Ising模型中，检测到了异特的无限随机性临界现象，提取的隧道指数与理论预测一致。", "conclusion": "本文的成果表明，基于VAE的自监督学习方法能够有效地发现不同类型的临界行为，并泛化到经典和量子物理的不同领域，为探索缺乏解析解的相图提供了强大的工具。"}}
{"id": "2602.14885", "title": "Drift-Diffusion Matching: Embedding dynamics in latent manifolds of asymmetric neural networks", "authors": ["Ramón Nartallo-Kaluarachchi", "Renaud Lambiotte", "Alain Goriely"], "summary": "Recurrent neural networks (RNNs) provide a theoretical framework for understanding computation in biological neural circuits, yet classical results, such as Hopfield's model of associative memory, rely on symmetric connectivity that restricts network dynamics to gradient-like flows. In contrast, biological networks support rich time-dependent behaviour facilitated by their asymmetry. Here we introduce a general framework, which we term drift-diffusion matching, for training continuous-time RNNs to represent arbitrary stochastic dynamical systems within a low-dimensional latent subspace. Allowing asymmetric connectivity, we show that RNNs can faithfully embed the drift and diffusion of a given stochastic differential equation, including nonlinear and nonequilibrium dynamics such as chaotic attractors. As an application, we construct RNN realisations of stochastic systems that transiently explore various attractors through both input-driven switching and autonomous transitions driven by nonequilibrium currents, which we interpret as models of associative and sequential (episodic) memory. To elucidate how these dynamics are encoded in the network, we introduce decompositions of the RNN based on its asymmetric connectivity and its time-irreversibility. Our results extend attractor neural network theory beyond equilibrium, showing that asymmetric neural populations can implement a broad class of dynamical computations within low-dimensional manifolds, unifying ideas from associative memory, nonequilibrium statistical mechanics, and neural computation.", "abs": "", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "q-bio.NC"], "AI": {"tldr": "本文提出了一种名为“漂移扩散匹配”的框架，用于训练非对称循环神经网络（RNN）以嵌入任意随机动力系统，从而扩展了吸引子神经网络理论，使其超越了平衡态。", "motivation": "传统的RNN模型，如Hopfield模型，通常基于对称连接，限制了网络动态。然而，生物神经网络具有非对称连接，支持更丰富的时变行为。因此，需要一种能够模拟非对称网络动态的框架。", "method": "提出“漂移扩散匹配”框架，通过训练连续时间RNN，使其能够忠实地嵌入给定随机微分方程的漂移和扩散，允许非对称连接，并支持非平衡态动态。", "result": "成功构建了RNN实现，能够模拟具有输入驱动切换和非平衡电流驱动的自发过渡的随机系统，并将其解释为联想和序列记忆的模型。研究还揭示了RNN中动态编码方式，通过对网络非对称连接和时间不可逆性的分解。", "conclusion": "该研究扩展了吸引子神经网络理论，表明非对称神经网络可以在低维流形中实现广泛的动态计算，统一了联想记忆、非平衡统计力学和神经计算等领域。"}}
{"id": "2602.13847", "title": "Causally constrained reduced-order neural models of complex turbulent dynamical systems", "authors": ["Fabrizio Falasca", "Laure Zanna"], "summary": "We introduce a flexible framework based on response theory and score matching to suppress spurious, noncausal dependencies in reduced-order neural emulators of turbulent systems, focusing on climate dynamics as a proof-of-concept. We showcase the approach using the stochastic Charney-DeVore model as a relevant prototype for low-frequency atmospheric variability. We show that the resulting causal constraints enhance neural emulators' ability to respond to both weak and strong external forcings, despite being trained exclusively on unforced data. The approach is broadly applicable to modeling complex turbulent dynamical systems in reduced spaces and can be readily integrated into general neural network architectures.", "abs": "", "categories": ["nlin.CD", "cond-mat.stat-mech", "cs.LG", "physics.ao-ph"], "AI": {"tldr": "本文提出了一种基于响应理论和分数匹配的框架，通过因果约束来抑制复杂湍流动力系统（以气候动力学为例）中神经网络模拟器的非因果依赖关系，从而提高其对外部强迫的响应能力。", "motivation": "传统的神经网络模拟器虽然能很好地重现系统统计特征，但在应对外部扰动时往往表现不佳，这限制了其在过程理解和情景探索中的应用。因果关系与系统对外部扰动的响应密切相关，因此通过约束模型尊重因果结构有望提高其响应能力。", "method": "该框架分为两个步骤：(1) 利用涨落-耗散定理（FDT）从静止、未扰动的数据中推断变量之间的直接因果耦合；(2) 在学习神经网络模型时，保留推断出的因果结构。", "result": "实验结果表明，因果约束增强了神经网络模拟器对弱和强外部强迫的响应能力，即使模型仅在未扰动的数据上进行训练。", "conclusion": "该方法为建模复杂湍流动力系统的低阶模型提供了一种通用的、可行的策略，并可轻松集成到一般的神经网络架构中，有望提高物理系统神经网络模拟器的预测能力和可解释性。"}}
{"id": "2602.14853", "title": "BEACONS: Bounded-Error, Algebraically-Composable Neural Solvers for Partial Differential Equations", "authors": ["Jonathan Gorard", "Ammar Hakim", "James Juno"], "summary": "The traditional limitations of neural networks in reliably generalizing beyond the convex hulls of their training data present a significant problem for computational physics, in which one often wishes to solve PDEs in regimes far beyond anything which can be experimentally or analytically validated. In this paper, we show how it is possible to circumvent these limitations by constructing formally-verified neural network solvers for PDEs, with rigorous convergence, stability, and conservation properties, whose correctness can therefore be guaranteed even in extrapolatory regimes. By using the method of characteristics to predict the analytical properties of PDE solutions a priori (even in regions arbitrarily far from the training domain), we show how it is possible to construct rigorous extrapolatory bounds on the worst-case L^inf errors of shallow neural network approximations. Then, by decomposing PDE solutions into compositions of simpler functions, we show how it is possible to compose these shallow neural networks together to form deep architectures, based on ideas from compositional deep learning, in which the large L^inf errors in the approximations have been suppressed. The resulting framework, called BEACONS (Bounded-Error, Algebraically-COmposable Neural Solvers), comprises both an automatic code-generator for the neural solvers themselves, as well as a bespoke automated theorem-proving system for producing machine-checkable certificates of correctness. We apply the framework to a variety of linear and non-linear PDEs, including the linear advection and inviscid Burgers' equations, as well as the full compressible Euler equations, in both 1D and 2D, and illustrate how BEACONS architectures are able to extrapolate solutions far beyond the training data in a reliable and bounded way. Various advantages of the approach over the classical PINN approach are discussed.", "abs": "", "categories": ["cs.LG", "math.NA", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种名为BEACONS的框架，通过形式化验证的神经网络架构来解决偏微分方程(PDEs)，即使在训练数据范围之外也能保证收敛性、稳定性和守恒性。", "motivation": "传统神经网络在超出训练数据凸包的区域进行外推时存在可靠性问题，尤其是在计算物理中，需要解决在无法实验或分析验证的条件下求解PDEs的问题。", "method": "BEACONS框架利用特征方法预测PDE解的解析性质，构建严格的外推边界，并将PDE解分解为更简单的函数组合，从而构建深度架构。同时，提供自动代码生成器和自动化定理证明系统，用于生成可机器检查的正确性证书。", "result": "BEACONS框架成功应用于多种线性与非线性PDEs，包括线性对流、无粘性Burgers方程以及完整的可压缩Euler方程，证明了其在可靠且有界的方式下，能够远超训练数据范围进行外推。", "conclusion": "BEACONS框架克服了传统神经网络和PINN方法的外推局限性，为求解PDEs提供了一种更可靠、可验证的解决方案，具有重要的理论和应用价值。"}}
{"id": "2602.13811", "title": "A Unified Physics-Informed Neural Network for Modeling Coupled Electro- and Elastodynamic Wave Propagation Using Three-Stage Loss Optimization", "authors": ["Suhas Suresh Bharadwaj", "Reuben Thomas Thovelil"], "summary": "Physics-Informed Neural Networks present a novel approach in SciML that integrates physical laws in the form of partial differential equations directly into the NN through soft constraints in the loss function. This work studies the application of PINNs to solve a one dimensional coupled electro-elastodynamic system modeling linear piezoelectricity in stress-charge form, governed by elastodynamic and electrodynamic equations. Our simulation employs a feedforward architecture, mapping space-time coordinates to mechanical displacement and electric potential. Our PINN model achieved global relative L2 errors of 2.34 and 4.87 percent for displacement and electric potential respectively. The results validate PINNs as effective mesh free solvers for coupled time-dependent PDE systems, though challenges remain regarding error accumulation and stiffness in coupled eigenvalue systems.", "abs": "", "categories": ["cs.NE", "cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种统一的物理信息神经网络（PINN）方法，用于模拟一维耦合的压电效应，该方法通过三阶段损失优化来解决电动力学和弹性动力学方程。", "motivation": "PINN在科学机器学习领域具有潜力，但对于耦合多物理场系统（如线性压电效应）的应用相对较少，需要进一步研究。", "method": "研究人员使用前馈神经网络架构，将时空坐标映射到机械位移和电势，并通过三阶段损失优化（Adam, AdamW, L-BFGS）训练PINN模型，将物理定律（弹性动力学和电动力学方程）嵌入到损失函数中。", "result": "PINN模型在位移和电势的全局相对L2误差分别为2.34%和4.87%，验证了PINN作为耦合时相关偏微分系统有效无网格求解器的能力。", "conclusion": "该研究表明PINN可以有效解决耦合时相关偏微分系统，但仍面临误差积累和耦合特征值系统刚度等挑战，为未来PINN在多物理场建模中的应用提供了参考。"}}
{"id": "2602.13805", "title": "Fast Physics-Driven Untrained Network for Highly Nonlinear Inverse Scattering Problems", "authors": ["Yutong Du", "Zicheng Liu", "Yi Huang", "Bazargul Matkerim", "Bo Qi", "Yali Zong", "Peixian Han"], "summary": "Untrained neural networks (UNNs) offer high-fidelity electromagnetic inverse scattering reconstruction but are computationally limited by high-dimensional spatial-domain optimization. We propose a Real-Time Physics-Driven Fourier-Spectral (PDF) solver that achieves sub-second reconstruction through spectral-domain dimensionality reduction. By expanding induced currents using a truncated Fourier basis, the optimization is confined to a compact low-frequency parameter space supported by scattering measurements. The solver integrates a contraction integral equation (CIE) to mitigate high-contrast nonlinearity and a contrast-compensated operator (CCO) to correct spectral-induced attenuation. Furthermore, a bridge-suppressing loss is formulated to enhance boundary sharpness between adjacent scatterers. Numerical and experimental results demonstrate a 100-fold speedup over state-of-the-art UNNs with robust performance under noise and antenna uncertainties, enabling real-time microwave imaging applications.", "abs": "", "categories": ["cs.LG", "physics.comp-ph"], "AI": {"tldr": "本文提出了一种基于傅里叶谱域的物理驱动神经网络（PDF-NN）求解器，通过低频傅里叶展开和物理信息整合，实现了亚秒级的电磁逆散射重建，显著提升了速度。", "motivation": "现有未训练神经网络（UNN）在电磁逆散射问题中虽然能获得高保真重建结果，但计算效率低，限制了其在实时应用中的使用。因此，需要一种能在保证成像精度的同时，大幅提升重建速度的解决方案。", "method": "该方法采用实时物理驱动傅里叶谱（PDF）求解器，利用截断的傅里叶基函数展开诱导电流，将优化问题限制在低频参数空间。同时，结合收缩积分方程（CIE）处理高对比度非线性，对比度补偿算子（CCO）校正谱诱导衰减，以及桥抑制损失增强相邻散射体之间的边界清晰度。", "result": "实验结果表明，PDF-NN求解器相比于现有UNN方法，重建速度提升了100倍，并且在噪声和天线不确定性下表现出鲁棒性。", "conclusion": "该研究为实时微波成像应用提供了新的解决方案，通过将物理驱动与傅里叶谱域方法相结合，实现了高精度、高效率的电磁逆散射重建。"}}
{"id": "2602.14975", "title": "Faster Molecular Dynamics with Neural Network Potentials via Distilled Multiple Time-Stepping and Non-Conservative Forces", "authors": ["Nicolaï Gouraud", "Côme Cattin", "Thomas Plé", "Olivier Adjoua", "Louis Lagardère", "Jean-Philip Piquemal"], "summary": "Following our previous work (J. Phys. Chem. Lett., 2026, 17, 5, 1288-1295), we propose the DMTS-NC approach, a distilled multi-time-step (DMTS) strategy using non conservative (NC) forces to further accelerate atomistic molecular dynamics simulations using foundation neural network models. There, a dual-level reversible reference system propagator algorithm (RESPA) formalism couples a target accurate conservative potential to a simplified distilled representation optimized for the production of non-conservative forces. Despite being non-conservative, the distilled architecture is designed to enforce key physical priors, such as equivariance under rotation and cancellation of atomic force components. These choices facilitate the distillation process and therefore improve drastically the robustness of simulation, significantly limiting the \"holes\" in the simpler potential, thus achieving excellent agreement with the forces data. Overall, the DMTS-NC scheme is found to be more stable and efficient than its conservative counterpart with additional speedups reaching 15-30% over DMTS. Requiring no finetuning steps, it is easier to implement and can be pushed to the limit of the systems physical resonances to maintain accuracy while providing maximum efficiency. As for DMTS, DMTS-NC is applicable to any neural network potential.", "abs": "", "categories": ["physics.chem-ph", "cs.LG"], "AI": {"tldr": "本文提出了一种名为DMTS-NC的新方法，通过使用蒸馏的多时间步长（DMTS）策略和非保守力，进一步加速基于神经网络势能的分子动力学模拟。", "motivation": "传统的神经网络势能（NNP）方法虽然具有高精度和可转移性，但在计算效率上仍有提升空间，因此需要开发加速模拟算法。", "method": "DMTS-NC方法结合了双层可逆参考系统传播算法（RESPA）和蒸馏表示，优化非保守力，同时设计蒸馏架构以确保旋转对称性和原子力分量抵消等关键物理先验，从而提高模拟的稳定性和效率。", "result": "实验结果表明，DMTS-NC方案比其保守版本更稳定、更高效，速度提升可达15-30%，且无需精细调整。", "conclusion": "DMTS-NC方法易于实现，适用于任何神经网络势能，能够在保持精度的同时提供最大的效率，为分子动力学模拟提供了新的加速途径。"}}
{"id": "2602.15022", "title": "Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation", "authors": ["Cai Zhou", "Zijie Chen", "Zian Li", "Jike Wang", "Kaiyi Jiang", "Pan Li", "Rose Yu", "Muhan Zhang", "Stephen Bates", "Tommi Jaakkola"], "summary": "Many generative tasks in chemistry and science involve distributions invariant to group symmetries (e.g., permutation and rotation). A common strategy enforces invariance and equivariance through architectural constraints such as equivariant denoisers and invariant priors. In this paper, we challenge this tradition through the alternative canonicalization perspective: first map each sample to an orbit representative with a canonical pose or order, train an unconstrained (non-equivariant) diffusion or flow model on the canonical slice, and finally recover the invariant distribution by sampling a random symmetry transform at generation time. Building on a formal quotient-space perspective, our work provides a comprehensive theory of canonical diffusion by proving: (i) the correctness, universality and superior expressivity of canonical generative models over invariant targets; (ii) canonicalization accelerates training by removing diffusion score complexity induced by group mixtures and reducing conditional variance in flow matching. We then show that aligned priors and optimal transport act complementarily with canonicalization and further improves training efficiency. We instantiate the framework for molecular graph generation under $S_n \\times SE(3)$ symmetries. By leveraging geometric spectra-based canonicalization and mild positional encodings, canonical diffusion significantly outperforms equivariant baselines in 3D molecule generation tasks, with similar or even less computation. Moreover, with a novel architecture Canon, CanonFlow achieves state-of-the-art performance on the challenging GEOM-DRUG dataset, and the advantage remains large in few-step generation.", "abs": "", "categories": ["cs.LG", "cs.AI", "math.GR", "q-bio.BM"], "AI": {"tldr": "本文提出了一种新的生成模型框架——Canonical Diffusion，它通过将样本映射到具有规范姿态的轨道代表，并在规范切片上训练非等变扩散模型，从而解决了化学和科学领域中对称性带来的挑战，并在分子图生成任务中取得了优异效果。", "motivation": "传统方法通过等变架构和不变先验来强制执行对称性约束，但这种方法会带来显著的架构和计算开销，并可能掩盖对称性带来的潜在问题，例如潜在的“仪表”歧义和轨迹交叉。", "method": "Canonical Diffusion框架首先将每个样本映射到具有规范姿态的轨道代表，然后在规范切片上训练一个非等变的扩散或流模型，最后通过在生成时采样随机对称变换来恢复不变分布。该框架结合了对偶空间视角、对齐先验和最优传输。", "result": "在3D分子生成任务中，Canonical Diffusion显著优于等变基线，并且在具有挑战性的GEOM-DRUG数据集上，CanonFlow实现了最先进的性能，尤其是在少步生成方面。", "conclusion": "Canonical Diffusion提供了一种更有效、更具表现力的生成模型方法，避免了传统方法中等变架构带来的复杂性，并为分子图生成等领域开辟了新的可能性。"}}
{"id": "2602.13419", "title": "Protect$^*$: Steerable Retrosynthesis through Neuro-Symbolic State Encoding", "authors": ["Shreyas Vinaya Sathyanarayana", "Shah Rahil Kirankumar", "Sharanabasava D. Hiremath", "Bharath Ramsundar"], "summary": "Large Language Models (LLMs) have shown remarkable potential in scientific domains like retrosynthesis; yet, they often lack the fine-grained control necessary to navigate complex problem spaces without error. A critical challenge is directing an LLM to avoid specific, chemically sensitive sites on a molecule - a task where unconstrained generation can lead to invalid or undesirable synthetic pathways. In this work, we introduce Protect$^*$, a neuro-symbolic framework that grounds the generative capabilities of Large Language Models (LLMs) in rigorous chemical logic. Our approach combines automated rule-based reasoning - using a comprehensive database of 55+ SMARTS patterns and 40+ characterized protecting groups - with the generative intuition of neural models. The system operates via a hybrid architecture: an ``automatic mode'' where symbolic logic deterministically identifies and guards reactive sites, and a ``human-in-the-loop mode'' that integrates expert strategic constraints. Through ``active state tracking,'' we inject hard symbolic constraints into the neural inference process via a dedicated protection state linked to canonical atom maps. We demonstrate this neuro-symbolic approach through case studies on complex natural products, including the discovery of a novel synthetic pathway for Erythromycin B, showing that grounding neural generation in symbolic logic enables reliable, expert-level autonomy.", "abs": "", "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG", "q-bio.BM"], "AI": {"tldr": "Protect∗是一个神经符号框架，通过将大型语言模型的生成能力与严格的化学逻辑相结合，实现了可控的逆合成分析，尤其擅长避免在分子中对化学敏感位点进行不必要的反应。", "motivation": "现有的大型语言模型在逆合成分析中潜力巨大，但缺乏对复杂问题空间进行精细控制的能力，尤其是在避免特定化学位点反应方面，容易生成无效或不理想的合成路径。", "method": "Protect∗采用神经-符号混合架构，结合了基于规则的推理（使用55+ SMARTS模式和40+保护基团数据库）和神经网络模型的生成直觉。通过“主动状态跟踪”，将硬符号约束注入到神经网络推理过程中，并引入了保护状态与规范原子图的关联。", "result": "通过复杂天然产物的案例研究，包括发现红霉素B的新型合成路径，证明了将神经网络生成与符号逻辑相结合能够实现可靠的、专家级别的自主性。", "conclusion": "Protect∗框架有效解决了在逆合成分析中对生成过程施加精细、专家驱动约束的难题，为科学发现领域LLM的应用提供了新的思路，并有望推动更可靠、更高效的化学合成研究。"}}
{"id": "2602.15029", "title": "Symmetry in language statistics shapes the geometry of model representations", "authors": ["Dhruva Karkada", "Daniel J. Korchinski", "Andres Nava", "Matthieu Wyart", "Yasaman Bahri"], "summary": "Although learned representations underlie neural networks' success, their fundamental properties remain poorly understood. A striking example is the emergence of simple geometric structures in LLM representations: for example, calendar months organize into a circle, years form a smooth one-dimensional manifold, and cities' latitudes and longitudes can be decoded by a linear probe. We show that the statistics of language exhibit a translation symmetry -- e.g., the co-occurrence probability of two months depends only on the time interval between them -- and we prove that the latter governs the aforementioned geometric structures in high-dimensional word embedding models. Moreover, we find that these structures persist even when the co-occurrence statistics are strongly perturbed (for example, by removing all sentences in which two months appear together) and at moderate embedding dimension. We show that this robustness naturally emerges if the co-occurrence statistics are collectively controlled by an underlying continuous latent variable. We empirically validate this theoretical framework in word embedding models, text embedding models, and large language models.", "abs": "", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.CL"], "AI": {"tldr": "本研究揭示了语言统计中的对称性如何塑造大型语言模型（LLM）的表示几何结构，例如月份形成环形、年份形成一维流形等。研究证明了这些几何结构源于语言中存在的平移对称性。", "motivation": "尽管深度学习模型取得了显著成功，但其内部表示的根本性质仍然不清楚。本研究旨在解释LLM表示中出现的简单几何结构，例如月份的环形排列和年份的一维流形。", "method": "研究人员分析了语言统计中的平移对称性，并证明了这种对称性支配了高维词嵌入模型中的几何结构。他们通过理论推导和实验验证，在词嵌入模型、文本嵌入模型和大型语言模型中验证了该框架，并研究了在扰动共现统计的情况下，这些结构是否仍然存在。", "result": "研究发现，语言统计中的对称性驱动了表示流形的形成，解释了循环概念的圆形表示、连续序列的“涟漪”一维流形以及空间时间坐标的线性解码等现象。理论分析预测了每个成分的幅度和频率，并表明长波模式对应于流形中的环形和圆形，而高次谐波对应于涟漪。", "conclusion": "本研究提供了一个统一的组织原则，解释了LLM表示中几何结构的出现，揭示了语言统计对称性与模型表示几何结构之间的内在联系。该研究为理解和设计更具解释性的LLM提供了新的视角。"}}
