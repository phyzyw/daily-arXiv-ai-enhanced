<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Probabilistic Computers for Neural Quantum States](https://arxiv.org/abs/2512.24558)
*Shuvro Chowdhury, Jasper Pieterse, Navid Anjum Aadit, Johan H. Mentink, Kerem Y. Camsari*

Main category: quant-ph

TL;DR: 本文结合稀疏玻尔兹曼机架构和概率计算硬件，利用FPGA实现的概率计算机加速了神经网络量子态的采样过程，有效解决了传统方法在模拟大规模量子多体系统中的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统量子多体模拟方法面临系统规模增长带来的挑战，神经网络量子态（NQS）虽然能有效表示多体波函数，但蒙特卡洛采样成本限制了其扩展性。

Method: 研究人员在FPGA上实现了一个概率计算机，将其作为能量基神经网络量子态的快速采样器。同时，引入了一种双采样算法来训练深度玻尔兹曼机，用条件采样取代了难以处理的边际化过程，从而训练更稀疏、更高效的深度模型。

Result: 利用概率计算机，研究人员成功地对二维横向场伊辛模型在临界点进行了模拟，实现了高达80×80（6400自旋）的晶格模拟，并训练了35×35（1225自旋）的系统。

Conclusion: 该研究表明，概率硬件能够克服神经网络量子态中的采样瓶颈，为模拟更大规模的量子多体系统和更深层次的变分架构开辟了道路。

Abstract: Neural quantum states efficiently represent many-body wavefunctions with neural networks, but the cost of Monte Carlo sampling limits their scaling to large system sizes. Here we address this challenge by combining sparse Boltzmann machine architectures with probabilistic computing hardware. We implement a probabilistic computer on field programmable gate arrays (FPGAs) and use it as a fast sampler for energy-based neural quantum states. For the two-dimensional transverse-field Ising model at criticality, we obtain accurate ground-state energies for lattices up to 80 $\times$ 80 (6400 spins) using a custom multi-FPGA cluster. Furthermore, we introduce a dual-sampling algorithm to train deep Boltzmann machines, replacing intractable marginalization with conditional sampling over auxiliary layers. This enables the training of sparse deep models and improves parameter efficiency relative to shallow networks. Using this algorithm, we train deep Boltzmann machines for a system with 35 $\times$ 35 (1225 spins). Together, these results demonstrate that probabilistic hardware can overcome the sampling bottleneck in variational simulation of quantum many-body systems, opening a path to larger system sizes and deeper variational architectures.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Generative forecasting with joint probability models](https://arxiv.org/abs/2512.24446)
*Patrick Wyrod, Ashesh Chattopadhyay, Daniele Venturi*

Main category: cs.LG

TL;DR: 本文提出了一种新的生成式预测方法，通过学习滞后系统状态的联合概率分布来预测混沌动力系统的演化，从而更好地捕捉非线性时序依赖性和多步轨迹。


<details>
  <summary>Details</summary>
Motivation: 混沌动力系统对初始条件敏感且包含未解决的多尺度过程，导致确定性预测存在根本局限。生成模型通过学习系统演化的可能性分布提供了一种替代方案，但现有方法通常侧重于条件预测，而非底层动力结构的建模。

Method: 该方法将预测重新定义为完全生成问题，学习短时间窗口内滞后系统状态的联合概率分布，并通过边缘化获得预测。提出了一种通用的、与模型无关的训练和推理框架，并引入了三种不确定性量化指标（集成方差、短程自相关和累积 Wasserstein 漂移）来评估预测的稳健性和可靠性。

Result: 在 Lorenz–63 系统和 Kuramoto–Sivashinsky 方程的实验中，联合生成模型在短期预测能力、保持吸引子几何形状和实现更准确的长期统计行为方面优于传统的条件下一阶预测模型。

Conclusion: 联合生成模型为混沌动力系统的预测提供了一种更准确、更可靠的方法，能够更好地处理模型不足和不确定性，并为科学机器学习领域提供了一种有价值的工具。

Abstract: Chaotic dynamical systems exhibit strong sensitivity to initial conditions and often contain unresolved multiscale processes, making deterministic forecasting fundamentally limited. Generative models offer an appealing alternative by learning distributions over plausible system evolutions; yet, most existing approaches focus on next-step conditional prediction rather than the structure of the underlying dynamics. In this work, we reframe forecasting as a fully generative problem by learning the joint probability distribution of lagged system states over short temporal windows and obtaining forecasts through marginalization. This new perspective allows the model to capture nonlinear temporal dependencies, represent multistep trajectory segments, and produce next-step predictions consistent with the learned joint distribution. We also introduce a general, model-agnostic training and inference framework for joint generative forecasting and show how it enables assessment of forecast robustness and reliability using three complementary uncertainty quantification metrics (ensemble variance, short-horizon autocorrelation, and cumulative Wasserstein drift), without access to ground truth. We evaluate the performance of the proposed method on two canonical chaotic dynamical systems, the Lorenz-63 system and the Kuramoto-Sivashinsky equation, and show that joint generative models yield improved short-term predictive skill, preserve attractor geometry, and achieve substantially more accurate long-range statistical behaviour than conventional conditional next-step models.

</details>


### [3] [A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling](https://arxiv.org/abs/2512.24643)
*Malikussaid, Septian Caesar Floresko, Ade Romadhony, Isman Kurniawan, Warih Maharani, Hilal Hudan Nuha*

Main category: cs.LG

TL;DR: 本文提出了一种可扩展的logP预测框架，通过高效的数据集成和可解释的集成建模，显著提升了logP预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 准确预测分子脂溶性（logP）是计算药物发现的关键挑战，影响药物的吸收、分布、代谢、排泄和毒性等多个参数。现有方法在处理大规模数据和解决异方差性方面存在局限。

Method: 研究人员整合了PubChem、ChEMBL和eMolecules三个权威化学数据库中的426850个生物活性化合物，开发了一种基于字节偏移索引的计算基础设施，以加速数据集成。并系统评估了多种建模方法，包括线性模型、随机森林和XGBoost等集成方法，并采用分层建模策略。

Result: 通过优化数据集成流程，将处理时间从100多天缩短至3.2小时。集成方法（Random Forest和XGBoost）在测试集上实现了R² = 0.765和RMSE = 0.731 logP单位。分层建模策略在药物样分子和极端情况下分别实现了RMSE = 0.838和R² = 0.767。

Conclusion: 该研究为分子设计提供了可操作的指导，建立了仅使用2D描述符的logP预测基准，并证明了精心策划的基于描述符的集成模型仍然可以与最先进的图神经网络架构竞争。

Abstract: This study presents a large-scale predictive modeling framework for logP prediction using 426850 bioactive compounds rigorously curated from the intersection of three authoritative chemical databases: PubChem, ChEMBL, and eMolecules. We developed a novel computational infrastructure to address the data integration challenge, reducing processing time from a projected over 100 days to 3.2 hours through byte-offset indexing architecture, a 740-fold improvement. Our comprehensive analysis revealed critical insights into the multivariate nature of lipophilicity: while molecular weight exhibited weak bivariate correlation with logP, SHAP analysis on ensemble models identified it as the single most important predictor globally. We systematically evaluated multiple modeling approaches, discovering that linear models suffered from inherent heteroskedasticity that classical remediation strategies, including weighted least squares and Box-Cox transformation, failed to address. Tree-based ensemble methods, including Random Forest and XGBoost, proved inherently robust to this violation, achieving an R-squared of 0.765 and RMSE of 0.731 logP units on the test set. Furthermore, a stratified modeling strategy, employing specialized models for drug-like molecules (91 percent of dataset) and extreme cases (nine percent), achieved optimal performance: an RMSE of 0.838 for the drug-like subset and an R-squared of 0.767 for extreme molecules, the highest of all evaluated approaches. These findings provide actionable guidance for molecular design, establish robust baselines for lipophilicity prediction using only 2D descriptors, and demonstrate that well-curated, descriptor-based ensemble models remain competitive with state-of-the-art graph neural network architectures.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [4] [Assessing generative modeling approaches for free energy estimates in condensed matter](https://arxiv.org/abs/2512.23930)
*Maximilian Schebek, Jiajun He, Emil Hoffmann, Yuanqi Du, Frank Noé, Jutta Rogal*

Main category: cond-mat.stat-mech

TL;DR: 本文系统评估了生成模型方法在凝聚态系统中的自由能估计能力，比较了不同方法的效率、准确性和可扩展性，旨在为选择合适的自由能估计策略提供定量框架。


<details>
  <summary>Details</summary>
Motivation: 传统的自由能计算方法计算成本高昂，尤其是在两个状态的相空间重叠度较低时。生成模型方法通过直接学习分布之间的桥梁，绕过了中间状态的采样，但目前尚不清楚哪种方法在效率、准确性和可扩展性之间提供了最佳平衡。

Method: 本文研究了离散和连续正态流在有针对性的自由能扰动中的性能，以及FEAT（自适应传输的自由能估计器）与 escorted Jarzynski 等式结合使用的情况。以粗粒化的单原子冰和 Lennard-Jones 固体作为基准系统进行评估，评估了准确性、数据效率、计算成本和系统规模的可扩展性。

Result: 研究结果表明，不同的生成模型方法在自由能估计方面表现出不同的优缺点，在准确性、数据效率、计算成本和可扩展性方面存在差异。通过对这些方法的定量比较，可以为选择合适的自由能估计策略提供指导。

Conclusion: 本文提供了一个用于选择凝聚相系统有效自由能估计策略的定量框架，有助于加速材料科学中的自由能计算，并为理解和预测物质的稳定性提供更可靠的依据。

Abstract: The accurate estimation of free energy differences between two states is a long-standing challenge in molecular simulations. Traditional approaches generally rely on sampling multiple intermediate states to ensure sufficient overlap in phase space and are, consequently, computationally expensive. Several generative-model-based methods have recently addressed this challenge by learning a direct bridge between distributions, bypassing the need for intermediate states. However, it remains unclear which approaches provide the best trade-off between efficiency, accuracy, and scalability. In this work, we systematically review these methods and benchmark selected approaches with a focus on condensed-matter systems. In particular, we investigate the performance of discrete and continuous normalizing flows in the context of targeted free energy perturbation as well as FEAT (Free energy Estimators with Adaptive Transport) together with the escorted Jarzynski equality, using coarse-grained monatomic ice and Lennard-Jones solids as benchmark systems. We evaluate accuracy, data efficiency, computational cost, and scalability with system size. Our results provide a quantitative framework for selecting effective free energy estimation strategies in condensed-phase systems.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [5] [Towards mechanistic understanding in a data-driven weather model: internal activations reveal interpretable physical features](https://arxiv.org/abs/2512.24440)
*Theodore MacMillan, Nicholas T. Ouellette*

Main category: physics.ao-ph

TL;DR: 本文研究了数据驱动天气模型GraphCast的内部计算，利用稀疏自编码器发现了模型中对应于热带气旋、大气河流等物理特征的可解释神经元组合，并验证了通过干预这些特征可以影响模型预测。


<details>
  <summary>Details</summary>
Motivation: 数据驱动物理模型虽然性能优异，但其内部计算过程不透明，难以理解其是否编码了物理定律以及泛化能力。本文旨在探索这些模型是否学习并编码了可解释的物理抽象，从而提高对模型的信任度。

Method: 研究人员将大型语言模型中的可解释性工具（稀疏自编码器）应用于GraphCast的隐藏层，通过无监督学习发现模型中可解释的特征组合。

Result: 研究发现GraphCast模型内部存在对应于热带气旋、大气河流、日周和年周行为、大尺度降水模式、特定地理编码和海冰范围等多种尺度特征。通过干预热带气旋特征，观察到对飓风演化的可解释和物理一致的修改。

Conclusion: 该研究为理解数据驱动物理模型提供了窗口，证明了这些模型能够学习训练数据之外的物理表示，为将数据驱动模型作为可信赖的预测工具和科学发现的工具奠定了基础。

Abstract: Large data-driven physics models like DeepMind's weather model GraphCast have empirically succeeded in parameterizing time operators for complex dynamical systems with an accuracy reaching or in some cases exceeding that of traditional physics-based solvers. Unfortunately, how these data-driven models perform computations is largely unknown and whether their internal representations are interpretable or physically consistent is an open question. Here, we adapt tools from interpretability research in Large Language Models to analyze intermediate computational layers in GraphCast, leveraging sparse autoencoders to discover interpretable features in the neuron space of the model. We uncover distinct features on a wide range of length and time scales that correspond to tropical cyclones, atmospheric rivers, diurnal and seasonal behavior, large-scale precipitation patterns, specific geographical coding, and sea-ice extent, among others. We further demonstrate how the precise abstraction of these features can be probed via interventions on the prediction steps of the model. As a case study, we sparsely modify a feature corresponding to tropical cyclones in GraphCast and observe interpretable and physically consistent modifications to evolving hurricanes. Such methods offer a window into the black-box behavior of data-driven physics models and are a step towards realizing their potential as trustworthy predictors and scientifically valuable tools for discovery.

</details>
