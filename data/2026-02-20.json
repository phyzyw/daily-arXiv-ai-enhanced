{"id": "2602.17089", "title": "Synergizing Transport-Based Generative Models and Latent Geometry for Stochastic Closure Modeling", "authors": ["Xinghao Dong", "Huchen Yang", "Jin-long Wu"], "summary": "Diffusion models recently developed for generative AI tasks can produce high-quality samples while still maintaining diversity among samples to promote mode coverage, providing a promising path for learning stochastic closure models. Compared to other types of generative AI models, such as GANs and VAEs, the sampling speed is known as a key disadvantage of diffusion models. By systematically comparing transport-based generative models on a numerical example of 2D Kolmogorov flows, we show that flow matching in a lower-dimensional latent space is suited for fast sampling of stochastic closure models, enabling single-step sampling that is up to two orders of magnitude faster than iterative diffusion-based approaches. To control the latent space distortion and thus ensure the physical fidelity of the sampled closure term, we compare the implicit regularization offered by a joint training scheme against two explicit regularizers: metric-preserving (MP) and geometry-aware (GA) constraints. Besides offering a faster sampling speed, both explicitly and implicitly regularized latent spaces inherit the key topological information from the lower-dimensional manifold of the original complex dynamical system, which enables the learning of stochastic closure models without demanding a huge amount of training data.", "published": "2026-02-19", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "pdf_url": "https://arxiv.org/pdf/2602.17089v1", "primary_category": "cs.LG"}
{"id": "2602.17176", "title": "Universal Fine-Grained Symmetry Inference and Enforcement for Rigorous Crystal Structure Prediction", "authors": ["Shi Yin", "Jinming Mu", "Xudong Zhu", "Lixin He"], "summary": "Crystal structure prediction (CSP), which aims to predict the three-dimensional atomic arrangement of a crystal from its composition, is central to materials discovery and mechanistic understanding. Existing deep learning models often treat crystallographic symmetry only as a soft heuristic or rely on space group and Wyckoff templates retrieved from known structures, which limits both physical fidelity and the ability to discover genuinely new material structures. In contrast to retrieval-based methods, our approach leverages large language models to encode chemical semantics and directly generate fine-grained Wyckoff patterns from composition, effectively circumventing the limitations inherent to database lookups. Crucially, we incorporate domain knowledge into the generative process through an efficient constrained-optimization search that rigorously enforces algebraic consistency between site multiplicities and atomic stoichiometry. By integrating this symmetry-consistent template into a diffusion backbone, our approach constrains the stochastic generative trajectory to a physically valid geometric manifold. This framework achieves state-of-the-art performance across stability, uniqueness, and novelty (SUN) benchmarks, alongside superior matching performance, thereby establishing a new paradigm for the rigorous exploration of targeted crystallographic space. This framework enables efficient expansion into previously uncharted materials space, eliminating reliance on existing databases or a priori structural knowledge.", "published": "2026-02-19", "categories": ["cond-mat.mtrl-sci", "cs.AI", "physics.comp-ph"], "pdf_url": "https://arxiv.org/pdf/2602.17176v1", "primary_category": "cond-mat.mtrl-sci"}
