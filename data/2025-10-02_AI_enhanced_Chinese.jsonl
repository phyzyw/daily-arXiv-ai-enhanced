{"id": "2509.26261", "title": "Why is topology hard to learn?", "authors": ["D. O. Oriekhov", "Stan Bergkamp", "Guliuxin Jin", "Juan Daniel Torres Luna", "Badr Zouggari", "Sibren van der Meer", "Naoual El Yazidi", "Eliska Greplova"], "summary": "Much attention has been devoted to the use of machine learning to approximate physical concepts. Yet, due to challenges in interpretability of machine learning techniques, the question of what physics machine learning models are able to learn remains open. Here we bridge the concept a physical quantity and its machine learning approximation in the context of the original application of neural networks in physics: topological phase classification. We construct a hybrid tensor-neural network object that exactly expresses real space topological invariant and rigorously assess its trainability and generalization. Specifically, we benchmark the accuracy and trainability of a tensor-neural network to multiple types of neural networks, thus exemplifying the differences in trainability and representational power. Our work highlights the challenges in learning topological invariants and constitutes a stepping stone towards more accurate and better generalizable machine learning representations in condensed matter physics.", "abs": "", "categories": ["cond-mat.mes-hall", "cond-mat.dis-nn", "cs.LG"], "AI": {"tldr": "本文研究了机器学习模型学习拓扑相的难点，通过构建一个精确表达实空间拓扑不变量的混合张量-神经网络模型，并与传统神经网络进行对比，揭示了机器学习学习拓扑不变量的挑战。", "motivation": "尽管机器学习在物理概念近似方面应用广泛，但机器学习模型是否真正理解物理学，尤其是在拓扑相分类中，仍不清楚。本文旨在弥合物理量和其机器学习近似之间的差距，并解决机器学习模型是否能绕过拓扑不变量的复杂性。", "method": "研究人员构建了一个混合张量-神经网络模型，该模型精确表达实空间绕组数，并将其在扩展的Su-Schriefer-Heeger模型上与不同类型的无物理神经网络进行基准测试。他们分析了训练期间的权重行为，并将其与原始拓扑不变量公式相关联。", "result": "研究结果表明，可以构建一个神经网络模型来精确学习拓扑不变量，而不是仅仅学习数据集中的代理。混合张量-神经网络模型比传统神经网络以四个数量级的更高精度逼近拓扑不变量。", "conclusion": "本文强调了学习拓扑不变量的挑战，并为在凝聚态物理学中开发更准确、更具泛化能力的机器学习表示方法奠定了基础。研究结果表明，机器学习模型确实可以学习拓扑不变量，而不仅仅是数据集中的近似值。"}}
