<div id=toc></div>

# Table of Contents

- [physics.chem-ph](#physics.chem-ph) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [1] [DeepEOSNet: Capturing the dependency on thermodynamic state in property prediction tasks](https://arxiv.org/abs/2509.17018)
*Jan Pavšek, Alexander Mitsos, Manuel Dahmen, Tai Xuan Tan, Jan G. Rittig*

Main category: physics.chem-ph

TL;DR: 本文提出了一种名为DeepEOSNet的新型机器学习架构，通过分离处理分子结构和状态依赖性来预测热力学性质，并在多个案例中表现出优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模型在预测状态相关的热力学性质时，通常将状态信息与分子指纹向量连接或嵌入半经验热力学关系，这使得模型难以同时学习分子结构和状态依赖性。

Method: DeepEOSNet采用图神经网络和多层感知机两个独立的网络通道分别处理分子结构和状态依赖性，并通过点积结合两者的输出。该架构借鉴了DeepONet的思想，学习状态依赖关系，并具备预测状态方程的潜力。

Result: 在蒸汽压预测和混合摩尔体积预测的案例研究中，DeepEOSNet在蒸汽压预测方面表现出优异的性能，在混合摩尔体积预测方面与现有模型相当。特别是在状态域数据稀疏且输出函数在不同分子中结构相似的情况下，DeepEOSNet具有巨大潜力。

Conclusion: DeepEOSNet提供了一种可行的分子性质预测选项，其概念易于转移到其他机器学习架构中，有望加速具有所需性质的分子识别，从而提高化学过程的效率。

Abstract: We propose a machine learning (ML) architecture to better capture the dependency of thermodynamic properties on the independent states. When predicting state-dependent thermodynamic properties, ML models need to account for both molecular structure and the thermodynamic state, described by independent variables, typically temperature, pressure, and composition. Modern molecular ML models typically include state information by adding it to molecular fingerprint vectors or by embedding explicit (semi-empirical) thermodynamic relations. Here, we propose to rather split the information processing on the molecular structure and the dependency on states into two separate network channels: a graph neural network and a multilayer perceptron, whose output is combined by a dot product. We refer to our approach as DeepEOSNet, as this idea is based on the DeepONet architecture [Lu et al. (2021), Nat. Mach. Intell.]: instead of operators, we learn state dependencies, with the possibility to predict equation of states (EOS). We investigate the predictive performance of DeepEOSNet by means of three case studies, which include the prediction of vapor pressure as a function of temperature, and mixture molar volume as a function of composition, temperature, and pressure. Our results show superior performance of DeepEOSNet for predicting vapor pressure and comparable performance for predicting mixture molar volume compared to state-of-research graph-based thermodynamic prediction models from our earlier works. In fact, we see large potential of DeepEOSNet in cases where data is sparse in the state domain and the output function is structurally similar across different molecules. The concept of DeepEOSNet can easily be transferred to other ML architectures in molecular context, and thus provides a viable option for property prediction.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [2] [AI-based Methods for Simulating, Sampling, and Predicting Protein Ensembles](https://arxiv.org/abs/2509.17224)
*Bowen Jing, Bonnie Berger, Tommi Jaakkola*

Main category: q-bio.BM

TL;DR: 本文综述了利用人工智能预测蛋白质集合的方法，旨在克服传统分子动力学模拟的局限性，加速蛋白质结构研究。


<details>
  <summary>Details</summary>
Motivation: 传统分子动力学模拟在探索蛋白质构象空间时存在时间尺度分离问题，计算成本高昂。人工智能方法有望提供更快速、更廉价的蛋白质集合计算方法，加速计算与实验的迭代。

Method: 综述涵盖了多种人工智能方法，包括粗粒化力场、生成模型、多序列比对扰动方法以及集合描述符建模。这些方法利用深度神经网络来近似各种函数，并根据所近似的函数类型进行分类。

Result: 评估了这些方法的成熟度，包括预测集合的准确性、适用系统的大小以及泛化能力。同时，也关注了新兴的机器学习框架，即使它们尚未达到实际应用水平。

Conclusion: 文章倡导在模型训练、模拟和推断之间建立闭环，以克服训练数据可用性的挑战，并推动下一代蛋白质集合预测模型的发展。

Abstract: Advances in deep learning have opened an era of abundant and accurate predicted protein structures; however, similar progress in protein ensembles has remained elusive. This review highlights several recent research directions towards AI-based predictions of protein ensembles, including coarse-grained force fields, generative models, multiple sequence alignment perturbation methods, and modeling of ensemble descriptors. An emphasis is placed on realistic assessments of the technological maturity of current methods, the strengths and weaknesses of broad families of techniques, and promising machine learning frameworks at an early stage of development. We advocate for "closing the loop" between model training, simulation, and inference to overcome challenges in training data availability and to enable the next generation of models.

</details>
