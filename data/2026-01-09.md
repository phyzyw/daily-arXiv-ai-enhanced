<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Differential syntactic and semantic encoding in LLMs](https://arxiv.org/abs/2601.04765)
*Santiago Acevedo, Alessandro Laio, Marco Baroni*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）中句法和语义信息的编码方式，发现它们至少部分线性编码，且在不同层级上呈现出差异。


<details>
  <summary>Details</summary>
Motivation: 为了理解LLMs如何存储语言能力，以及句法和语义在语言中的分离程度，本研究旨在探究LLMs内部层表示中句法和语义信息的编码方式。

Method: 研究人员通过平均共享相同句法结构或语义内容的句子向量来构建句法和语义“质心”，然后从句子向量中减去这些质心，以评估其对句子相似性的影响。同时，他们分析了句法和语义在不同层级上的编码特征。

Result: 研究发现，通过减去句法和语义质心，可以显著影响句子向量与句法或语义匹配句子的相似度，表明句法和语义至少部分线性编码。此外，句法和语义的跨层编码模式不同，并且可以一定程度上解耦，语义主要编码在中心层，而句法在更广泛的层级中保持显著。

Conclusion: 本研究为LLMs的可解释性提供了新的见解，表明LLMs的中心层存在更深层次的语言处理，并且支持了深度网络通过简单的线性叠加来编码信息的假设，进一步揭示了LLMs内部句法和语义信息编码的差异。

Abstract: We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Robust Reasoning as a Symmetry-Protected Topological Phase](https://arxiv.org/abs/2601.05240)
*Ilmo Sung*

Main category: cs.LG

TL;DR: 本文提出将鲁棒推理视为一种对称保护拓扑相，利用非阿贝尔任何子交换编织的拓扑不变性来替代脆弱的几何插值，从而提高逻辑推理的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型容易产生“幻觉”，即逻辑不一致性。研究旨在解决这种脆弱性，并探索一种能够实现鲁棒推理的新型架构，克服传统模型在长程推理中面临的逻辑一致性丧失问题。

Method: 作者提出了一种“全同网络”（Holonomic Network），该网络将逻辑操作形式上等同于非阿贝尔任何子编织，从而构建一种对称保护拓扑相。通过构建具有10(3.6×10^6)状态的符号操作任务，评估了该模型的泛化能力。

Result: 实验表明，全同网络在噪声阈值以下表现出宏观“质量间隙”，保持不变的保真度。在S 10(3.6×10^6)上的变量绑定任务中，该模型实现了100倍的泛化能力，而Transformer模型则丧失了逻辑一致性。消融研究表明，这种保护性来自非阿贝尔规范对称性。

Conclusion: 该研究表明，逻辑推理可能属于一种新的普适性类别，将因果稳定性与语义流形的拓扑结构联系起来，为构建更鲁棒、更可靠的AI系统提供了新的思路。

Abstract: Large language models suffer from "hallucinations"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a "Metric Phase," where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic "mass gap," maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\times$ beyond training ($L=50 \to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.

</details>
