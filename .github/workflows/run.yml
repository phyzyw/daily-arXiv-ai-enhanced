name: arXiv-daily-ai-enhanced
on:
  schedule:
    - cron: "03 19 * * *"
  workflow_dispatch:
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # --------------------------
      # 步骤1：安装 Miniconda 并创建环境
      # --------------------------
      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: 3.10
          miniconda-version: "latest"

      - name: Create and configure environments
        run: |
          # 1. 创建爬取专用环境（crawl-env）
          echo "=== 创建爬取专用环境（crawl-env） ==="
          conda create -n crawl-env python=3.10 -y
          conda activate crawl-env
          
          # 安装依赖包
          conda install -c conda-forge pip -y
          pip install pymed==0.8.9 arxiv==2.1.3 requests==2.32.5
          
          # 记录Python路径
          export CRAWL_PYTHON="$(which python)"
          echo "爬取环境Python路径：$CRAWL_PYTHON"
          echo "CRAWL_PYTHON=$CRAWL_PYTHON" >> $GITHUB_ENV
          
          # 验证安装
          echo "✅ 爬取环境已安装包："
          pip list
          
          # 2. 创建主环境（main-env）
          echo -e "\n=== 创建主环境（main-env） ==="
          conda create -n main-env python=3.10 -y
          conda activate main-env
          
          # 安装依赖包
          conda install -c conda-forge pip -y
          pip install scrapy==2.12.0 langchain==0.3.20 langchain-openai==0.3.9 openai==1.66.3
          
          # 同步其他依赖
          if [ -f "requirements.txt" ]; then
            pip install -r requirements.txt
          fi
          
          # 记录Python路径
          export MAIN_PYTHON="$(which python)"
          echo "主环境Python路径：$MAIN_PYTHON"
          echo "MAIN_PYTHON=$MAIN_PYTHON" >> $GITHUB_ENV
          
          # 验证安装
          echo "✅ 主环境已安装包："
          pip list

      # --------------------------
      # 步骤2：arXiv爬取（使用crawl-env）
      # --------------------------
      - name: Crawl arXiv papers (isolated env)
        id: crawl_step
        run: |
          # 激活爬取环境
          conda activate crawl-env
          
          # 从环境变量获取爬取Python路径
          CRAWL_PYTHON="${{ env.CRAWL_PYTHON }}"
          echo "=== 预检查爬取环境pymed导入 ==="
          
          # 检查pymed是否正确安装
          if python -c "import pymed; print('✅ pymed导入成功')"; then
            echo "pymed预检查通过"
          else
            echo "❌ pymed预检查失败，终止爬取"
            echo "当前环境Python路径：$CRAWL_PYTHON"
            echo "当前环境已安装包："
            pip list
            exit 1
          fi

          # 准备日期和目录
          today=$(date -u "+%Y-%m-%d")
          mkdir -p data
          echo "开始爬取 $today 的arXiv论文... / Starting to crawl $today arXiv papers..."

          # 删除旧文件（如有）
          if [ -f "data/${today}.jsonl" ]; then
              echo "🗑️ 删除现有文件：data/${today}.jsonl"
              rm "data/${today}.jsonl"
          fi

          # 切换目录并设置环境变量
          cd daily_arxiv
          export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
          export LANGUAGE="${{ vars.LANGUAGE }}"
          export CATEGORIES="${{ vars.CATEGORIES }}"
          export MODEL_NAME="${{ vars.MODEL_NAME }}"
          export OUTPUT_FILE="../data/${today}.jsonl"

          # 运行爬取脚本
          echo "=== 开始运行爬取脚本 ==="
          python daily_arxiv/spiders/arxiv.py

          # 检查爬取结果
          if [ ! -f "../data/${today}.jsonl" ]; then
              echo "❌ 爬取失败：未生成数据文件"
              exit 1
          fi

          echo "crawl_date=$today" >> $GITHUB_OUTPUT
          echo "✅ 爬取完成，数据文件：data/${today}.jsonl"

      # --------------------------
      # 步骤3：去重检查（使用main-env）
      # --------------------------
      - name: Check for duplicates (main env)
        run: |
          # 激活主环境
          conda activate main-env
          
          echo "=== 开始去重检查（使用主环境） ==="
          cd daily_arxiv
          set +e
          
          # 运行去重脚本
          python daily_arxiv/check_stats.py
          dedup_exit_code=$?
          set -e

          echo "去重检查退出码: $dedup_exit_code"
          echo "dedup_exit_code=$dedup_exit_code" >> $GITHUB_OUTPUT

          # 判断是否有新内容
          case $dedup_exit_code in
              0)
                  echo "has_new_content=true" >> $GITHUB_OUTPUT
                  ;;
              1)
                  echo "has_new_content=false" >> $GITHUB_OUTPUT
                  echo "skip_reason=no_new_content" >> $GITHUB_OUTPUT
                  ;;
              2)
                  echo "has_new_content=false" >> $GITHUB_OUTPUT
                  echo "skip_reason=processing_error" >> $GITHUB_OUTPUT
                  exit 1
                  ;;
              *)
                  echo "❌ 未知退出码，终止工作流"
                  echo "has_new_content=false" >> $GITHUB_OUTPUT
                  echo "skip_reason=unknown_error" >> $GITHUB_OUTPUT
                  exit 1
                  ;;
          esac

      # --------------------------
      # 步骤4：AI增强（使用main-env）
      # --------------------------
      - name: AI Enhancement Processing (main env)
        run: |
          # 激活主环境
          conda activate main-env
          
          today=${{ steps.crawl_step.outputs.crawl_date }}
          echo "=== 开始AI增强处理（使用主环境） ==="

          cd ai
          export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
          export LANGUAGE="${{ vars.LANGUAGE }}"
          export MODEL_NAME="${{ vars.MODEL_NAME }}"

          # 运行AI增强脚本
          python enhance.py --data ../data/${today}.jsonl

          if [ $? -ne 0 ]; then
              echo "❌ AI处理失败"
              exit 1
          fi
          echo "✅ AI增强处理完成"

      # --------------------------
      # 步骤5：Markdown转换（使用main-env）
      # --------------------------
      - name: Convert to Markdown (main env)
        if: steps.dedup_check.outputs.has_new_content == 'true'
        shell: bash -l {0}  # 确保conda环境在shell中可用
        run: |
          # 激活主环境
          conda activate main-env
          
          today=${{ steps.crawl_step.outputs.crawl_date }}
          echo "=== 开始Markdown转换（使用主环境） ==="

          export LANGUAGE="${{ vars.LANGUAGE }}"
          cd to_md
          AI_FILE="../data/${today}_AI_enhanced_${LANGUAGE}.jsonl"

          if [ ! -f "$AI_FILE" ]; then
              echo "❌ 未找到AI增强文件：$AI_FILE"
              exit 1
          fi

          # 运行转换脚本
          python convert.py --data "$AI_FILE"

          if [ $? -ne 0 ]; then
              echo "❌ Markdown转换失败"
              exit 1
          fi
          echo "✅ Markdown转换完成"

      # --------------------------
      # 后续步骤（文件更新、提交等）
      # --------------------------
      - name: Update file list
        if: steps.dedup_check.outputs.has_new_content == 'true'
        run: |
          echo "=== 更新文件列表 ==="
          mkdir -p assets
          ls data/*.jsonl | sed 's|data/||' > assets/file-list.txt
          echo "✅ 文件列表更新完成"

      - name: Summary
        run: |
          if [ "${{ steps.dedup_check.outputs.has_new_content }}" = "true" ]; then
            echo "✅ 工作流完成：新内容已处理"
          else
            echo "ℹ️ 工作流完成：无新内容（原因：${{ steps.dedup_check.outputs.skip_reason }}）"
          fi

      - name: Commit changes
        if: steps.dedup_check.outputs.has_new_content == 'true'
        run: |
          git config --global user.email "${{ vars.EMAIL }}"
          git config --global user.name "${{ vars.NAME }}"
          git add .

          if git diff --staged --quiet; then
            echo "ℹ️ 无变更需提交"
            exit 0
          fi

          git commit -m "update: $(date -u '+%Y-%m-%d') arXiv papers"
          echo "✅ 变更已提交"

      - name: Pull latest changes and push
        if: steps.dedup_check.outputs.has_new_content == 'true'
        run: |
          git config pull.rebase true
          git config rebase.autoStash true

          for i in {1..3}; do
            echo "推送尝试 $i"
            if git push origin main; then
              echo "✅ 推送成功"
              break
            else
              echo "⚠️ 推送失败，拉取最新代码..."
              git pull origin main --no-edit || true
              if [ $i -eq 3 ]; then
                echo "❌ 3次尝试后推送失败"
                exit 1
              fi
            fi
          done
    
