name: arXiv-daily-ai-enhanced
on:
  schedule:
    - cron: "03 19 * * *"
  workflow_dispatch:
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # --------------------------
      # 步骤1：安装Miniconda（不指定Python版本，后续手动控制）
      # --------------------------
      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          miniconda-version: "latest"
          use-only-tar-bz2: false
          conda-remove-defaults: false
          environment-file: ""  # 不使用预设环境文件
          activate-environment: ""  # 不自动激活环境，后续手动激活base

      # --------------------------
      # 步骤2：激活base环境并降级Python到3.10（关键修复）
      # --------------------------
      - name: Activate base env and downgrade Python to 3.10
        shell: bash -l {0}  # 必须带-l {0}，确保加载Conda环境变量
        run: |
          # 1. 激活base环境（Conda默认环境）
          echo "=== 激活base环境 ==="
          conda activate base || { echo "❌ 无法激活base环境"; exit 1; }

          # 2. 降级Python到3.10（兼容所有依赖包）
          echo -e "\n=== 降级base环境Python到3.10 ==="
          # 使用conda-forge渠道确保版本稳定性，同时更新依赖以避免冲突
          if ! conda install -c conda-forge python=3.10 --update-deps -y; then
            echo "❌ Python降级失败，尝试强制安装"
            # 强制安装（解决依赖冲突的备选方案）
            conda install -c conda-forge python=3.10 --force-reinstall --update-deps -y || exit 1
          fi

          # 3. 验证Python版本
          echo -e "\n=== 验证base环境Python版本 ==="
          python --version
          if ! python --version | grep -q "3.10"; then
            echo "❌ Python版本未成功降级（当前版本：$(python --version)）"
            exit 1
          fi
          echo "✅ Python版本已确认：$(python --version)"

          # 4. 清理缓存（避免旧包干扰）
          echo -e "\n=== 清理Conda缓存 ==="
          conda clean --all -y --quiet

      # --------------------------
      # 步骤3：创建并配置两个独立环境（基于Python 3.10）
      # --------------------------
      - name: Create and configure isolated environments
        shell: bash -l {0}
        run: |
          # 确保处于base环境（避免环境残留）
          conda activate base || exit 1

          # 1. 创建爬取环境（crawl-env）
          echo "=== 创建爬取环境（crawl-env） ==="
          # 先删除旧环境（避免版本冲突）
          if conda info --envs | grep -q "crawl-env"; then
            conda env remove -n crawl-env -y
          fi
          # 显式指定Python 3.10，与base环境一致
          if ! conda create -n crawl-env -c conda-forge python=3.10 -y; then
            echo "❌ crawl-env创建失败"
            exit 1
          fi
          conda activate crawl-env || { echo "❌ 无法激活crawl-env"; exit 1; }

          # 安装爬取依赖（优先Conda渠道，缺失包用pip）
          echo -e "\n=== 安装爬取依赖 ==="
          conda install -c conda-forge requests=2.31.0 -y  # 固定版本避免兼容性问题
          pip install pymed==0.8.9 arxiv==2.1.3  # 仅PyPI有，用pip安装

          # 验证依赖（提前发现导入问题）
          echo -e "\n=== 验证爬取环境依赖 ==="
          if ! python -c "import pymed; import arxiv; import requests"; then
            echo "❌ 爬取环境依赖导入失败"
            pip list | grep -E "pymed|arxiv|requests"  # 打印包版本辅助排查
            exit 1
          fi
          echo "✅ 爬取环境配置完成"

          # 记录爬取环境Python路径（供后续步骤使用）
          echo "CRAWL_PYTHON=$(which python)" >> $GITHUB_ENV

          # 2. 创建主环境（main-env）
          echo -e "\n=== 创建主环境（main-env） ==="
          conda deactivate  # 退出crawl-env，避免干扰
          if conda info --envs | grep -q "main-env"; then
            conda env remove -n main-env -y
          fi
          if ! conda create -n main-env -c conda-forge python=3.10 -y; then
            echo "❌ main-env创建失败"
            exit 1
          fi
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }

          # 安装主环境依赖（scrapy从conda-forge安装，避免编译错误）
          echo -e "\n=== 安装主环境依赖 ==="
          conda install -c conda-forge scrapy==2.12.0 pip=24.0 -y  # 固定scrapy和pip版本
          pip install langchain==0.3.20 langchain-openai==0.3.9 openai==1.66.3

          # 安装requirements.txt（如有）
          if [ -f "requirements.txt" ]; then
            echo -e "\n=== 安装requirements.txt依赖 ==="
            pip install -r requirements.txt || { echo "❌ requirements.txt安装失败"; exit 1; }
          fi

          # 验证主环境依赖
          echo -e "\n=== 验证主环境依赖 ==="
          if ! python -c "import scrapy; import langchain; import openai"; then
            echo "❌ 主环境依赖导入失败"
            pip list | grep -E "scrapy|langchain|openai"
            exit 1
          fi
          echo "✅ 主环境配置完成"

          # 记录主环境Python路径
          echo "MAIN_PYTHON=$(which python)" >> $GITHUB_ENV

      # --------------------------
      # 步骤4：arXiv爬取（使用crawl-env）
      # --------------------------
      - name: Crawl arXiv papers (crawl-env)
        id: crawl_step
        shell: bash -l {0}
        run: |
          # 激活爬取环境
          conda activate crawl-env || { echo "❌ 无法激活crawl-env"; exit 1; }

          # 准备日期和输出目录
          today=$(date -u "+%Y-%m-%d")
          mkdir -p data
          output_file="data/${today}.jsonl"

          # 删除旧文件（避免数据重复）
          if [ -f "$output_file" ]; then
            echo "🗑️ 删除旧爬取文件：$output_file"
            rm "$output_file"
          fi

          # 配置环境变量并运行爬取脚本
          echo -e "\n=== 运行爬取脚本 ==="
          cd daily_arxiv || { echo "❌ 未找到daily_arxiv目录"; exit 1; }
          export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
          export LANGUAGE="${{ vars.LANGUAGE }}"
          export CATEGORIES="${{ vars.CATEGORIES }}"
          export MODEL_NAME="${{ vars.MODEL_NAME }}"
          export OUTPUT_FILE="../$output_file"

          # 使用爬取环境的Python执行脚本
          ${{ env.CRAWL_PYTHON }} daily_arxiv/spiders/arxiv.py || { echo "❌ 爬取脚本运行失败"; exit 1; }

          # 验证爬取结果（非空文件）
          if [ ! -f "../$output_file" ] || [ ! -s "../$output_file" ]; then
            echo "❌ 爬取失败：未生成有效文件（${output_file}）"
            exit 1
          fi
          echo -e "\n✅ 爬取完成，文件大小：$(du -sh "../$output_file" | cut -f1)"
          echo "crawl_date=$today" >> $GITHUB_OUTPUT

      # --------------------------
      # 步骤5：去重检查（使用main-env）
      # --------------------------
      - name: Check duplicates (main-env)
        id: dedup_check
        shell: bash -l {0}
        run: |
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }

          echo "=== 开始去重检查 ==="
          cd daily_arxiv || { echo "❌ 未找到daily_arxiv目录"; exit 1; }

          # 允许脚本返回非0 exit code（用于判断结果）
          set +e
          ${{ env.MAIN_PYTHON }} daily_arxiv/check_stats.py
          dedup_exit_code=$?
          set -e

          # 根据退出码判断结果（需与check_stats.py逻辑匹配）
          case $dedup_exit_code in
            0)
              echo "has_new_content=true" >> $GITHUB_OUTPUT
              echo "✅ 检测到新内容"
              ;;
            1)
              echo "has_new_content=false" >> $GITHUB_OUTPUT
              echo "skip_reason=no_new_content" >> $GITHUB_OUTPUT
              echo "ℹ️ 无新内容，跳过后续步骤"
              ;;
            *)
              echo "has_new_content=false" >> $GITHUB_OUTPUT
              echo "skip_reason=processing_error" >> $GITHUB_OUTPUT
              echo "❌ 去重检查出错（退出码：$dedup_exit_code），终止工作流"
              exit 1
              ;;
          esac

      # --------------------------
      # 步骤6：AI增强（main-env，仅当有新内容时运行）
      # --------------------------
      - name: AI Enhancement (main-env)
        if: steps.dedup_check.outputs.has_new_content == 'true'
        shell: bash -l {0}
        run: |
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }

          today=${{ steps.crawl_step.outputs.crawl_date }}
          input_file="data/${today}.jsonl"
          echo "=== 开始AI增强：$input_file ==="

          # 检查输入文件有效性
          if [ ! -f "$input_file" ] || [ ! -s "$input_file" ]; then
            echo "❌ 爬取文件无效（不存在或为空）：$input_file"
            exit 1
          fi

          # 运行AI增强脚本
          cd ai || { echo "❌ 未找到ai目录"; exit 1; }
          export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
          export LANGUAGE="${{ vars.LANGUAGE }}"
          export MODEL_NAME="${{ vars.MODEL_NAME }}"

          ${{ env.MAIN_PYTHON }} enhance.py --data "../$input_file" || { echo "❌ AI增强失败"; exit 1; }

          # 验证AI输出文件
          ai_output_file="../data/${today}_AI_enhanced_${LANGUAGE}.jsonl"
          if [ ! -f "$ai_output_file" ] || [ ! -s "$ai_output_file" ]; then
            echo "❌ AI增强未生成有效文件：$ai_output_file"
            exit 1
          fi
          echo "✅ AI增强完成，输出文件：$ai_output_file"

      # --------------------------
      # 步骤7：Markdown转换（main-env，仅当有新内容时运行）
      # --------------------------
      - name: Convert to Markdown (main-env)
        if: steps.dedup_check.outputs.has_new_content == 'true'
        shell: bash -l {0}
        run: |
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }

          today=${{ steps.crawl_step.outputs.crawl_date }}
          language="${{ vars.LANGUAGE }}"
          ai_file="data/${today}_AI_enhanced_${language}.jsonl"
          echo "=== 开始Markdown转换：$ai_file ==="

          # 检查AI增强文件有效性
          if [ ! -f "$ai_file" ] || [ ! -s "$ai_file" ]; then
            echo "❌ AI增强文件无效：$ai_file"
            exit 1
          fi

          # 运行转换脚本
          cd to_md || { echo "❌ 未找到to_md目录"; exit 1; }
          export LANGUAGE="$language"

          ${{ env.MAIN_PYTHON }} convert.py --data "../$ai_file" || { echo "❌ Markdown转换失败"; exit 1; }

          # 验证Markdown输出
          md_file="../data/${today}_AI_enhanced_${language}.md"
          if [ -f "$md_file" ] && [ -s "$md_file" ]; then
            echo "✅ Markdown转换完成，文件大小：$(du -sh "$md_file" | cut -f1)"
          else
            echo "❌ Markdown输出文件无效：$md_file"
            exit 1
          fi

      # --------------------------
      # 步骤8：文件更新与Git提交（仅当有新内容时运行）
      # --------------------------
      - name: Update file list and commit changes
        if: steps.dedup_check.outputs.has_new_content == 'true'
        run: |
          # 1. 更新文件列表（仅保留最新10个文件，避免列表过大）
          echo "=== 更新文件列表 ==="
          mkdir -p assets
          ls -1t data/*.jsonl data/*.md 2>/dev/null | head -n 10 > assets/file-list.txt
          echo "✅ 文件列表已更新：$(wc -l < assets/file-list.txt) 个文件"

          # 2. Git配置与提交
          echo -e "\n=== 提交变更到GitHub ==="
          git config --global user.email "${{ vars.EMAIL }}"
          git config --global user.name "${{ vars.NAME }}"

          # 暂存变更（仅跟踪data和assets目录）
          git add data/ assets/

          # 检查是否有变更需提交
          if git diff --staged --quiet; then
            echo "ℹ️ 无变更需提交"
            exit 0
          fi

          # 提交并推送（重试3次避免网络波动）
          git commit -m "update: ${{ steps.crawl_step.outputs.crawl_date }} arXiv papers (AI enhanced)"
          
          for i in {1..3}; do
            if git push origin main; then
              echo "✅ 推送成功（尝试 $i/3）"
              break
            else
              echo "⚠️ 推送失败（尝试 $i/3），拉取最新代码重试..."
              git pull origin main --no-edit || true  # 拉取最新代码解决冲突
              if [ $i -eq 3 ]; then
                echo "❌ 3次尝试后推送失败，终止流程"
                exit 1
              fi
            fi
          done

      # --------------------------
      # 步骤9：工作流总结
      # --------------------------
      - name: Workflow summary
        run: |
          echo -e "\n=== 工作流执行总结 ==="
          echo "执行时间：$(date -u "+%Y-%m-%d %H:%M:%S UTC")"
          echo "爬取日期：${{ steps.crawl_step.outputs.crawl_date }}"
          echo "是否有新内容：${{ steps.dedup_check.outputs.has_new_content }}"
          if [ "${{ steps.dedup_check.outputs.has_new_content }}" = "false" ]; then
            echo "跳过原因：${{ steps.dedup_check.outputs.skip_reason }}"
          fi
          echo -e "\n✅ 工作流执行结束"
