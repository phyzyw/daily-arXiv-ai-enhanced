name: arXiv-daily-ai-enhanced
on:
  schedule:
    - cron: "03 19 * * *"
  workflow_dispatch:
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # --------------------------
      # 步骤1：安装Miniconda（关键修复：不指定基础环境，使用默认配置）
      # --------------------------
      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          miniconda-version: "latest"
          use-only-tar-bz2: false
          conda-remove-defaults: false
          # 移除python-version和activate-environment，避免创建base环境
          environment-file: ""

      # --------------------------
      # 步骤2：初始化Conda并验证基础环境
      # --------------------------
      - name: Initialize Conda and verify base environment
        shell: bash -l {0}
        run: |
          # 验证Conda安装
          echo "=== Conda版本信息 ==="
          conda --version
          
          # 确认base环境存在（Conda默认创建）
          echo -e "\n=== 已存在的环境 ==="
          conda info --envs
          
          # 检查Python版本，确保满足要求
          echo -e "\n=== Base环境Python版本 ==="
          python --version
          if ! python --version | grep -q "3.10\|3.11"; then
            echo "❌ Base环境Python版本不兼容（需要3.10或3.11）"
            exit 1
          fi
          
          # 清理缓存
          conda clean --all -y --quiet

      # --------------------------
      # 步骤3：创建并配置两个独立环境
      # --------------------------
      - name: Create and configure environments
        shell: bash -l {0}
        run: |
          # 1. 创建爬取专用环境（crawl-env）
          echo "=== 创建爬取环境（crawl-env） ==="
          if conda info --envs | grep -q "crawl-env"; then
            conda env remove -n crawl-env -y
          fi
          if ! conda create -n crawl-env python=3.10 -y; then
            echo "❌ 爬取环境创建失败"
            exit 1
          fi
          conda activate crawl-env || { echo "❌ 无法激活crawl-env"; exit 1; }
          
          # 安装爬取依赖
          conda install -c conda-forge pip requests -y
          pip install pymed==0.8.9 arxiv==2.1.3
          
          # 记录Python路径
          export CRAWL_PYTHON="$(which python)"
          echo "CRAWL_PYTHON=$CRAWL_PYTHON" >> $GITHUB_ENV
          
          # 验证依赖
          if ! python -c "import pymed; import arxiv; import requests"; then
            echo "❌ 爬取环境依赖验证失败"
            exit 1
          fi

          # 2. 创建主环境（main-env）
          echo -e "\n=== 创建主环境（main-env） ==="
          conda deactivate
          if conda info --envs | grep -q "main-env"; then
            conda env remove -n main-env -y
          fi
          if ! conda create -n main-env python=3.10 -y; then
            echo "❌ 主环境创建失败"
            exit 1
          fi
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }
          
          # 安装主环境依赖
          conda install -c conda-forge pip scrapy==2.12.0 -y
          pip install langchain==0.3.20 langchain-openai==0.3.9 openai==1.66.3
          
          # 安装requirements.txt依赖
          if [ -f "requirements.txt" ]; then
            pip install -r requirements.txt || { echo "❌ requirements.txt安装失败"; exit 1; }
          fi
          
          # 记录Python路径
          export MAIN_PYTHON="$(which python)"
          echo "MAIN_PYTHON=$MAIN_PYTHON" >> $GITHUB_ENV
          
          # 验证依赖
          if ! python -c "import scrapy; import langchain; import openai"; then
            echo "❌ 主环境依赖验证失败"
            exit 1
          fi

      # --------------------------
      # 步骤4：arXiv爬取（使用crawl-env）
      # --------------------------
      - name: Crawl arXiv papers (crawl-env)
        id: crawl_step
        shell: bash -l {0}
        run: |
          conda activate crawl-env || { echo "❌ 无法激活crawl-env"; exit 1; }
          
          today=$(date -u "+%Y-%m-%d")
          mkdir -p data
          output_file="data/${today}.jsonl"
          
          # 删除旧文件
          if [ -f "$output_file" ]; then
            rm "$output_file"
          fi

          # 运行爬取脚本
          cd daily_arxiv || { echo "❌ 未找到daily_arxiv目录"; exit 1; }
          export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
          export LANGUAGE="${{ vars.LANGUAGE }}"
          export CATEGORIES="${{ vars.CATEGORIES }}"
          export MODEL_NAME="${{ vars.MODEL_NAME }}"
          export OUTPUT_FILE="../$output_file"

          ${{ env.CRAWL_PYTHON }} daily_arxiv/spiders/arxiv.py || { echo "❌ 爬取失败"; exit 1; }

          # 验证结果
          if [ ! -f "../$output_file" ] || [ ! -s "../$output_file" ]; then
            echo "❌ 爬取文件异常"
            exit 1
          fi
          echo "crawl_date=$today" >> $GITHUB_OUTPUT

      # --------------------------
      # 步骤5：去重检查（使用main-env）
      # --------------------------
      - name: Check duplicates (main-env)
        id: dedup_check
        shell: bash -l {0}
        run: |
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }
          
          cd daily_arxiv || { echo "❌ 未找到daily_arxiv目录"; exit 1; }
          set +e
          ${{ env.MAIN_PYTHON }} daily_arxiv/check_stats.py
          dedup_exit_code=$?
          set -e

          case $dedup_exit_code in
            0)
              echo "has_new_content=true" >> $GITHUB_OUTPUT
              ;;
            1)
              echo "has_new_content=false" >> $GITHUB_OUTPUT
              echo "skip_reason=no_new_content" >> $GITHUB_OUTPUT
              ;;
            *)
              echo "has_new_content=false" >> $GITHUB_OUTPUT
              echo "skip_reason=processing_error" >> $GITHUB_OUTPUT
              exit 1
              ;;
          esac

      # --------------------------
      # 步骤6：AI增强（main-env）
      # --------------------------
      - name: AI Enhancement (main-env)
        if: steps.dedup_check.outputs.has_new_content == 'true'
        shell: bash -l {0}
        run: |
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }
          
          today=${{ steps.crawl_step.outputs.crawl_date }}
          input_file="data/${today}.jsonl"
          
          if [ ! -f "$input_file" ]; then
            echo "❌ 爬取文件不存在"
            exit 1
          fi

          cd ai || { echo "❌ 未找到ai目录"; exit 1; }
          export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
          export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
          export LANGUAGE="${{ vars.LANGUAGE }}"
          export MODEL_NAME="${{ vars.MODEL_NAME }}"

          ${{ env.MAIN_PYTHON }} enhance.py --data "../$input_file" || { echo "❌ AI增强失败"; exit 1; }

          # 验证AI输出
          ai_output_file="../data/${today}_AI_enhanced_${LANGUAGE}.jsonl"
          if [ ! -f "$ai_output_file" ] || [ ! -s "$ai_output_file" ]; then
            echo "❌ AI增强文件异常"
            exit 1
          fi

      # --------------------------
      # 步骤7：Markdown转换（main-env）
      # --------------------------
      - name: Convert to Markdown (main-env)
        if: steps.dedup_check.outputs.has_new_content == 'true'
        shell: bash -l {0}
        run: |
          conda activate main-env || { echo "❌ 无法激活main-env"; exit 1; }
          
          today=${{ steps.crawl_step.outputs.crawl_date }}
          language="${{ vars.LANGUAGE }}"
          ai_file="data/${today}_AI_enhanced_${language}.jsonl"
          
          if [ ! -f "$ai_file" ]; then
            echo "❌ AI增强文件不存在"
            exit 1
          fi

          cd to_md || { echo "❌ 未找到to_md目录"; exit 1; }
          export LANGUAGE="$language"

          ${{ env.MAIN_PYTHON }} convert.py --data "../$ai_file" || { echo "❌ Markdown转换失败"; exit 1; }

          # 验证Markdown输出
          md_file="../data/${today}_AI_enhanced_${language}.md"
          if [ ! -f "$md_file" ] || [ ! -s "$md_file" ]; then
            echo "❌ Markdown文件异常"
            exit 1
          fi

      # --------------------------
      # 后续步骤：文件更新、提交、推送
      # --------------------------
      - name: Update file list and commit changes
        if: steps.dedup_check.outputs.has_new_content == 'true'
        run: |
          # 更新文件列表
          mkdir -p assets
          ls -1t data/*.jsonl data/*.md 2>/dev/null | head -n 10 > assets/file-list.txt
          
          # 提交变更
          git config --global user.email "${{ vars.EMAIL }}"
          git config --global user.name "${{ vars.NAME }}"
          git add data/ assets/
          
          if ! git diff --staged --quiet; then
            git commit -m "update: ${{ steps.crawl_step.outputs.crawl_date }} arXiv papers"
            
            # 推送（带重试）
            for i in {1..3}; do
              if git push origin main; then
                echo "✅ 推送成功"
                break
              else
                git pull origin main --no-edit || true
                if [ $i -eq 3 ]; then
                  echo "❌ 推送失败"
                  exit 1
                fi
              fi
            done
          else
            echo "ℹ️ 无变更需提交"
          fi

      - name: Workflow summary
        run: |
          echo "=== 工作流总结 ==="
          echo "是否有新内容: ${{ steps.dedup_check.outputs.has_new_content }}"
          if [ "${{ steps.dedup_check.outputs.has_new_content }}" = "false" ]; then
            echo "跳过原因: ${{ steps.dedup_check.outputs.skip_reason }}"
          fi
    
